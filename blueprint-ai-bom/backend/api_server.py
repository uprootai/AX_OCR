"""
Blueprint AI BOM - Backend API Server

AI ê¸°ë°˜ ë„ë©´ ë¶„ì„ ë° BOM ìƒì„± API
"""

import os
import uuid
import logging
from datetime import datetime
from pathlib import Path
from typing import Optional

logger = logging.getLogger(__name__)

from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse

from routers.session_router import router as session_router_api, set_session_service
from routers.detection_router import router as detection_router_api, set_detection_service
from routers.bom_router import router as bom_router_api, set_bom_service
# Analysis ë¼ìš°í„° íŒ¨í‚¤ì§€ (5ê°œ ëª¨ë“ˆë¡œ ë¶„í• ë¨)
from routers.analysis import (
    core_router,
    dimension_router,
    line_router,
    region_router,
    gdt_router,
    set_core_services,
    set_line_services,
    set_region_services,
    set_gdt_services,
)
from routers.verification_router import router as verification_router_api, set_verification_services
from routers.classification_router import router as classification_router_api, set_classification_services
from routers.relation_router import router as relation_router_api, set_relation_services
from routers.feedback_router import router as feedback_router_api, set_feedback_services
from routers.midterm_router import router as midterm_router_api, set_session_service as set_midterm_session_service
from routers.longterm_router import router as longterm_router_api, set_session_service as set_longterm_session_service
from routers.pid_features_router import router as pid_features_router_api, set_pid_features_service
from routers.settings_router import router as settings_router_api
from schemas.session import SessionCreate, SessionResponse
from services.session_service import SessionService
from services.detection_service import DetectionService
from services.bom_service import BOMService
from services.dimension_service import DimensionService
from services.line_detector_service import LineDetectorService
from services.dimension_relation_service import DimensionRelationService
from services.connectivity_analyzer import ConnectivityAnalyzer  # Phase 6: P&ID ì—°ê²° ë¶„ì„
from services.region_segmenter import RegionSegmenter  # Phase 5: ì˜ì—­ ë¶„í• 
from services.gdt_parser import GDTParser  # Phase 7: GD&T íŒŒì‹±

# ê¸°ë³¸ ê²½ë¡œ ì„¤ì • (Dockerì—ì„œëŠ” /app ê¸°ì¤€)
BASE_DIR = Path(__file__).parent
UPLOAD_DIR = BASE_DIR / "uploads"
RESULTS_DIR = BASE_DIR / "results"
CONFIG_DIR = BASE_DIR / "config"
MODELS_DIR = BASE_DIR / "models"

# ë””ë ‰í† ë¦¬ ìƒì„±
UPLOAD_DIR.mkdir(exist_ok=True)
RESULTS_DIR.mkdir(exist_ok=True)
CONFIG_DIR.mkdir(exist_ok=True)

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="Blueprint AI BOM API",
    description="AI ê¸°ë°˜ ë„ë©´ ë¶„ì„ ë° BOM ìƒì„± ì†”ë£¨ì…˜ + P&ID ë¶„ì„ ê¸°ëŠ¥",
    version="10.6.0",  # v10.6: P&ID ë¶„ì„ ê¸°ëŠ¥ (ë°¸ë¸Œ, ì¥ë¹„, ì²´í¬ë¦¬ìŠ¤íŠ¸)
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
session_service = SessionService(UPLOAD_DIR, RESULTS_DIR)

# YOLO ëª¨ë¸ ê²½ë¡œ (ì¡´ì¬í•˜ë©´ ë¡œë“œ)
model_path = MODELS_DIR / "best.pt"
if not model_path.exists():
    model_path = None

detection_service = DetectionService(model_path=model_path)
bom_service = BOMService(output_dir=RESULTS_DIR)
dimension_service = DimensionService()  # v2: ì¹˜ìˆ˜ OCR ì„œë¹„ìŠ¤
line_detector_service = LineDetectorService()  # v2: ì„  ê²€ì¶œ ì„œë¹„ìŠ¤
relation_service = DimensionRelationService()  # Phase 2: ì¹˜ìˆ˜ì„  ê¸°ë°˜ ê´€ê³„ ì¶”ì¶œ
connectivity_analyzer = ConnectivityAnalyzer()  # Phase 6: P&ID ì—°ê²° ë¶„ì„
region_segmenter = RegionSegmenter()  # Phase 5: ì˜ì—­ ë¶„í• 
gdt_parser = GDTParser()  # Phase 7: GD&T íŒŒì‹±

# ë¼ìš°í„°ì— ì„œë¹„ìŠ¤ ì£¼ì…
set_session_service(session_service, UPLOAD_DIR)
set_detection_service(detection_service, session_service)
set_bom_service(bom_service, session_service)
# Analysis íŒ¨í‚¤ì§€ ì„œë¹„ìŠ¤ ì£¼ì… (5ê°œ ë¼ìš°í„°)
set_core_services(dimension_service, detection_service, session_service, relation_service)
set_line_services(line_detector_service, connectivity_analyzer)
set_region_services(region_segmenter)
set_gdt_services(gdt_parser)
set_verification_services(session_service)  # v3: Active Learning ê²€ì¦
set_classification_services(session_service)  # v4: VLM ë¶„ë¥˜
set_relation_services(session_service, line_detector_service)  # Phase 2: ì¹˜ìˆ˜ì„  ê¸°ë°˜ ê´€ê³„
set_feedback_services(session_service)  # Phase 8: í”¼ë“œë°± ë£¨í”„
set_midterm_session_service(session_service)  # ì¤‘ê¸° ë¡œë“œë§µ: ìš©ì ‘, ê±°ì¹ ê¸°, ìˆ˜ëŸ‰, ë²Œë£¬
set_longterm_session_service(session_service)  # ì¥ê¸° ë¡œë“œë§µ: ì˜ì—­, ë…¸íŠ¸, ë¦¬ë¹„ì „, VLM
set_pid_features_service(session_service)  # P&ID ë¶„ì„ ê¸°ëŠ¥: ë°¸ë¸Œ, ì¥ë¹„, ì²´í¬ë¦¬ìŠ¤íŠ¸

# ë¼ìš°í„° ë“±ë¡ (prefix ì—†ì´ - ë¼ìš°í„° ë‚´ë¶€ì— ì´ë¯¸ prefix ìˆìŒ)
app.include_router(session_router_api, tags=["Session"])
app.include_router(detection_router_api, tags=["Detection"])
app.include_router(bom_router_api, tags=["BOM"])
# Analysis íŒ¨í‚¤ì§€ ë¼ìš°í„° ë“±ë¡ (5ê°œ ëª¨ë“ˆ)
app.include_router(core_router, tags=["Analysis Core"])
app.include_router(dimension_router, tags=["Dimensions"])
app.include_router(line_router, tags=["Lines & Connectivity"])
app.include_router(region_router, tags=["Regions"])
app.include_router(gdt_router, tags=["GD&T & Title Block"])
app.include_router(verification_router_api, tags=["Verification"])  # v3: Active Learning
app.include_router(classification_router_api, tags=["Classification"])  # v4: VLM ë¶„ë¥˜
app.include_router(relation_router_api, tags=["Relations"])  # Phase 2: ì¹˜ìˆ˜ì„  ê¸°ë°˜ ê´€ê³„
app.include_router(feedback_router_api, tags=["Feedback"])  # Phase 8: í”¼ë“œë°± ë£¨í”„
app.include_router(midterm_router_api, tags=["Mid-term Features"])  # ì¤‘ê¸° ë¡œë“œë§µ: ìš©ì ‘, ê±°ì¹ ê¸°, ìˆ˜ëŸ‰, ë²Œë£¬
app.include_router(longterm_router_api, tags=["Long-term Features"])  # ì¥ê¸° ë¡œë“œë§µ: ì˜ì—­, ë…¸íŠ¸, ë¦¬ë¹„ì „, VLM
app.include_router(pid_features_router_api, tags=["P&ID Features"])  # P&ID ë¶„ì„ ê¸°ëŠ¥: ë°¸ë¸Œ, ì¥ë¹„, ì²´í¬ë¦¬ìŠ¤íŠ¸
app.include_router(settings_router_api, tags=["Settings"])  # API í‚¤ ì„¤ì •


@app.get("/")
async def root():
    """API ìƒíƒœ í™•ì¸"""
    return {
        "name": "Blueprint AI BOM API",
        "version": "8.0.0",
        "status": "running",
        "timestamp": datetime.now().isoformat()
    }


@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return {"status": "healthy"}


@app.get("/api/system/gpu")
async def get_gpu_status():
    """GPU ìƒíƒœ ì¡°íšŒ"""
    try:
        import subprocess
        result = subprocess.run(
            ['nvidia-smi', '--query-gpu=utilization.gpu,memory.used,memory.total', '--format=csv,noheader,nounits'],
            capture_output=True, text=True, timeout=5
        )
        if result.returncode == 0:
            parts = result.stdout.strip().split(', ')
            gpu_util = int(parts[0])
            memory_used = int(parts[1])
            memory_total = int(parts[2])
            memory_percent = (memory_used / memory_total) * 100 if memory_total > 0 else 0
            return {
                "available": True,
                "gpu_util": gpu_util,
                "memory_used": memory_used,
                "memory_total": memory_total,
                "memory_percent": round(memory_percent, 1)
            }
    except Exception:
        pass
    return {
        "available": False,
        "gpu_util": 0,
        "memory_used": 0,
        "memory_total": 0,
        "memory_percent": 0
    }


@app.get("/api/system/info")
async def get_system_info():
    """ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ"""
    import json

    # í´ë˜ìŠ¤ ì •ë³´
    classes_file = BASE_DIR / "classes_info_with_pricing.json"
    class_count = 0
    pricing_count = 0
    if classes_file.exists():
        with open(classes_file, "r", encoding="utf-8") as f:
            classes_data = json.load(f)
            # Dict í˜•ì‹: {class_name: {ëª¨ë¸ëª…, ë‹¨ê°€, ...}}
            if isinstance(classes_data, dict):
                class_count = len(classes_data)
                pricing_count = sum(1 for v in classes_data.values() if isinstance(v, dict) and v.get("ë‹¨ê°€", 0) > 0)
            # List í˜•ì‹: [{class_name, unit_price, ...}]
            elif isinstance(classes_data, list):
                class_count = len(classes_data)
                pricing_count = sum(1 for c in classes_data if isinstance(c, dict) and c.get("unit_price", 0) > 0)

    # ì„¸ì…˜ ìˆ˜
    session_count = len(session_service.list_sessions(limit=1000))

    return {
        "class_count": class_count,
        "pricing_count": pricing_count,
        "session_count": session_count,
        "model_name": "YOLO v11",
        "version": "7.0.0"
    }


@app.post("/api/system/cache/clear")
async def clear_cache(cache_type: str = "all"):
    """ìºì‹œ ì •ë¦¬"""
    import shutil
    import gc

    cleared = []

    if cache_type in ["all", "uploads"]:
        # ì˜¤ë˜ëœ ì—…ë¡œë“œ íŒŒì¼ ì •ë¦¬ (7ì¼ ì´ìƒ)
        import time
        now = time.time()
        for session_dir in UPLOAD_DIR.iterdir():
            if session_dir.is_dir():
                dir_time = session_dir.stat().st_mtime
                if now - dir_time > 7 * 24 * 60 * 60:  # 7ì¼
                    shutil.rmtree(session_dir, ignore_errors=True)
                    cleared.append(session_dir.name)

    if cache_type in ["all", "memory"]:
        # Python ë©”ëª¨ë¦¬ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        gc.collect()
        cleared.append("memory")

    return {
        "status": "success",
        "cache_type": cache_type,
        "cleared": cleared,
        "message": f"{len(cleared)}ê°œ í•­ëª© ì •ë¦¬ ì™„ë£Œ"
    }


# ==================== Test Images API ====================

TEST_DRAWINGS_DIR = BASE_DIR / "test_drawings"

@app.get("/api/test-images")
async def list_test_images():
    """í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ëª©ë¡ ì¡°íšŒ"""
    if not TEST_DRAWINGS_DIR.exists():
        return {"images": []}

    images = []
    allowed_extensions = {".png", ".jpg", ".jpeg", ".pdf"}

    for file_path in TEST_DRAWINGS_DIR.iterdir():
        if file_path.is_file() and file_path.suffix.lower() in allowed_extensions:
            images.append({
                "filename": file_path.name,
                "path": str(file_path),
                "size": file_path.stat().st_size,
                "type": file_path.suffix.lower()[1:]  # Remove the dot
            })

    return {"images": sorted(images, key=lambda x: x["filename"])}


@app.post("/api/test-images/load")
async def load_test_image(filename: str):
    """í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¡œë“œ ë° ì„¸ì…˜ ìƒì„±"""
    file_path = TEST_DRAWINGS_DIR / filename

    if not file_path.exists():
        raise HTTPException(status_code=404, detail="í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ì„¸ì…˜ ID ìƒì„±
    session_id = str(uuid.uuid4())

    # íŒŒì¼ ë³µì‚¬
    session_dir = UPLOAD_DIR / session_id
    session_dir.mkdir(exist_ok=True)

    import shutil
    dest_path = session_dir / filename
    shutil.copy(file_path, dest_path)

    # ì„¸ì…˜ ì •ë³´ ì €ì¥
    session_info = session_service.create_session(
        session_id=session_id,
        filename=filename,
        file_path=str(dest_path)
    )

    return {
        "session_id": session_id,
        "filename": filename,
        "file_path": str(dest_path),
        "status": "uploaded",
        "message": "í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ"
    }


# ==================== Models API ====================

@app.get("/api/models")
async def list_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ ëª©ë¡"""
    models = [
        {
            "id": "yolo_v11n",
            "name": "YOLOv11 Nano",
            "emoji": "ğŸš€",
            "description": "ë¹ ë¥¸ ê²€ì¶œ ì†ë„, ë‚®ì€ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©",
            "accuracy": 0.85,
            "speed": "fast"
        },
        {
            "id": "yolo_v11s",
            "name": "YOLOv11 Small",
            "emoji": "âš¡",
            "description": "ê· í˜• ì¡íŒ ì†ë„ì™€ ì •í™•ë„",
            "accuracy": 0.88,
            "speed": "medium"
        },
        {
            "id": "yolo_v11m",
            "name": "YOLOv11 Medium",
            "emoji": "ğŸ¯",
            "description": "ë†’ì€ ì •í™•ë„, ì¤‘ê°„ ì†ë„",
            "accuracy": 0.91,
            "speed": "medium"
        },
        {
            "id": "yolo_v11x",
            "name": "YOLOv11 XLarge",
            "emoji": "ğŸ”¬",
            "description": "ìµœê³  ì •í™•ë„, ëŠë¦° ì†ë„",
            "accuracy": 0.94,
            "speed": "slow"
        }
    ]
    return {"models": models}


# ==================== Ground Truth API ====================

# Reference GT (read-only, from test_drawings)
GT_LABELS_DIR = BASE_DIR / "test_drawings" / "labels"
GT_CLASSES_FILE = BASE_DIR / "test_drawings" / "classes.txt"

# Uploaded GT (writable, for user uploads)
GT_UPLOAD_DIR = BASE_DIR / "uploads" / "gt_labels"


def load_gt_classes() -> list[str]:
    """GT í´ë˜ìŠ¤ ëª©ë¡ ë¡œë“œ"""
    if not GT_CLASSES_FILE.exists():
        return []
    with open(GT_CLASSES_FILE, "r", encoding="utf-8") as f:
        return [line.strip() for line in f if line.strip()]


def parse_yolo_label(label_file: Path, img_width: int, img_height: int, classes: list[str]) -> list[dict]:
    """YOLO í˜•ì‹ ë¼ë²¨ íŒŒì‹± (normalized -> absolute coords)"""
    if not label_file.exists():
        return []

    labels = []
    with open(label_file, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            # Skip comments and empty lines
            if not line or line.startswith("#"):
                continue

            parts = line.split()
            if len(parts) < 5:
                continue

            try:
                class_id = int(parts[0])
                x_center = float(parts[1])
                y_center = float(parts[2])
                width = float(parts[3])
                height = float(parts[4])

                # Convert normalized coords to absolute
                x1 = int((x_center - width / 2) * img_width)
                y1 = int((y_center - height / 2) * img_height)
                x2 = int((x_center + width / 2) * img_width)
                y2 = int((y_center + height / 2) * img_height)

                # Get class name
                class_name = classes[class_id] if class_id < len(classes) else f"class_{class_id}"

                labels.append({
                    "class_id": class_id,
                    "class_name": class_name,
                    "bbox": {"x1": x1, "y1": y1, "x2": x2, "y2": y2},
                    "x_center": x_center,
                    "y_center": y_center,
                    "width": width,
                    "height": height,
                })
            except (ValueError, IndexError):
                continue

    return labels


def find_gt_label_file(base_name: str) -> Path | None:
    """GT ë¼ë²¨ íŒŒì¼ ì°¾ê¸° (ì—…ë¡œë“œëœ íŒŒì¼ ìš°ì„ , ì—†ìœ¼ë©´ ë ˆí¼ëŸ°ìŠ¤ íŒŒì¼)"""
    # ì—…ë¡œë“œëœ GT ë¨¼ì € í™•ì¸
    uploaded_file = GT_UPLOAD_DIR / f"{base_name}.txt"
    if uploaded_file.exists():
        return uploaded_file
    # ë ˆí¼ëŸ°ìŠ¤ GT í™•ì¸
    reference_file = GT_LABELS_DIR / f"{base_name}.txt"
    if reference_file.exists():
        return reference_file
    return None


def load_gt_classes_for_file(label_file: Path) -> list[str]:
    """ë¼ë²¨ íŒŒì¼ì— í•´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤ ëª©ë¡ ë¡œë“œ"""
    # ì—…ë¡œë“œëœ GTì¸ ê²½ìš° uploadsì˜ classes.txt ì‚¬ìš©
    if label_file.parent == GT_UPLOAD_DIR:
        classes_file = GT_UPLOAD_DIR / "classes.txt"
        if classes_file.exists():
            with open(classes_file, "r", encoding="utf-8") as f:
                return [line.strip() for line in f if line.strip()]
    # ë ˆí¼ëŸ°ìŠ¤ GT classes
    return load_gt_classes()


@app.get("/api/ground-truth/{filename}")
async def get_ground_truth(filename: str, img_width: int = 1000, img_height: int = 1000):
    """ì´ë¯¸ì§€ íŒŒì¼ëª…ì— í•´ë‹¹í•˜ëŠ” Ground Truth ë¼ë²¨ ì¡°íšŒ

    Args:
        filename: ì´ë¯¸ì§€ íŒŒì¼ëª… (ì˜ˆ: img_00031.jpg)
        img_width: ì´ë¯¸ì§€ ë„ˆë¹„ (ì ˆëŒ€ ì¢Œí‘œ ë³€í™˜ìš©)
        img_height: ì´ë¯¸ì§€ ë†’ì´ (ì ˆëŒ€ ì¢Œí‘œ ë³€í™˜ìš©)
    """
    # Remove extension and find label file
    base_name = Path(filename).stem
    label_file = find_gt_label_file(base_name)

    if not label_file:
        return {
            "filename": filename,
            "has_ground_truth": False,
            "labels": [],
            "count": 0,
            "message": f"GT ë¼ë²¨ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {base_name}.txt"
        }

    classes = load_gt_classes_for_file(label_file)
    labels = parse_yolo_label(label_file, img_width, img_height, classes)

    return {
        "filename": filename,
        "has_ground_truth": True,
        "labels": labels,
        "count": len(labels),
        "classes": classes,
        "label_file": str(label_file.name)
    }


@app.get("/api/ground-truth")
async def list_available_ground_truth():
    """ì‚¬ìš© ê°€ëŠ¥í•œ GT ë¼ë²¨ ëª©ë¡ ì¡°íšŒ (ì—…ë¡œë“œëœ íŒŒì¼ + ë ˆí¼ëŸ°ìŠ¤ íŒŒì¼)"""
    label_files = []
    seen_names = set()

    # ì—…ë¡œë“œëœ GT ë¨¼ì € (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
    if GT_UPLOAD_DIR.exists():
        for f in GT_UPLOAD_DIR.iterdir():
            if f.is_file() and f.suffix == ".txt" and f.name != "classes.txt":
                label_files.append({
                    "filename": f.stem,
                    "label_file": f.name,
                    "size": f.stat().st_size,
                    "source": "uploaded"
                })
                seen_names.add(f.stem)

    # ë ˆí¼ëŸ°ìŠ¤ GT (ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°ë§Œ)
    if GT_LABELS_DIR.exists():
        for f in GT_LABELS_DIR.iterdir():
            if f.is_file() and f.suffix == ".txt" and f.name != "classes.txt" and not f.name.startswith("README"):
                if f.stem not in seen_names:
                    label_files.append({
                        "filename": f.stem,
                        "label_file": f.name,
                        "size": f.stat().st_size,
                        "source": "reference"
                    })

    classes = load_gt_classes()

    return {
        "labels": sorted(label_files, key=lambda x: x["filename"]),
        "count": len(label_files),
        "classes": classes,
        "classes_count": len(classes)
    }


@app.post("/api/ground-truth/upload")
async def upload_ground_truth(
    file: UploadFile = File(...),
    filename: str = None,
    img_width: int = 1000,
    img_height: int = 1000
):
    """GT ë¼ë²¨ íŒŒì¼ ì—…ë¡œë“œ

    ì§€ì› í˜•ì‹:
    - JSON: [{"class_name": "...", "bbox": {"x1": 0, "y1": 0, "x2": 100, "y2": 100}}, ...]
    - TXT (YOLO í˜•ì‹): class_id x_center y_center width height (per line)
    - XML (Pascal VOC í˜•ì‹)

    Args:
        file: ì—…ë¡œë“œí•  GT íŒŒì¼
        filename: ì €ì¥í•  íŒŒì¼ëª… (ì—†ìœ¼ë©´ ì›ë³¸ íŒŒì¼ëª… ì‚¬ìš©)
        img_width: ì´ë¯¸ì§€ ë„ˆë¹„ (ì¢Œí‘œ ë³€í™˜ìš©)
        img_height: ì´ë¯¸ì§€ ë†’ì´ (ì¢Œí‘œ ë³€í™˜ìš©)
    """
    import json
    import xml.etree.ElementTree as ET

    # íŒŒì¼ëª… ê²°ì •
    original_name = Path(file.filename).stem
    target_name = filename if filename else original_name
    target_name = Path(target_name).stem  # í™•ì¥ì ì œê±°

    # GT ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ ìƒì„± (writable)
    GT_UPLOAD_DIR.mkdir(parents=True, exist_ok=True)

    content = await file.read()
    content_str = content.decode('utf-8')

    labels = []
    classes = load_gt_classes()

    try:
        # JSON í˜•ì‹
        if file.filename.endswith('.json'):
            data = json.loads(content_str)
            if isinstance(data, list):
                for item in data:
                    class_name = item.get('class_name', item.get('label', 'unknown'))
                    bbox = item.get('bbox', item.get('bndbox', {}))

                    # class_id ì°¾ê¸° ë˜ëŠ” ì¶”ê°€
                    if class_name in classes:
                        class_id = classes.index(class_name)
                    else:
                        classes.append(class_name)
                        class_id = len(classes) - 1

                    # bboxë¥¼ YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (x_center, y_center, width, height - normalized)
                    x1 = bbox.get('x1', bbox.get('xmin', 0))
                    y1 = bbox.get('y1', bbox.get('ymin', 0))
                    x2 = bbox.get('x2', bbox.get('xmax', 0))
                    y2 = bbox.get('y2', bbox.get('ymax', 0))

                    x_center = ((x1 + x2) / 2) / img_width
                    y_center = ((y1 + y2) / 2) / img_height
                    w = (x2 - x1) / img_width
                    h = (y2 - y1) / img_height

                    labels.append(f"{class_id} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}")

        # XML (Pascal VOC) í˜•ì‹
        elif file.filename.endswith('.xml'):
            root = ET.fromstring(content_str)
            for obj in root.findall('object'):
                class_name = obj.find('name').text
                bndbox = obj.find('bndbox')

                if class_name in classes:
                    class_id = classes.index(class_name)
                else:
                    classes.append(class_name)
                    class_id = len(classes) - 1

                x1 = float(bndbox.find('xmin').text)
                y1 = float(bndbox.find('ymin').text)
                x2 = float(bndbox.find('xmax').text)
                y2 = float(bndbox.find('ymax').text)

                x_center = ((x1 + x2) / 2) / img_width
                y_center = ((y1 + y2) / 2) / img_height
                w = (x2 - x1) / img_width
                h = (y2 - y1) / img_height

                labels.append(f"{class_id} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}")

        # TXT (YOLO) í˜•ì‹ - ê·¸ëŒ€ë¡œ ì €ì¥
        elif file.filename.endswith('.txt'):
            labels = [line.strip() for line in content_str.split('\n') if line.strip()]

        else:
            raise HTTPException(status_code=400, detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {file.filename}")

        # YOLO í˜•ì‹ìœ¼ë¡œ ì €ì¥ (uploads ë””ë ‰í† ë¦¬ì— ì €ì¥)
        label_file = GT_UPLOAD_DIR / f"{target_name}.txt"
        with open(label_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(labels))

        # í´ë˜ìŠ¤ íŒŒì¼ ì €ì¥ (uploads ë””ë ‰í† ë¦¬ì—)
        classes_file = GT_UPLOAD_DIR / "classes.txt"
        with open(classes_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(classes))

        return {
            "success": True,
            "filename": target_name,
            "label_file": str(label_file.name),
            "label_count": len(labels),
            "message": f"GT ë¼ë²¨ {len(labels)}ê°œê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
        }

    except json.JSONDecodeError as e:
        raise HTTPException(status_code=400, detail=f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
    except ET.ParseError as e:
        raise HTTPException(status_code=400, detail=f"XML íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"GT ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")


@app.post("/api/ground-truth/compare")
async def compare_with_ground_truth(
    filename: str,
    detections: list[dict],
    img_width: int = 1000,
    img_height: int = 1000,
    iou_threshold: float = 0.3,
    model_type: str = None,
    class_agnostic: bool = False
):
    """ê²€ì¶œ ê²°ê³¼ì™€ Ground Truth ë¹„êµ (TP/FP/FN ê³„ì‚°)

    Args:
        filename: ì´ë¯¸ì§€ íŒŒì¼ëª…
        detections: ê²€ì¶œ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ [{class_name, bbox: {x1,y1,x2,y2}}]
        img_width: ì´ë¯¸ì§€ ë„ˆë¹„
        img_height: ì´ë¯¸ì§€ ë†’ì´
        iou_threshold: IoU ì„ê³„ê°’ (ê¸°ë³¸ 0.3)
        model_type: ëª¨ë¸ íƒ€ì… (bom_detector ë“±) - í•´ë‹¹ í´ë˜ìŠ¤ íŒŒì¼ ì‚¬ìš©
        class_agnostic: Trueë©´ í´ë˜ìŠ¤ ë¬´ê´€í•˜ê²Œ ìœ„ì¹˜(IoU)ë§Œìœ¼ë¡œ ë§¤ì¹­
    """
    # Load GT (ì—…ë¡œë“œëœ íŒŒì¼ ìš°ì„ )
    base_name = Path(filename).stem
    label_file = find_gt_label_file(base_name)

    if not label_file:
        return {
            "error": "GT ë¼ë²¨ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
            "has_ground_truth": False,
            "filename": filename,
            "searched_label": f"{base_name}.txt"
        }

    # ëª¨ë¸ íƒ€ì…ì— ë”°ë¥¸ í´ë˜ìŠ¤ íŒŒì¼ ì„ íƒ
    if model_type:
        # ì—…ë¡œë“œëœ GT ë””ë ‰í† ë¦¬ ë¨¼ì € í™•ì¸
        model_classes_file = GT_UPLOAD_DIR / f"classes_{model_type}.txt"
        if not model_classes_file.exists():
            model_classes_file = GT_LABELS_DIR / f"classes_{model_type}.txt"
        if model_classes_file.exists():
            with open(model_classes_file, "r", encoding="utf-8") as f:
                classes = [line.strip() for line in f if line.strip()]
        else:
            classes = load_gt_classes_for_file(label_file)
    else:
        classes = load_gt_classes_for_file(label_file)

    gt_labels = parse_yolo_label(label_file, img_width, img_height, classes)

    # Debug logging
    logger.debug(f"GT Compare: class_agnostic={class_agnostic}, model_type={model_type}")
    logger.debug(f"  filename={filename}, gt_count={len(gt_labels)}, det_count={len(detections)}")

    def calculate_iou(box1: dict, box2: dict) -> float:
        """IoU ê³„ì‚°"""
        x1 = max(box1["x1"], box2["x1"])
        y1 = max(box1["y1"], box2["y1"])
        x2 = min(box1["x2"], box2["x2"])
        y2 = min(box1["y2"], box2["y2"])

        if x2 <= x1 or y2 <= y1:
            return 0.0

        intersection = (x2 - x1) * (y2 - y1)
        area1 = (box1["x2"] - box1["x1"]) * (box1["y2"] - box1["y1"])
        area2 = (box2["x2"] - box2["x1"]) * (box2["y2"] - box2["y1"])
        union = area1 + area2 - intersection

        return intersection / union if union > 0 else 0.0

    # Match detections with GT
    matched_gt = set()
    matched_det = set()
    tp_matches = []

    for i, det in enumerate(detections):
        det_bbox = det.get("bbox", {})
        det_class = det.get("class_name", "")

        best_iou = 0
        best_gt_idx = -1

        for j, gt in enumerate(gt_labels):
            if j in matched_gt:
                continue

            iou = calculate_iou(det_bbox, gt["bbox"])
            gt_class = gt.get("class_name", "")

            # class_agnostic ëª¨ë“œ: ìœ„ì¹˜(IoU)ë§Œìœ¼ë¡œ ë§¤ì¹­ (í´ë˜ìŠ¤ ë¬´ì‹œ)
            # ì¼ë°˜ ëª¨ë“œ: í´ë˜ìŠ¤ ë§¤ì¹­ + IoU threshold ì¡°ê±´
            if class_agnostic:
                # ìœ„ì¹˜ë§Œ í™•ì¸
                if iou > best_iou and iou >= iou_threshold:
                    best_iou = iou
                    best_gt_idx = j
                    if iou > 0.5:
                        logger.debug(f"  Match found: det[{i}] <-> gt[{j}], IoU={iou:.3f}")
            else:
                # í´ë˜ìŠ¤ë„ ì¼ì¹˜í•´ì•¼ í•¨
                if det_class == gt_class and iou > best_iou and iou >= iou_threshold:
                    best_iou = iou
                    best_gt_idx = j

        if best_gt_idx >= 0:
            matched_gt.add(best_gt_idx)
            matched_det.add(i)
            tp_matches.append({
                "detection_idx": i,
                "gt_idx": best_gt_idx,
                "iou": best_iou,
                "det_class": det_class,
                "gt_class": gt_labels[best_gt_idx]["class_name"],
                "gt_bbox": gt_labels[best_gt_idx]["bbox"],  # GT bbox for frontend cropping
                "class_match": det_class == gt_labels[best_gt_idx]["class_name"]
            })

    # Calculate metrics
    tp = len(tp_matches)
    fp = len(detections) - tp
    fn = len(gt_labels) - tp

    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

    # FP details (detections that didn't match any GT)
    fp_detections = [detections[i] for i in range(len(detections)) if i not in matched_det]

    # FN details (GT that weren't detected)
    fn_labels = [gt_labels[i] for i in range(len(gt_labels)) if i not in matched_gt]

    return {
        "filename": filename,
        "has_ground_truth": True,
        "metrics": {
            "tp": tp,
            "fp": fp,
            "fn": fn,
            "precision": round(precision * 100, 2),
            "recall": round(recall * 100, 2),
            "f1_score": round(f1 * 100, 2),
            "iou_threshold": iou_threshold
        },
        "gt_count": len(gt_labels),
        "detection_count": len(detections),
        "tp_matches": tp_matches,
        "fp_detections": fp_detections,
        "fn_labels": fn_labels
    }


@app.post("/api/upload")
async def upload_file(file: UploadFile = File(...)):
    """
    ë„ë©´ íŒŒì¼ ì—…ë¡œë“œ

    - ì§€ì› í˜•ì‹: PDF, PNG, JPG, JPEG
    - ìµœëŒ€ í¬ê¸°: 50MB
    """
    # íŒŒì¼ í™•ì¥ì ê²€ì¦
    allowed_extensions = {".pdf", ".png", ".jpg", ".jpeg"}
    file_ext = Path(file.filename).suffix.lower()

    if file_ext not in allowed_extensions:
        raise HTTPException(
            status_code=400,
            detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: {', '.join(allowed_extensions)}"
        )

    # ì„¸ì…˜ ID ìƒì„±
    session_id = str(uuid.uuid4())

    # íŒŒì¼ ì €ì¥
    session_dir = UPLOAD_DIR / session_id
    session_dir.mkdir(exist_ok=True)

    file_path = session_dir / file.filename

    with open(file_path, "wb") as f:
        content = await file.read()
        f.write(content)

    # ì„¸ì…˜ ì •ë³´ ì €ì¥
    session_info = session_service.create_session(
        session_id=session_id,
        filename=file.filename,
        file_path=str(file_path)
    )

    return {
        "session_id": session_id,
        "filename": file.filename,
        "file_path": str(file_path),
        "status": "uploaded",
        "message": "íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ. /api/detection/detect ë¥¼ í˜¸ì¶œí•˜ì—¬ ê²€ì¶œì„ ì‹œì‘í•˜ì„¸ìš”."
    }


@app.get("/api/config/classes")
async def get_classes():
    """ê²€ì¶œ í´ë˜ìŠ¤ ëª©ë¡ ì¡°íšŒ"""
    import json

    classes_file = BASE_DIR / "classes_info_with_pricing.json"

    if not classes_file.exists():
        raise HTTPException(status_code=404, detail="í´ë˜ìŠ¤ ì •ë³´ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    with open(classes_file, "r", encoding="utf-8") as f:
        classes_data = json.load(f)

    return classes_data


@app.get("/api/config/template")
async def get_template():
    """í˜„ì¬ í…œí”Œë¦¿ ì¡°íšŒ"""
    template_file = CONFIG_DIR / "template.json"

    if not template_file.exists():
        return {"message": "í…œí”Œë¦¿ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", "template": None}

    import json
    with open(template_file, "r", encoding="utf-8") as f:
        template = json.load(f)

    return template


@app.get("/api/config/class-examples")
async def get_class_examples():
    """í´ë˜ìŠ¤ë³„ ì°¸ì¡° ì´ë¯¸ì§€ ëª©ë¡"""
    import base64
    import glob

    class_examples_dir = BASE_DIR / "class_examples"

    if not class_examples_dir.exists():
        return {"examples": [], "message": "class_examples ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤."}

    examples = []
    pattern = str(class_examples_dir / "*.jpg")
    files = sorted(glob.glob(pattern))

    for file_path in files:
        try:
            filename = os.path.basename(file_path)

            # í´ë˜ìŠ¤ ì´ë¦„ ì¶”ì¶œ (class_XX_í´ë˜ìŠ¤ëª….jpg íŒ¨í„´)
            # ì˜ˆ: class_00_10_BUZZER_HY-256-2(AC220V)_p01.jpg
            parts = filename.split('_', 2)
            if len(parts) >= 3:
                # ë‚˜ë¨¸ì§€ ë¶€ë¶„ì—ì„œ _p01.jpg ë˜ëŠ” .jpg ì œê±°
                remaining = parts[2]
                if remaining.endswith('_p01.jpg'):
                    remaining = remaining[:-8]
                elif remaining.endswith('.jpg'):
                    remaining = remaining[:-4]
                class_name = remaining
            else:
                class_name = filename.replace('.jpg', '')

            # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
            with open(file_path, "rb") as f:
                image_data = base64.b64encode(f.read()).decode('utf-8')

            examples.append({
                "class_name": class_name,
                "image_base64": image_data,
                "filename": filename
            })
        except Exception as e:
            logger.warning(f"Error loading example {file_path}: {e}")
            continue

    return {"examples": examples, "count": len(examples)}


@app.delete("/api/sessions/cleanup")
async def cleanup_old_sessions(max_age_hours: int = 24):
    """ì˜¤ë˜ëœ ì„¸ì…˜ ì •ë¦¬

    Args:
        max_age_hours: ì´ ì‹œê°„ë³´ë‹¤ ì˜¤ë˜ëœ ì„¸ì…˜ ì‚­ì œ (ê¸°ë³¸ 24ì‹œê°„)
    """
    from datetime import timedelta
    import shutil

    cleaned_count = 0
    error_count = 0
    cutoff_time = datetime.now() - timedelta(hours=max_age_hours)

    sessions = session_service.list_sessions(limit=1000)

    for session in sessions:
        try:
            created_at = datetime.fromisoformat(session.get("created_at", ""))
            if created_at < cutoff_time:
                session_service.delete_session(session["session_id"])
                cleaned_count += 1
        except Exception as e:
            logger.warning(f"Error cleaning session {session.get('session_id')}: {e}")
            error_count += 1

    return {
        "cleaned_count": cleaned_count,
        "error_count": error_count,
        "message": f"{max_age_hours}ì‹œê°„ ì´ìƒ ëœ ì„¸ì…˜ {cleaned_count}ê°œ ì‚­ì œë¨"
    }


@app.get("/api/sessions/stats")
async def get_sessions_stats():
    """ì„¸ì…˜ í†µê³„"""
    sessions = session_service.list_sessions(limit=1000)

    total = len(sessions)
    by_status = {}

    for session in sessions:
        status = session.get("status", "unknown")
        by_status[status] = by_status.get(status, 0) + 1

    # ê°€ì¥ ì˜¤ë˜ëœ ì„¸ì…˜
    oldest = None
    if sessions:
        oldest = min(sessions, key=lambda s: s.get("created_at", ""))

    return {
        "total_sessions": total,
        "by_status": by_status,
        "oldest_session": {
            "session_id": oldest.get("session_id") if oldest else None,
            "created_at": oldest.get("created_at") if oldest else None
        } if oldest else None
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=5020,
        reload=True
    )
