"""Core Analysis Router - í”„ë¦¬ì…‹, ì˜µì…˜, ë¶„ì„ ì‹¤í–‰ API

ë¶„í• ëœ analysis_router.pyì˜ í•µì‹¬ ê¸°ëŠ¥:
- í”„ë¦¬ì…‹ ëª©ë¡ ë° ì ìš©
- ë¶„ì„ ì˜µì…˜ ê´€ë¦¬
- í†µí•© ë¶„ì„ ì‹¤í–‰
"""
from typing import Dict, Any
from fastapi import APIRouter, HTTPException
import logging

from schemas.analysis_options import (
    AnalysisOptions,
    AnalysisOptionsUpdate,
    AnalysisResult,
    PRESETS,
    apply_preset_to_options,
)
from schemas.session import SessionStatus

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/analysis", tags=["Analysis Core"])

# ì„œë¹„ìŠ¤ ì£¼ìž…ì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
_dimension_service = None
_detection_service = None
_session_service = None
_relation_service = None
_table_service = None

# ì„¸ì…˜ë³„ ì˜µì…˜ ìºì‹œ (ë©”ëª¨ë¦¬) - ë‹¤ë¥¸ ë¼ìš°í„°ì—ì„œë„ ì ‘ê·¼ í•„ìš”
_session_options: Dict[str, AnalysisOptions] = {}


def set_core_services(dimension_service, detection_service, session_service, relation_service=None, table_service=None):
    """ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ì„¤ì • (api_server.pyì—ì„œ í˜¸ì¶œ)"""
    global _dimension_service, _detection_service, _session_service, _relation_service, _table_service
    _dimension_service = dimension_service
    _detection_service = detection_service
    _session_service = session_service
    _relation_service = relation_service
    _table_service = table_service


def get_dimension_service():
    if _dimension_service is None:
        raise HTTPException(status_code=500, detail="Dimension service not initialized")
    return _dimension_service


def get_detection_service():
    if _detection_service is None:
        raise HTTPException(status_code=500, detail="Detection service not initialized")
    return _detection_service


def get_session_service():
    if _session_service is None:
        raise HTTPException(status_code=500, detail="Session service not initialized")
    return _session_service


def get_relation_service():
    if _relation_service is None:
        raise HTTPException(status_code=500, detail="Relation service not initialized")
    return _relation_service


def get_session_options():
    """ì„¸ì…˜ ì˜µì…˜ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜ (ë‹¤ë¥¸ ë¼ìš°í„°ì—ì„œ ì ‘ê·¼ìš©)"""
    return _session_options


# VLM ë„ë©´ ë¶„ë¥˜ ê²°ê³¼ â†’ ì‹¬ë³¼ ê²€ì¶œ ëª¨ë¸ ìžë™ ë§¤í•‘
_DRAWING_TYPE_MODEL_MAP = {
    "mechanical_part": "engineering",
    "assembly": "engineering",
    "pid": "pid_symbol",
    "electrical": "panasia",
    "architectural": "engineering",
}


def _resolve_options(session_id: str, session: dict) -> AnalysisOptions:
    """ì„¸ì…˜ì˜ ë¶„ì„ ì˜µì…˜ ê²°ì • (ìºì‹œ â†’ features ê¸°ë°˜ ìžë™ ìƒì„±)"""
    cached = _session_options.get(session_id)
    if cached is not None:
        return cached

    options = AnalysisOptions()
    features = session.get("features", [])
    if features:
        feature_to_option = {
            "symbol_detection": "enable_symbol_detection",
            "dimension_ocr": "enable_dimension_ocr",
            "line_detection": "enable_line_detection",
            "text_extraction": "enable_text_extraction",
            "table_extraction": "enable_text_extraction",
        }
        data = options.model_dump()
        # features ë¦¬ìŠ¤íŠ¸ê°€ ìžˆìœ¼ë©´ ëª¨ë“  enable_* í”Œëž˜ê·¸ë¥¼ Falseë¡œ ë¦¬ì…‹
        for key in data:
            if key.startswith("enable_"):
                data[key] = False
        # ë¦¬ìŠ¤íŠ¸ì— ìžˆëŠ” ê¸°ëŠ¥ë§Œ í™œì„±í™”
        for feature in features:
            opt_key = feature_to_option.get(feature)
            if opt_key:
                data[opt_key] = True
        # dimension_ocr ì‹œ line_detection ìžë™ í™œì„±í™” (ì¹˜ìˆ˜ì„  ê´€ê³„ ë¶„ì„ìš©)
        # ë‹¨, featuresì— line_detectionì´ ëª…ì‹œì ìœ¼ë¡œ ì—†ìœ¼ë©´ ìŠ¤í‚µ (BOM ì„¸ì…˜ ë“±)
        if data.get("enable_dimension_ocr") and "line_detection" not in features:
            # line_detection ë¯¸ìš”ì²­ â†’ ê´€ê³„ ë¶„ì„ë§Œ í™œì„±í™” (ë¡œì»¬ ê³„ì‚°, API í˜¸ì¶œ ì—†ìŒ)
            data["enable_relation_extraction"] = True
        elif data.get("enable_dimension_ocr") and "line_detection" in features:
            data["enable_line_detection"] = True
            data["enable_relation_extraction"] = True
        options = AnalysisOptions(**data)
        logger.info(f"ì„¸ì…˜ featuresì—ì„œ ì˜µì…˜ ìžë™ ìƒì„±: {features}")

    # VLM drawing_typeì— ë”°ë¼ ì‹¬ë³¼ ëª¨ë¸ ìžë™ ì„ íƒ (ê¸°ë³¸ê°’ì¼ ë•Œë§Œ)
    drawing_type = session.get("drawing_type", "")
    if drawing_type in _DRAWING_TYPE_MODEL_MAP:
        if options.symbol_model_type == "panasia":
            options.symbol_model_type = _DRAWING_TYPE_MODEL_MAP[drawing_type]
            logger.info(f"ë„ë©´ ìœ í˜• '{drawing_type}' â†’ ëª¨ë¸ '{options.symbol_model_type}' ìžë™ ì„ íƒ")

    _session_options[session_id] = options
    return options


# ==================== í”„ë¦¬ì…‹ API ====================

@router.get("/presets")
async def list_presets():
    """ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¦¬ì…‹ ëª©ë¡"""
    presets_list = []
    for preset_id, preset_data in PRESETS.items():
        presets_list.append({
            "id": preset_id,
            "name": preset_data.get("name", preset_id),
            "description": preset_data.get("description", ""),
            "icon": preset_data.get("icon", "ðŸ“‹"),
        })
    return {"presets": presets_list}


# ==================== ë¶„ì„ ì˜µì…˜ API ====================

@router.get("/options/{session_id}")
async def get_analysis_options(session_id: str) -> AnalysisOptions:
    """ì„¸ì…˜ì˜ ë¶„ì„ ì˜µì…˜ ì¡°íšŒ"""
    session_service = get_session_service()

    session = session_service.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    return _resolve_options(session_id, session)


@router.put("/options/{session_id}")
async def update_analysis_options(
    session_id: str,
    options_update: AnalysisOptionsUpdate
) -> AnalysisOptions:
    """ì„¸ì…˜ì˜ ë¶„ì„ ì˜µì…˜ ì—…ë°ì´íŠ¸"""
    session_service = get_session_service()

    session = session_service.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    current = _session_options.get(session_id, AnalysisOptions())

    if options_update.preset and options_update.preset in PRESETS:
        current = apply_preset_to_options(current, options_update.preset)
    else:
        update_data = options_update.model_dump(exclude_unset=True, exclude={'preset'})
        current_data = current.model_dump()
        for key, value in update_data.items():
            if value is not None:
                current_data[key] = value
        current = AnalysisOptions(**current_data)

    _session_options[session_id] = current
    return current


@router.post("/options/{session_id}/preset/{preset_name}")
async def apply_preset(session_id: str, preset_name: str) -> AnalysisOptions:
    """í”„ë¦¬ì…‹ ì ìš©"""
    session_service = get_session_service()

    session = session_service.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    if preset_name not in PRESETS:
        raise HTTPException(status_code=400, detail=f"Unknown preset: {preset_name}")

    options = apply_preset_to_options(AnalysisOptions(), preset_name)
    _session_options[session_id] = options

    # AnalysisOptions â†’ session features ë™ê¸°í™”
    OPTION_TO_FEATURE = {
        "enable_symbol_detection": "symbol_detection",
        "enable_dimension_ocr": "dimension_ocr",
        "enable_line_detection": "line_detection",
        "enable_text_extraction": "title_block_ocr",
        "enable_relation_extraction": "relation_extraction",
    }
    features = [
        feat for opt_key, feat in OPTION_TO_FEATURE.items()
        if getattr(options, opt_key, False)
    ]
    session_service.update_session(session_id, {"features": features})

    return options


# ==================== ë¶„ì„ ì‹¤í–‰ API ====================

@router.post("/run/{session_id}")
async def run_analysis(session_id: str) -> AnalysisResult:
    """
    ë¶„ì„ ì‹¤í–‰

    ì„¤ì •ëœ ì˜µì…˜ì— ë”°ë¼ í•´ë‹¹ ë¶„ì„ ì‹¤í–‰.
    - enable_symbol_detection: YOLO ì‹¬ë³¼ ê²€ì¶œ
    - enable_dimension_ocr: eDOCr2 ì¹˜ìˆ˜ ì¸ì‹
    """
    # ì§€ì—° ìž„í¬íŠ¸ (ìˆœí™˜ ì°¸ì¡° ë°©ì§€)
    from .line_router import get_line_detector_service

    session_service = get_session_service()
    detection_service = get_detection_service()
    dimension_service = get_dimension_service()

    session = session_service.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    image_path = session.get("file_path")
    if not image_path:
        raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")

    options = _resolve_options(session_id, session)

    result = AnalysisResult(
        session_id=session_id,
        options=options,
        detections=[],
        dimensions=[],
        lines=[],
        texts=[],
        relations=[],
        processing_time_ms=0.0,
        errors=[]
    )

    total_time = 0.0

    # 1. ì‹¬ë³¼ ê²€ì¶œ
    if options.enable_symbol_detection:
        try:
            session_service.update_status(session_id, SessionStatus.DETECTING)

            from schemas.detection import DetectionConfig
            config = DetectionConfig(
                confidence=options.confidence_threshold,
                model_type=options.symbol_model_type  # panasia ëª¨ë¸ ì‚¬ìš©
            )

            detection_result = detection_service.detect(
                image_path=image_path,
                config=config
            )

            result.detections = detection_result.get("detections", [])
            total_time += detection_result.get("processing_time_ms", 0)

            session_service.set_detections(
                session_id=session_id,
                detections=detection_result["detections"],
                image_width=detection_result["image_width"],
                image_height=detection_result["image_height"]
            )

            logger.info(f"ì‹¬ë³¼ ê²€ì¶œ ì™„ë£Œ: {len(result.detections)}ê°œ")

        except Exception as e:
            error_msg = f"ì‹¬ë³¼ ê²€ì¶œ ì‹¤íŒ¨: {str(e)}"
            logger.error(error_msg)
            result.errors.append(error_msg)

    # 2. ì¹˜ìˆ˜ OCR
    if options.enable_dimension_ocr:
        try:
            dimension_result = dimension_service.extract_dimensions(
                image_path=image_path,
                confidence_threshold=options.confidence_threshold,
                ocr_engines=options.ocr_engines,
            )

            result.dimensions = dimension_result.get("dimensions", [])
            total_time += dimension_result.get("processing_time_ms", 0)

            session_service.update_session(session_id, {
                "dimensions": result.dimensions,
                "dimension_count": len(result.dimensions),
            })

            logger.info(f"ì¹˜ìˆ˜ OCR ì™„ë£Œ: {len(result.dimensions)}ê°œ")

        except Exception as e:
            error_msg = f"ì¹˜ìˆ˜ OCR ì‹¤íŒ¨: {str(e)}"
            logger.error(error_msg)
            result.errors.append(error_msg)

    # 3. ì„  ê²€ì¶œ
    if options.enable_line_detection:
        try:
            line_detector_service = get_line_detector_service()

            from schemas.line import LineDetectionConfig
            config = LineDetectionConfig(
                method="lsd",
                classify_types=True,
                classify_colors=True,
                find_intersections=True,
                visualize=False,
            )

            line_result = line_detector_service.detect_lines(image_path, config)

            result.lines = line_result.get("lines", [])
            total_time += line_result.get("processing_time_ms", 0)

            session_service.update_session(session_id, {
                "lines": result.lines,
                "intersections": line_result.get("intersections", []),
                "line_statistics": line_result.get("statistics", {}),
                "line_count": len(result.lines),
            })

            logger.info(f"ì„  ê²€ì¶œ ì™„ë£Œ: {len(result.lines)}ê°œ")

        except Exception as e:
            error_msg = f"ì„  ê²€ì¶œ ì‹¤íŒ¨: {str(e)}"
            logger.error(error_msg)
            result.errors.append(error_msg)

    # 4. í…ìŠ¤íŠ¸/í…Œì´ë¸” ì¶”ì¶œ (Table Detector API)
    if options.enable_text_extraction and _table_service:
        try:
            table_result = _table_service.extract_tables(
                image_path=image_path,
                enable_cell_reocr=True,   # E1-B: EasyOCR ì…€ ìž¬ì¸ì‹
                enable_crop_upscale=True, # E1-B-2: í¬ë¡­ ì´ë¯¸ì§€ ESRGAN ì—…ìŠ¤ì¼€ì¼
                upscale_scale=2,          # 2x ì—…ìŠ¤ì¼€ì¼ (4xëŠ” ë„ˆë¬´ ëŠë¦¼)
            )

            if table_result.get("error"):
                result.errors.append(table_result["error"])
            else:
                tables = table_result.get("tables", [])
                regions = table_result.get("regions", [])
                total_time += table_result.get("processing_time_ms", 0)

                text_entries = []
                for region in regions:
                    text_entries.append({
                        "type": "table_region",
                        "bbox": region.get("bbox"),
                        "confidence": region.get("confidence"),
                        "label": region.get("label", "table"),
                    })
                for table in tables:
                    text_entries.append({
                        "type": "table",
                        "table_id": table.get("id"),
                        "rows": table.get("rows"),
                        "cols": table.get("cols"),
                        "headers": table.get("headers", []),
                        "data": table.get("data", []),
                        "html": table.get("html", ""),
                        "source_region": table.get("source_region", ""),
                    })

                result.texts = text_entries

                # E1-B: ìž¬OCR í†µê³„
                reocr_stats = table_result.get("reocr_stats")
                update_data = {
                    "texts": text_entries,
                    "tables_count": len(tables),
                    "table_regions_count": len(regions),
                    "table_results": tables,
                }
                if reocr_stats:
                    update_data["reocr_stats"] = reocr_stats

                session_service.update_session(session_id, update_data)

                log_msg = f"í…Œì´ë¸” ì¶”ì¶œ ì™„ë£Œ: {len(regions)}ê°œ ì˜ì—­, {len(tables)}ê°œ í…Œì´ë¸”"
                if reocr_stats and reocr_stats.get("corrected", 0) > 0:
                    log_msg += f" [ìž¬OCR: {reocr_stats['corrected']}ê°œ ì…€ ìˆ˜ì •]"
                logger.info(log_msg)

        except Exception as e:
            error_msg = f"í…Œì´ë¸” ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}"
            logger.error(error_msg)
            result.errors.append(error_msg)

    # 5. í‘œì œëž€/NOTES í…ìŠ¤íŠ¸ OCR (EasyOCR ì§ì ‘ í˜¸ì¶œ)
    if options.enable_text_extraction and _table_service:
        try:
            text_result = _table_service.extract_text_regions(
                image_path=image_path,
                ocr_engine="easyocr",
                lang="en",
            )
            text_regions = text_result.get("text_regions", [])
            total_time += text_result.get("processing_time_ms", 0)

            if text_regions:
                session_service.update_session(session_id, {
                    "text_regions": text_regions,
                    "text_regions_count": len(text_regions),
                })

                # text_entriesì— í…ìŠ¤íŠ¸ ì˜ì—­ ì¶”ê°€
                for tr in text_regions:
                    result.texts.append({
                        "type": "text_region",
                        "region": tr.get("region"),
                        "full_text": tr.get("full_text", ""),
                        "text_count": tr.get("text_count", 0),
                        "detections": tr.get("detections", []),
                    })

                # textsê°€ ê°±ì‹ ë˜ì—ˆìœ¼ë©´ ì„¸ì…˜ë„ ê°±ì‹ 
                session_service.update_session(session_id, {
                    "texts": result.texts,
                })

                logger.info(
                    f"í…ìŠ¤íŠ¸ ì˜ì—­ OCR ì™„ë£Œ: {len(text_regions)}ê°œ ì˜ì—­, "
                    f"ì´ {sum(r.get('text_count', 0) for r in text_regions)}ê°œ í…ìŠ¤íŠ¸"
                )

        except Exception as e:
            error_msg = f"í…ìŠ¤íŠ¸ ì˜ì—­ OCR ì‹¤íŒ¨: {str(e)}"
            logger.error(error_msg)
            result.errors.append(error_msg)

    # 6. í‘œì œëž€ ìžë™ ì¶”ì¶œ (title_block_ocr feature í™œì„±í™” ì‹œ)
    features = session.get("features", [])
    if "title_block_ocr" in features:
        try:
            from services.region_segmenter import RegionSegmenter, RegionSegmentationConfig, RegionType
            from schemas.gdt import TitleBlockData

            segmenter = RegionSegmenter()
            config = RegionSegmentationConfig(
                detect_title_block=True,
                detect_bom_table=False,
                detect_legend=False,
                detect_notes=False,
                detect_detail_views=False,
            )

            seg_result = await segmenter.segment(
                session_id=session_id,
                image_path=image_path,
                config=config,
            )

            title_block_region = None
            for region in seg_result.regions:
                if region.region_type == RegionType.TITLE_BLOCK:
                    title_block_region = region
                    break

            if title_block_region:
                process_result = await segmenter.process_region(
                    session_id=session_id,
                    region_id=title_block_region.id,
                    image_path=image_path,
                )

                title_block_data = TitleBlockData(
                    raw_text=process_result.ocr_text,
                    **(process_result.metadata or {})
                )

                session_service.update_session(session_id, {
                    "title_block": title_block_data.model_dump(),
                    "title_block_region_id": title_block_region.id,
                })

                logger.info(f"í‘œì œëž€ ìžë™ ì¶”ì¶œ ì™„ë£Œ: {title_block_data.drawing_number or 'N/A'}")

        except Exception as e:
            logger.warning(f"í‘œì œëž€ ìžë™ ì¶”ì¶œ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {str(e)}")

    # ==================== ê´€ê³„ ë¶„ì„ (Post-Processing) ====================
    current_session = session_service.get_session(session_id)
    if current_session:
        dims = current_session.get("dimensions", [])
        syms = current_session.get("detections", [])
        lines_data = current_session.get("lines", [])

        # A. ì¹˜ìˆ˜ì„ -ì¹˜ìˆ˜ ê´€ê³„ ë¶„ì„
        if dims and lines_data and options.enable_line_detection:
            try:
                line_detector_service = get_line_detector_service()
                from schemas.line import Line
                parsed_lines = [Line(**l) if isinstance(l, dict) else l for l in lines_data]

                relations = line_detector_service.find_dimension_lines(parsed_lines, dims)

                session_service.update_session(session_id, {
                    "dimension_line_relations": [rel.model_dump() for rel in relations],
                })
                logger.info(f"ì¹˜ìˆ˜ì„  ê´€ê³„ ë¶„ì„ ì™„ë£Œ: {len(relations)}ê°œ")
            except Exception as e:
                logger.error(f"ì¹˜ìˆ˜ì„  ê´€ê³„ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

        # B. ì¹˜ìˆ˜-ì‹¬ë³¼ ì—°ê²°
        if dims and syms and (options.enable_dimension_ocr or options.enable_symbol_detection):
            try:
                line_detector_service = get_line_detector_service()
                from schemas.line import Line
                parsed_lines = [Line(**l) if isinstance(l, dict) else l for l in lines_data] if lines_data else None

                links = line_detector_service.link_dimensions_to_symbols(dims, syms, parsed_lines)

                link_data = [link.model_dump() for link in links]
                session_service.update_session(session_id, {
                    "dimension_symbol_links": link_data,
                })

                link_map = {link.dimension_id: link.symbol_id for link in links if link.symbol_id}
                updated_dims = []
                for dim in dims:
                    dim_copy = dict(dim)
                    if dim.get("id") in link_map:
                        dim_copy["linked_to"] = link_map[dim.get("id")]
                    updated_dims.append(dim_copy)

                session_service.update_session(session_id, {"dimensions": updated_dims})
                result.dimensions = updated_dims

                logger.info(f"ì¹˜ìˆ˜-ì‹¬ë³¼ ì—°ê²° ì™„ë£Œ: {len(link_data)}ê°œ")
            except Exception as e:
                logger.error(f"ì¹˜ìˆ˜-ì‹¬ë³¼ ì—°ê²° ì‹¤íŒ¨: {str(e)}")

        # C. ì¹˜ìˆ˜ì„  ê¸°ë°˜ ê´€ê³„ ì¶”ì¶œ
        if dims and options.enable_relation_extraction:
            try:
                import time
                start_time = time.time()

                relation_service = get_relation_service()
                relations = relation_service.extract_relations(
                    dimensions=dims,
                    symbols=syms,
                    lines=lines_data
                )

                session_service.update_session(session_id, {
                    "relations": relations
                })

                result.relations = relations

                rel_time = (time.time() - start_time) * 1000
                total_time += rel_time

                method_counts = {}
                for rel in relations:
                    method = rel.get("method", "proximity")
                    method_counts[method] = method_counts.get(method, 0) + 1

                logger.info(f"ì¹˜ìˆ˜ì„  ê¸°ë°˜ ê´€ê³„ ì¶”ì¶œ ì™„ë£Œ: {len(relations)}ê°œ (ë°©ë²•ë³„: {method_counts})")

            except Exception as e:
                error_msg = f"ê´€ê³„ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}"
                logger.error(error_msg)
                result.errors.append(error_msg)

    result.processing_time_ms = total_time

    # í•µì‹¬ ê²°ê³¼(ì¹˜ìˆ˜/ê²€ì¶œ)ê°€ ìžˆìœ¼ë©´ ë¹„í•µì‹¬ ì˜¤ë¥˜(OCR ì—”ì§„ ë¯¸ì ‘ì† ë“±)ëŠ” ë¬´ì‹œ
    has_results = len(result.dimensions) > 0 or len(result.detections) > 0
    if result.errors and not has_results:
        session_service.update_status(session_id, SessionStatus.ERROR)
    else:
        session_service.update_status(session_id, SessionStatus.VERIFIED)

    return result
