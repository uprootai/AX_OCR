#!/usr/bin/env python3
"""
AI ì‹¬ë³¼ ì¸ì‹ ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ BOM ë¶„ì„ ë° ê²¬ì  ìë™í™” ì†”ë£¨ì…˜ v2.0
ìƒˆë¡œìš´ ìˆœì°¨ì  ì›Œí¬í”Œë¡œìš° ë° ë‹¤ì¤‘ ëª¨ë¸ ì§€ì›
"""

import streamlit as st
import pandas as pd
import json
import os
import glob
from pathlib import Path
import cv2
import numpy as np
# PDF ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import fitz  # PyMuPDF
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False

# OCR ê¸°ëŠ¥ ì™„ì „ ì œê±°ë¨
from PIL import Image
import tempfile
import time
import io
from ultralytics import YOLO
import torch
try:
    from streamlit_drawable_canvas import st_canvas
    CANVAS_AVAILABLE = True
except ImportError as e:
    CANVAS_AVAILABLE = False
    st_canvas = None
    print(f"âš ï¸ streamlit-drawable-canvas import ì‹¤íŒ¨: {e}")
from reportlab.lib.pagesizes import A4
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.lib import colors

# Detectron2ì™€ OCR ê¸°ëŠ¥ ì™„ì „ ì œê±°

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ìŠ¤ë§ˆíŠ¸ BOM ë¶„ì„ ì†”ë£¨ì…˜ v2.0",
    page_icon="ğŸ”§",
    layout="wide"
)

# Canvas ì»´í¬ë„ŒíŠ¸ ìµœì í™” ìŠ¤í¬ë¦½íŠ¸ ì‚½ì…
st.markdown("""
<script>
// Canvas willReadFrequently ìµœì í™”
document.addEventListener('DOMContentLoaded', function() {
    const observer = new MutationObserver(function(mutations) {
        mutations.forEach(function(mutation) {
            mutation.addedNodes.forEach(function(node) {
                if (node.nodeType === 1 && node.tagName === 'CANVAS') {
                    const ctx = node.getContext('2d', { willReadFrequently: true });
                }
            });
        });
    });
    observer.observe(document.body, { childList: true, subtree: true });
});
</script>
""", unsafe_allow_html=True)

# ================ ìºì‹± ìµœì í™” í•¨ìˆ˜ë“¤ ================

@st.cache_data
def load_pricing_data_cached():
    """ê°€ê²© ë°ì´í„° ìºì‹œ ë¡œë“œ"""
    pricing_db_path = "classes_info_with_pricing.json"
    if os.path.exists(pricing_db_path):
        with open(pricing_db_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

# [ë¯¸ì‚¬ìš© í•¨ìˆ˜ - ì£¼ì„ì²˜ë¦¬ë¨] OCR Ground Truth ë°ì´í„° ë¡œë“œ
# @st.cache_data
# def load_ground_truth_cached():
#     """Ground Truth ë°ì´í„° ìºì‹œ ë¡œë“œ"""
#     ground_truth_path = "ocr_ground_truth.json"
#     if os.path.exists(ground_truth_path):
#         with open(ground_truth_path, 'r', encoding='utf-8') as f:
#             return json.load(f)
#     return {}

@st.cache_data
def load_class_names_from_examples_cached():
    """class_examples ë””ë ‰í† ë¦¬ì—ì„œ í´ë˜ìŠ¤ëª… ì¶”ì¶œ (ìºì‹œë¨)"""
    class_examples_path = "class_examples"
    class_names = []

    if not os.path.exists(class_examples_path):
        return []

    pattern = os.path.join(class_examples_path, "class_*.jpg")
    files = glob.glob(pattern)

    for file_path in files:
        filename = os.path.basename(file_path)
        if filename.startswith("class_") and filename.endswith(".jpg"):
            class_name = filename[6:-4]  # "class_" ì œê±°í•˜ê³  ".jpg" ì œê±°
            # "XX_" í˜•ì‹ì˜ ì¸ë±ìŠ¤ ì œê±° (ì˜ˆ: "00_10_BUZZER..." -> "10_BUZZER...")
            parts = class_name.split('_', 1)
            if len(parts) == 2 and parts[0].isdigit():
                class_name = parts[1]
            class_names.append(class_name)

    return sorted(class_names)

@st.cache_data
def load_and_resize_image_cached(image_path, target_width=None, target_height=None, scale=0.5):
    """ì´ë¯¸ì§€ ë¡œë“œ ë° ë¦¬ì‚¬ì´ì¦ˆ (ìºì‹œë¨) - ì„±ëŠ¥ ê°œì„ """
    from PIL import Image
    import numpy as np

    if not os.path.exists(image_path):
        return None

    img = Image.open(image_path)

    if target_width and target_height:
        img_resized = img.resize((target_width, target_height), Image.Resampling.LANCZOS)
    elif scale != 1.0:
        width, height = img.size
        new_width = int(width * scale)
        new_height = int(height * scale)
        img_resized = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
    else:
        img_resized = img

    return np.array(img_resized)

@st.cache_data
def image_to_base64_cached(image_array):
    """ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”© (ìºì‹œë¨) - ì„±ëŠ¥ ê°œì„ """
    from PIL import Image
    import base64
    from io import BytesIO
    import numpy as np

    # numpy arrayë¥¼ PIL Imageë¡œ ë³€í™˜
    if isinstance(image_array, np.ndarray):
        if image_array.ndim == 2:  # grayscale
            img_pil = Image.fromarray(image_array.astype(np.uint8))
        else:  # color
            img_pil = Image.fromarray(image_array.astype(np.uint8))
    else:
        img_pil = image_array

    # base64 ì¸ì½”ë”©
    buffered = BytesIO()
    img_pil.save(buffered, format="PNG")
    img_base64 = base64.b64encode(buffered.getvalue()).decode()

    return img_base64

@st.cache_data
def create_background_image_with_boxes_cached(image_array, detections_data, verification_status_hash):
    """ë°°ê²½ ì´ë¯¸ì§€ì— ê²€ì¶œ ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ìºì‹œë¨) - ì„±ëŠ¥ ê°œì„ 

    Args:
        image_array: ì›ë³¸ ì´ë¯¸ì§€ numpy array
        detections_data: ê²€ì¶œ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (JSON-serializable)
        verification_status_hash: ê²€ì¦ ìƒíƒœ í•´ì‹œê°’ (ìºì‹± í‚¤)

    Returns:
        ë°•ìŠ¤ì™€ ë ˆì´ë¸”ì´ ê·¸ë ¤ì§„ ì´ë¯¸ì§€
    """
    import cv2
    import numpy as np

    # ì´ë¯¸ì§€ ë³µì‚¬
    background_img = image_array.copy()

    # BGR to RGB ë³€í™˜
    if len(background_img.shape) == 3 and background_img.shape[2] == 3:
        background_img = cv2.cvtColor(background_img, cv2.COLOR_BGR2RGB)

    for idx, det_info in enumerate(detections_data):
        bbox = det_info['bbox']
        status = det_info['status']
        class_name = det_info['class_name']

        x1, y1, x2, y2 = bbox
        display_num = idx + 1

        # ìƒíƒœì— ë”°ë¥¸ ìƒ‰ìƒ ì„¤ì •
        if status == "approved":
            color = (0, 255, 0)  # ì´ˆë¡ìƒ‰
        elif status == "rejected":
            color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰
        else:
            color = (255, 255, 0)  # ë…¸ë€ìƒ‰ (ëŒ€ê¸°ì¤‘)

        # ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        cv2.rectangle(background_img, (x1, y1), (x2, y2), color, 2)

        # ë°•ìŠ¤ ì˜¤ë¥¸ìª½ì— ë²ˆí˜¸ë§Œ í‘œì‹œ
        label = f"{display_num}"
        font_scale = 1.5
        thickness = 3
        label_size, baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)

        label_x = x2 + 10
        label_y = y1 + 30

        # í°ìƒ‰ ë°°ê²½
        cv2.rectangle(background_img,
                    (label_x - 5, label_y - label_size[1] - 5),
                    (label_x + label_size[0] + 5, label_y + baseline + 5),
                    (255, 255, 255), -1)

        # í…Œë‘ë¦¬
        cv2.rectangle(background_img,
                    (label_x - 5, label_y - label_size[1] - 5),
                    (label_x + label_size[0] + 5, label_y + baseline + 5),
                    color, 2)

        # ë²ˆí˜¸ í…ìŠ¤íŠ¸
        cv2.putText(background_img, label, (label_x, label_y),
                   cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness)

    return background_img

# OCR í•¨ìˆ˜ ì œê±°ë¨

@st.cache_resource
def load_yolo_model_cached(model_path: str):
    """YOLO ëª¨ë¸ì„ ìºì‹œëœ ë¦¬ì†ŒìŠ¤ë¡œ ë¡œë“œ"""
    try:
        st.info(f"ğŸ”„ ëª¨ë¸ ë¡œë”© ì‹œë„: {model_path}")

        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(model_path):
            st.error(f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}")
            return None

        model = YOLO(model_path)

        # ëª¨ë¸ ìœ íš¨ì„± í™•ì¸
        if not hasattr(model, 'predict'):
            st.error(f"âŒ ë¡œë“œëœ ëª¨ë¸ì— predict ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤")
            return None

        # GPU ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° GPUë¡œ ì´ë™
        if torch.cuda.is_available():
            model.to('cuda')
            st.info(f"âœ… ëª¨ë¸ì„ GPUë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤")
        else:
            st.info(f"â„¹ï¸ CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤")

        st.success(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_path}")
        return model
    except Exception as e:
        st.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ({model_path}): {e}")
        import traceback
        st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return None

# PaddleOCR í•¨ìˆ˜ ì œê±°ë¨

def safe_mean(values):
    """ì•ˆì „í•œ í‰ê·  ê³„ì‚° - ë¹ˆ ë°°ì—´ ì²˜ë¦¬"""
    if not values or len(values) == 0:
        return 0.0
    return np.mean(values)

class ModelRegistry:
    """ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, registry_path="models/registry.json"):
        self.registry_path = registry_path
        self.registry = self.load_registry()
    
    def load_registry(self):
        """ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë¡œë“œ"""
        if os.path.exists(self.registry_path):
            with open(self.registry_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {"models": {}, "classes": {}, "metadata": {}}
    
    def get_available_models(self):
        """í™œì„±í™”ëœ ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
        available = {}
        for model_id, model_info in self.registry.get("models", {}).items():
            if model_info.get("active", True):
                # ì‹¤ì œ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                model_path = model_info.get("path", "")
                if self._check_model_exists(model_path, model_info.get("type")):
                    available[model_id] = model_info
        return available
    
    def _check_model_exists(self, path, model_type):
        """ëª¨ë¸ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        if model_type == "YOLO":
            return os.path.exists(path) and path.endswith('.pt')
        elif model_type == "Detectron2":
            # Detectron2 ì§€ì› ì œê±°ë¨
            return False
        return False

    def get_default_model(self):
        """ê¸°ë³¸ ëª¨ë¸ ë°˜í™˜"""
        for model_id, model_info in self.registry.get("models", {}).items():
            if model_info.get("default", False) and model_info.get("active", False):
                return model_id, model_info

        # defaultê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ í™œì„±í™”ëœ YOLO ëª¨ë¸ ë°˜í™˜
        for model_id, model_info in self.registry.get("models", {}).items():
            if model_info.get("type") == "YOLO" and model_info.get("active", False):
                return model_id, model_info

        return None, None

class SmartBOMSystemV2:
    """ìƒˆë¡œìš´ ìŠ¤ë§ˆíŠ¸ BOM ì‹œìŠ¤í…œ v2.0"""
    
    def __init__(self):
        self.model_registry = ModelRegistry()
        self.pricing_db_path = "classes_info_with_pricing.json"
        self.test_drawings_path = "test_drawings"
        self.class_examples_path = "class_examples"  # í´ë˜ìŠ¤ë³„ ì˜ˆì‹œ ì´ë¯¸ì§€ ê²½ë¡œ
        self.device = self.setup_device()
        self.loaded_models = {}  # ë¡œë“œëœ ëª¨ë¸ë“¤ì„ ìºì‹œ
        self.pricing_data = load_pricing_data_cached()
        self.data_yaml = self.load_data_yaml()  # YOLO ë°ì´í„°ì…‹ ì •ë³´

        # data.yaml ê¸°ë°˜ í´ë˜ìŠ¤ëª…ì„ ê·¸ëŒ€ë¡œ í‘œì‹œí•˜ë¯€ë¡œ ë§¤í•‘ í…Œì´ë¸” ì œê±°
        # ìƒˆë¡œìš´ ëª¨ë¸ì€ data.yamlì˜ ìƒì„¸ í´ë˜ìŠ¤ëª…ì„ ì§ì ‘ ì‚¬ìš©
        self.class_name_mapping = {}

        # OCR ê¸°ëŠ¥ ì™„ì „ ì œê±°ë¨

        # ëª¨ë¸ ê°€ì¤‘ì¹˜ (Weighted Ensembleìš©)
        self.model_weights = {
            'yolo_v11l': 1.0,  # YOLOv11L
            'yolo_v11x': 1.2,  # YOLOv11X (ë” í° ëª¨ë¸ì´ë¯€ë¡œ ë” ë†’ì€ ê°€ì¤‘ì¹˜)
            'yolo_v8': 0.9,    # YOLOv8 (ì´ì „ ë²„ì „ì´ë¯€ë¡œ ì•½ê°„ ë‚®ì€ ê°€ì¤‘ì¹˜)
            # Detectron2 ê´€ë ¨ ì œê±°ë¨
        }
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if 'current_image' not in st.session_state:
            st.session_state.current_image = None
        if 'selected_models' not in st.session_state:
            st.session_state.selected_models = []
        if 'detection_results' not in st.session_state:
            st.session_state.detection_results = {}
        if 'verified_detections' not in st.session_state:
            st.session_state.verified_detections = []
        if 'manual_annotations' not in st.session_state:
            st.session_state.manual_annotations = []

    def setup_device(self):
        """ë””ë°”ì´ìŠ¤ ì„¤ì •"""
        if torch.cuda.is_available():
            device = "cuda"
            device_info = f"GPU: {torch.cuda.get_device_name()}"
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            device_info += f" ({gpu_memory:.1f}GB)"
        else:
            device = "cpu"
            device_info = "CPU: ë©€í‹°ì½”ì–´ ì²˜ë¦¬"
        
        return {"device": device, "info": device_info, "available": torch.cuda.is_available()}

    def load_pricing_data(self):
        """ê°€ê²© ë°ì´í„° ë¡œë“œ"""
        if os.path.exists(self.pricing_db_path):
            with open(self.pricing_db_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}

    def load_class_names_from_examples(self):
        """class_examples ë””ë ‰í† ë¦¬ì—ì„œ í´ë˜ìŠ¤ëª… ì¶”ì¶œ"""
        class_names = []

        if not os.path.exists(self.class_examples_path):
            return []

        # class_examples ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  jpg íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
        pattern = os.path.join(self.class_examples_path, "class_*.jpg")
        files = glob.glob(pattern)

        for file_path in files:
            filename = os.path.basename(file_path)
            # class_[ì •ë ¬ë²ˆí˜¸]_[ì‹¤ì œí´ë˜ìŠ¤ì •ë³´]_p01.jpg íŒ¨í„´ì—ì„œ ì‹¤ì œí´ë˜ìŠ¤ì •ë³´ ì¶”ì¶œ
            # ì˜ˆ: class_00_10_BUZZER_HY-256-2(AC220V)_p01.jpg â†’ 10_BUZZER_HY-256-2(AC220V)

            parts = filename.split('_', 2)  # class, ì •ë ¬ë²ˆí˜¸, ë‚˜ë¨¸ì§€ë¡œ ë¶„ë¦¬
            if len(parts) >= 3:
                # ë‚˜ë¨¸ì§€ ë¶€ë¶„ì—ì„œ _p01.jpg ë˜ëŠ” .jpg ì œê±°
                remaining = parts[2]
                if remaining.endswith('_p01.jpg'):
                    remaining = remaining[:-8]  # _p01.jpg ê¸¸ì´ë§Œí¼ ì œê±°
                elif remaining.endswith('.jpg'):
                    remaining = remaining[:-4]  # .jpg ê¸¸ì´ë§Œí¼ ì œê±°
                class_names.append(remaining)

        # í´ë˜ìŠ¤ëª… ì• ìˆ«ìë¡œ ì •ë ¬
        def get_class_number(class_name):
            parts = class_name.split('_')
            if parts and parts[0].isdigit():
                return int(parts[0])
            # ìˆ«ì,ìˆ«ì í˜•ì‹ ì²˜ë¦¬ (ì˜ˆ: "2,3,4,5_CIRCUIT...")
            if parts and ',' in parts[0]:
                first_num = parts[0].split(',')[0]
                if first_num.isdigit():
                    return int(first_num)
            return 999

        class_names.sort(key=get_class_number)
        return class_names

    def load_data_yaml(self):
        """YOLO data.yaml íŒŒì¼ ë¡œë“œ"""
        data_yaml_path = os.path.join(self.test_drawings_path, 'data.yaml')
        if os.path.exists(data_yaml_path):
            import yaml
            with open(data_yaml_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        return None

    def get_display_class_name(self, class_name):
        """ì§§ì€ í´ë˜ìŠ¤ëª…ì„ ê¸´ í˜•íƒœë¡œ ë³€í™˜"""
        return self.class_name_mapping.get(class_name, class_name)

    def render_sidebar(self):
        """ì‚¬ì´ë“œë°” ë Œë”ë§"""
        with st.sidebar:
            st.title("ğŸ”§ ì‹œìŠ¤í…œ ì„¤ì •")
            
            # 1. ë°ì´í„° ì…ë ¥ ì„¹ì…˜
            st.header("ğŸ“ ë°ì´í„° ì…ë ¥")
            
            # íŒŒì¼ ì—…ë¡œë“œ
            uploaded_file = st.file_uploader(
                "ë„ë©´ íŒŒì¼ ì—…ë¡œë“œ",
                type=['pdf', 'png', 'jpg', 'jpeg'],
                help="PDF ë˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
            )
            
            # í…ŒìŠ¤íŠ¸ ë„ë©´ ì„ íƒ
            test_files = self.get_test_files()
            if test_files:
                st.write("ë˜ëŠ” í…ŒìŠ¤íŠ¸ ë„ë©´ ì„ íƒ:")
                selected_test = st.selectbox(
                    "í…ŒìŠ¤íŠ¸ ë„ë©´",
                    ["ì„ íƒí•˜ì„¸ìš”..."] + test_files,
                    key="test_drawing_selector"
                )
            else:
                selected_test = None

            # ì´ë¯¸ì§€ ë¡œë“œ ë° ì„¤ì •
            if uploaded_file is not None:
                processed_file = self.process_uploaded_file(uploaded_file)
                if processed_file is not None:
                    st.session_state.current_image = processed_file
                    # ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥ (Enhanced OCR v3.0 Ultimateë¥¼ ìœ„í•´)
                    if isinstance(processed_file, dict) and 'image' in processed_file:
                        st.session_state.original_image = processed_file['image']
                    st.success("âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ")
            elif selected_test and selected_test != "ì„ íƒí•˜ì„¸ìš”...":
                test_image = self.load_test_image(selected_test)
                if test_image is not None:
                    st.session_state.current_image = test_image
                    # ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥ (Enhanced OCR v3.0 Ultimateë¥¼ ìœ„í•´)
                    if isinstance(test_image, dict) and 'image' in test_image:
                        st.session_state.original_image = test_image['image']
                    st.success(f"âœ… {selected_test} ë¡œë“œ ì™„ë£Œ")

            st.divider()

            # 2. ì‹œìŠ¤í…œ ì •ë³´
            st.header("ğŸ–¥ï¸ ì‹œìŠ¤í…œ ì •ë³´")
            st.write(f"**ì²˜ë¦¬ì¥ì¹˜**: {self.device['info']}")
            st.write(f"**ê°€ê²© DB**: {len(self.pricing_data)}ê°œ ë¶€í’ˆ")
            
            if self.device['available']:
                gpu_status = self.get_gpu_status()
                if gpu_status['available']:
                    st.write(f"**GPU ë©”ëª¨ë¦¬**: {gpu_status['memory_used']}MB / {gpu_status['memory_total']}MB")
                    st.progress(gpu_status['memory_percent'] / 100)

            st.divider()

            # 4. ë©”ëª¨ë¦¬ ê´€ë¦¬
            st.header("ğŸ§  ë©”ëª¨ë¦¬ ê´€ë¦¬")
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ—‘ï¸ ìºì‹œ ì •ë¦¬"):
                    self.clear_all_cache()
                    st.success("ëª¨ë“  ìºì‹œ ë° ì„¸ì…˜ ìƒíƒœ ì •ë¦¬ ì™„ë£Œ")
                    # st.rerun() ì œê±° - ìºì‹œ ì •ë¦¬ í›„ ìë™ ì—…ë°ì´íŠ¸
            
            with col2:
                auto_clear = st.checkbox("ìë™ ì •ë¦¬", value=True)

    def get_test_files(self):
        """í…ŒìŠ¤íŠ¸ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        if os.path.exists(self.test_drawings_path):
            files = []
            for file in os.listdir(self.test_drawings_path):
                if file.lower().endswith(('.pdf', '.png', '.jpg', '.jpeg')):
                    files.append(file)
            return sorted(files)
        return []

    def process_uploaded_file(self, uploaded_file):
        """ì—…ë¡œë“œëœ íŒŒì¼ ì²˜ë¦¬"""
        if uploaded_file.type == "application/pdf":
            # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
            if PDF_AVAILABLE:
                try:
                    # PyMuPDF ì‚¬ìš©
                    pdf_bytes = uploaded_file.getvalue()
                    pdf_document = fitz.open(stream=pdf_bytes, filetype="pdf")
                    
                    # ì²« í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
                    page = pdf_document[0]
                    mat = fitz.Matrix(2, 2)  # 200 DPI ìƒë‹¹ì˜ í™•ëŒ€
                    pix = page.get_pixmap(matrix=mat)
                    
                    # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
                    img_data = pix.pil_tobytes(format="PNG")
                    image = Image.open(io.BytesIO(img_data))
                    
                    pdf_document.close()
                    
                    return {"image": np.array(image), "filename": uploaded_file.name, "type": "PDF"}
                except Exception as e:
                    st.error(f"PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    st.info("ì¼ì‹œì ì¸ ì˜¤ë¥˜ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ì´ë¯¸ì§€ íŒŒì¼(JPG, PNG)ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
                    return None
            else:
                st.error("âš ï¸ PDF ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                st.info("ğŸ“‹ í•´ê²° ë°©ë²•:")
                st.code("pip install PyMuPDF pdf2image", language="bash")
                st.info("ğŸ–¼ï¸ ë˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼(JPG, PNG)ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
                return None
        else:
            # ì´ë¯¸ì§€ íŒŒì¼ ì§ì ‘ ë¡œë“œ
            image = Image.open(uploaded_file)
            return {"image": np.array(image), "filename": uploaded_file.name, "type": "Image"}

    def load_test_image(self, filename):
        """í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¡œë“œ"""
        filepath = os.path.join(self.test_drawings_path, filename)
        if filename.lower().endswith('.pdf'):
            if PDF_AVAILABLE:
                try:
                    # PyMuPDF ì‚¬ìš©
                    pdf_document = fitz.open(filepath)
                    
                    # ì²« í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
                    page = pdf_document[0]
                    mat = fitz.Matrix(2, 2)  # 200 DPI ìƒë‹¹ì˜ í™•ëŒ€
                    pix = page.get_pixmap(matrix=mat)
                    
                    # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
                    img_data = pix.pil_tobytes(format="PNG")
                    image = Image.open(io.BytesIO(img_data))
                    
                    pdf_document.close()
                    
                    return {"image": np.array(image), "filename": filename, "type": "PDF"}
                except Exception as e:
                    st.error(f"PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    st.info("ì´ë¯¸ì§€ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    return None
            else:
                st.warning("PDF ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                st.info("ì´ë¯¸ì§€ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                return None
        else:
            image = Image.open(filepath)
            return {"image": np.array(image), "filename": filename, "type": "Image"}

    def get_gpu_status(self):
        """GPU ìƒíƒœ í™•ì¸"""
        try:
            import subprocess
            result = subprocess.run([
                'nvidia-smi', '--query-gpu=memory.used,memory.total,utilization.gpu',
                '--format=csv,noheader,nounits'
            ], capture_output=True, text=True)
            
            if result.returncode == 0:
                gpu_info = result.stdout.strip().split(', ')
                memory_used = int(gpu_info[0])
                memory_total = int(gpu_info[1])
                gpu_util = int(gpu_info[2])
                return {
                    "memory_used": memory_used,
                    "memory_total": memory_total,
                    "memory_percent": (memory_used / memory_total) * 100,
                    "gpu_util": gpu_util,
                    "available": True
                }
        except:
            pass
        return {"available": False}

    def clear_model_cache(self):
        """ëª¨ë¸ ìºì‹œ ì •ë¦¬"""
        self.loaded_models = {}

        # ì„¸ì…˜ ìƒíƒœì—ì„œ ëª¨ë¸ ìºì‹œ ì •ë¦¬ (model_ ì ‘ë‘ì‚¬ë¥¼ ê°€ì§„ í‚¤ë“¤)
        model_keys_to_clear = [key for key in st.session_state.keys() if key.startswith('model_')]
        for key in model_keys_to_clear:
            del st.session_state[key]

        # Streamlit ìì› ìºì‹œ í´ë¦¬ì–´
        st.cache_resource.clear()

        if torch.cuda.is_available():
            torch.cuda.empty_cache()

        st.info("ğŸ§¹ ëª¨ë“  ëª¨ë¸ ìºì‹œê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤")

    def clear_all_cache(self):
        """ëª¨ë“  ìºì‹œ ë° ì„¸ì…˜ ìƒíƒœ ì •ë¦¬"""
        # ëª¨ë¸ ìºì‹œ ì •ë¦¬
        self.clear_model_cache()

        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (í•µì‹¬ ìƒíƒœë“¤ë§Œ)
        session_keys_to_clear = [
            'current_image', 'selected_models', 'detection_results',
            'verified_detections', 'manual_annotations', 'edit_mode',
            'modified_classes', 'temp_class_', 'bom_data', 'bom_generated'
        ]

        for key in list(st.session_state.keys()):
            # temp_class_ë¡œ ì‹œì‘í•˜ëŠ” í‚¤ë“¤ë„ ëª¨ë‘ ì •ë¦¬
            if key.startswith('temp_class_') or key in session_keys_to_clear:
                del st.session_state[key]

    def render_main_workflow(self):
        """ë©”ì¸ ì›Œí¬í”Œë¡œìš° ë Œë”ë§"""
        
        # 1. ë„ë©´ í‘œì‹œ ì„¹ì…˜
        st.title("ğŸ¯ AI ê¸°ë°˜ BOM ì¶”ì¶œ ì›Œí¬í”Œë¡œìš°")
        
        if hasattr(st.session_state, 'current_image') and st.session_state.current_image is not None:
            self.render_drawing_display()
            st.divider()
            
            # 2. AI ëª¨ë¸ ì„ íƒ ì„¹ì…˜
            self.render_model_selection()
            st.divider()
            
            # 3. ê²€ì¶œ ê²°ê³¼ í‘œì‹œ
            if st.session_state.selected_models:
                self.render_detection_results()
                st.divider()
                
                # 4. ì‹¬ë³¼ ê²€ì¦ ì„¹ì…˜
                self.render_symbol_verification()
                st.divider()
                
                # 5. BOM ìƒì„± ë° ë‚´ë³´ë‚´ê¸°
                self.render_bom_generation()
        else:
            st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ ë„ë©´ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ í…ŒìŠ¤íŠ¸ ë„ë©´ì„ ì„ íƒí•˜ì„¸ìš”.")

    def render_drawing_display(self):
        """ì„ íƒëœ ë„ë©´ í‘œì‹œ"""
        st.header("ğŸ“‹ ì„ íƒëœ ë„ë©´")
        
        image_data = st.session_state.current_image
        col1, col2 = st.columns([3, 1])
        
        with col1:
            # ì´ë¯¸ì§€ í¬ê¸°ë¥¼ 1/4ë¡œ ì¤„ì´ê¸° ìœ„í•´ width íŒŒë¼ë¯¸í„° ì‚¬ìš©
            # ì›ë³¸ ì´ë¯¸ì§€ì˜ ë„ˆë¹„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ 25%ë¡œ í‘œì‹œ
            original_width = image_data["image"].shape[1]
            display_width = int(original_width * 0.25)  # 1/4 í¬ê¸°
            st.image(image_data["image"], caption=f"ğŸ“„ {image_data['filename']}", width=display_width)
        
        with col2:
            st.subheader("ğŸ“Š ë„ë©´ ì •ë³´")
            height, width = image_data["image"].shape[:2]
            st.write(f"**íŒŒì¼ëª…**: {image_data['filename']}")
            st.write(f"**í˜•ì‹**: {image_data['type']}")
            st.write(f"**í•´ìƒë„**: {width} Ã— {height} px")
            st.write(f"**ì¢…íš¡ë¹„**: {width/height:.2f}")
            
            # í•´ìƒë„ ê²½ê³ 
            if width < 2000 or height < 2000:
                st.warning("âš ï¸ ë‚®ì€ í•´ìƒë„ë¡œ ì¸í•´ ê²€ì¶œ ì„±ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                st.success("âœ… ê³ í•´ìƒë„ ì´ë¯¸ì§€ë¡œ ìµœì ì˜ ê²€ì¶œ ì„±ëŠ¥ ê¸°ëŒ€")

    def render_model_selection(self):
        """AI ëª¨ë¸ ì„ íƒ ì„¹ì…˜"""
        st.header("ğŸ¤– AI ëª¨ë¸ ì„ íƒ")

        available_models = self.model_registry.get_available_models()

        if not available_models:
            st.error("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©
        default_model_result = self.model_registry.get_default_model()

        if default_model_result:
            default_model_id, default_model_info = default_model_result
            if default_model_id in available_models:
                # ê¸°ë³¸ ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ì„ íƒëœ ëª¨ë¸ ëª©ë¡ì— ì¶”ê°€
                selected_models = [default_model_id]
                st.session_state.selected_models = selected_models

            # ê²€ì¶œ ì„¤ì • í‘œì‹œ
            st.divider()

            # ê²€ì¶œ ì„¤ì • í—¤ë”ì— ë„ì›€ë§ ì¶”ê°€
            col_header, col_info = st.columns([2, 3])
            with col_header:
                st.subheader("ğŸ¯ ê²€ì¶œ ì„¤ì •")

            # YOLOv11n ìµœì í™” ì„¤ì •
            st.success("âœ… YOLOv11n ìµœì í™” í™œì„±í™”ë¨")
            st.session_state['use_yolo11_approach'] = True  # YOLOv11nëŠ” í•­ìƒ ìµœì í™” ëª¨ë“œ ì‚¬ìš©

            # íŒŒë¼ë¯¸í„° ì¡°ì •
            col1, col2 = st.columns(2)
            with col1:
                confidence_threshold = st.slider(
                    "ì‹ ë¢°ë„ ì„ê³„ê°’",
                    min_value=0.3,
                    max_value=1.0,
                    value=st.session_state.get('confidence_threshold', 0.4),
                    step=0.05,
                    key="yolo11_confidence_threshold",
                    help="API ì„œë²„ì™€ ë™ì¼í•œ ìµœì  ì„¤ì •: 0.4"
                )
            with col2:
                iou_threshold = st.slider(
                    "IoU ì„ê³„ê°’",
                    min_value=0.1,
                    max_value=0.8,
                    value=st.session_state.get('model_iou_threshold', 0.5),
                    step=0.05,
                    key="yolo11_iou_threshold",
                    help="ë‚®ì„ìˆ˜ë¡ ë” ê´€ëŒ€í•œ ë§¤ì¹­"
                )
            st.session_state.confidence_threshold = confidence_threshold
            st.session_state['model_iou_threshold'] = iou_threshold

            col1, col2, col3 = st.columns([1, 1, 2])
            with col1:
                if st.button("ğŸš€ ê²€ì¶œ ì‹œì‘", type="primary"):
                    self.run_detection()
            with col2:
                st.empty()  # ë¹ˆ ê³µê°„ ìœ ì§€
                    
        else:
            st.error("âš ï¸ YOLOv11X ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

    def run_detection(self):
        """ì„ íƒëœ ëª¨ë¸ë“¤ë¡œ ê²€ì¶œ ì‹¤í–‰"""
        if not st.session_state.current_image or not st.session_state.selected_models:
            return

        progress_bar = st.progress(0)
        status_text = st.empty()

        # ê²€ì¶œ ë¶„ì„ ê²°ê³¼ ì´ˆê¸°í™”
        if 'analysis_results' not in st.session_state:
            st.session_state.analysis_results = []
        else:
            st.session_state.analysis_results.clear()

        results = {}
        total_models = len(st.session_state.selected_models)

        for i, model_id in enumerate(st.session_state.selected_models):
            status_text.text(f"ê²€ì¶œ ì¤‘: {model_id} ({i+1}/{total_models})")
            progress_bar.progress((i+1) / total_models)

            # ëª¨ë¸ ë¡œë“œ ë° ì‹¤í–‰
            # manual ëª¨ë¸ì€ model_registryì— ì—†ìœ¼ë¯€ë¡œ ë³„ë„ ì²˜ë¦¬
            if model_id == 'manual':
                model_info = {
                    'name': 'ìˆ˜ì‘ì—… ë¼ë²¨ë§',
                    'emoji': 'âœï¸',
                    'type': 'MANUAL',
                    'description': 'ì‚¬ìš©ìê°€ ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€í•œ ê²€ì¶œ'
                }
            else:
                model_info = self.model_registry.registry["models"][model_id]
            detections = self.detect_with_model(model_id, model_info)
            results[model_id] = detections

            time.sleep(0.5)  # ì‚¬ìš©ì ê²½í—˜ì„ ìœ„í•œ ì•½ê°„ì˜ ì§€ì—°

        # ê²€ì¶œ ê²°ê³¼ ì €ì¥
        st.session_state.detection_results = results
        status_text.text("âœ… ëª¨ë“  ëª¨ë¸ ê²€ì¶œ ì™„ë£Œ!")

        time.sleep(1)
        status_text.empty()
        progress_bar.empty()
        # st.rerun() ì œê±° - Streamlitì´ ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•¨

    def detect_with_model(self, model_id, model_info):
        """íŠ¹ì • ëª¨ë¸ë¡œ ê²€ì¶œ ìˆ˜í–‰"""
        try:
            if model_info['type'] == 'YOLO':
                return self._detect_with_yolo(model_id, model_info)
            elif model_info['type'] == 'Detectron2':
                st.error(f"âŒ Detectron2 ëª¨ë¸ì€ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_id}")
                return []
        except Exception as e:
            st.error(f"âŒ {model_id} ê²€ì¶œ ì‹¤íŒ¨: {str(e)}")
            return []

    def _detect_with_yolo(self, model_id, model_info):
        """YOLO ëª¨ë¸ ê²€ì¶œ - YOLO11-main ì ‘ê·¼ë²• ì ìš© (ìºì‹œ ìµœì í™”)"""
        # ìºì‹œì—ì„œ ëª¨ë¸ ë¡œë“œ ë˜ëŠ” ê¸°ì¡´ ë¡œë“œëœ ëª¨ë¸ ì‚¬ìš©
        cache_key = f"yolo_model_cache_{model_id}"
        if cache_key not in st.session_state:
            model_path = model_info['path']
            st.info(f"ğŸ” ëª¨ë¸ ë¡œë“œ ì¤‘: {model_id} from {model_path}")

            # ëª¨ë¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(model_path):
                st.error(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
                # ê¸°ë³¸ ëª¨ë¸ë¡œ ëŒ€ì²´ (YOLOv11n)
                model_path = "models/yolo/v11n/best.pt"
                st.warning(f"âš ï¸ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©: {model_path}")

            # ëª¨ë¸ ì§ì ‘ ë¡œë“œ (ìºì‹œ í•¨ìˆ˜ ëŒ€ì‹ )
            try:
                st.info(f"ğŸ”„ ëª¨ë¸ ë¡œë”© ì‹œë„: {model_path}")
                from ultralytics import YOLO
                model = YOLO(model_path)

                # ëª¨ë¸ ìœ íš¨ì„± í™•ì¸
                if not hasattr(model, 'predict'):
                    st.error(f"âŒ ë¡œë“œëœ ëª¨ë¸ì— predict ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤")
                    return []

                # GPU ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° GPUë¡œ ì´ë™
                if torch.cuda.is_available():
                    model.to('cuda')
                    st.info(f"âœ… ëª¨ë¸ì„ GPUë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤")
                else:
                    st.info(f"â„¹ï¸ CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤")

                # ëª¨ë¸ ì €ì¥ ì „ ìµœì¢… ê²€ì¦
                if model is None or not hasattr(model, 'predict'):
                    st.error(f"âŒ ë¡œë“œëœ ëª¨ë¸ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. íƒ€ì…: {type(model)}")
                    return []

                # ì•ˆì „í•œ ìºì‹œ ì €ì¥
                st.session_state[cache_key] = model
                st.success(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_path}")

            except Exception as e:
                st.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ({model_path}): {e}")
                import traceback
                st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                # ì‹¤íŒ¨ ì‹œ ìºì‹œì— Noneë„ ì €ì¥í•˜ì§€ ì•ŠìŒ
                return []

        model = st.session_state[cache_key]

        # ëª¨ë¸ ìœ íš¨ì„± ê²€ì¦
        if model is None or not hasattr(model, 'predict'):
            st.error(f"âŒ {model_id}: ìœ íš¨í•˜ì§€ ì•Šì€ ëª¨ë¸ì…ë‹ˆë‹¤. ëª¨ë¸ì„ ë‹¤ì‹œ ë¡œë“œí•©ë‹ˆë‹¤.")
            # ìºì‹œì—ì„œ ì œê±°í•˜ê³  ë‹¤ì‹œ ë¡œë“œ ì‹œë„
            if cache_key in st.session_state:
                del st.session_state[cache_key]
            return []

        image = st.session_state.current_image['image']

        # YOLO11-main ì ‘ê·¼ë²• ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        use_yolo11_approach = st.session_state.get('use_yolo11_approach', True)

        if use_yolo11_approach:
            # YOLO11-main ë°©ì‹: ì‚¬ìš©ì ì„¤ì • ì ìš©, ì´ë¯¸ì§€ í¬ê¸° ìµœì í™”
            conf_threshold = st.session_state.get('confidence_threshold', 0.7)
            iou_threshold = st.session_state.get('model_iou_threshold', 0.5)

            # ì´ë¯¸ì§€ í¬ê¸° ìµœì í™” (32ì˜ ë°°ìˆ˜ë¡œ ì¡°ì •)
            height, width = image.shape[:2]
            max_dim = max(width, height)

            # YOLO stride(32)ì˜ ë°°ìˆ˜ë¡œ ì¡°ì •í•˜ì—¬ ê²½ê³  ë°©ì§€
            max_dim = ((max_dim + 31) // 32) * 32

            # ì„ì‹œ ì´ë¯¸ì§€ íŒŒì¼ ì €ì¥ (íŒŒì¼ ê²½ë¡œë¡œ ì „ë‹¬í•˜ê¸° ìœ„í•´)
            import tempfile
            with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp_file:
                cv2.imwrite(tmp_file.name, image)
                temp_image_path = tmp_file.name

            # ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
            st.info(f"ğŸ“Š {model_id} ê²€ì¶œ ì‹œì‘ (YOLO11-main ìµœì í™”)")
            st.write(f"ğŸ”§ ì„¤ì •: ì‹ ë¢°ë„={conf_threshold:.2f}, IoU={iou_threshold:.2f}, imgsz={max_dim}")
            st.write(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ í¬ê¸°: {width}x{height}, ìµœëŒ€ ì°¨ì›: {max_dim}")

            results = model.predict(
                source=temp_image_path,  # íŒŒì¼ ê²½ë¡œ ì‚¬ìš©
                conf=conf_threshold,
                iou=iou_threshold,
                imgsz=1024,  # API ì„œë²„ì™€ ë™ì¼í•œ ìµœì  í¬ê¸°
                device=self.device['device'],
                verbose=False
            )

            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            try:
                os.unlink(temp_image_path)
            except:
                pass

        else:
            # ê¸°ì¡´ DrawingBOMExtractor ë°©ì‹ (ë‚®ì€ confidence)
            conf_threshold = st.session_state.get('model_confidence_threshold', 0.4)
            iou_threshold = st.session_state.get('model_iou_threshold', 0.5)

            # ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
            st.info(f"ğŸ“Š {model_id} ê²€ì¶œ ì‹œì‘ (ê¸°ì¡´ ë°©ì‹)")
            st.write(f"ğŸ”§ ì„¤ì •: ì‹ ë¢°ë„={conf_threshold:.3f}, IoU={iou_threshold:.3f}, ë””ë°”ì´ìŠ¤={self.device['device']}")
            st.write(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ í¬ê¸°: {image.shape if hasattr(image, 'shape') else 'Unknown'}")

            results = model.predict(
                source=image,
                conf=conf_threshold,
                iou=iou_threshold,
                device=self.device['device'],
                verbose=False
            )
        
        # ì›ì‹œ ê²€ì¶œ ê²°ê³¼ ë¡œê¹…
        st.write(f"ğŸ” ì›ì‹œ ê²€ì¶œ ê²°ê³¼ ìˆ˜: {len(results) if results else 0}")
        if results and len(results) > 0:
            result = results[0]
            raw_detections = len(result.boxes) if result.boxes is not None else 0
            st.write(f"ğŸ“¦ ê²€ì¶œëœ ë°•ìŠ¤ ìˆ˜: {raw_detections}")
            if result.boxes is not None and raw_detections > 0:
                raw_confidences = result.boxes.conf.cpu().numpy()
                st.write(f"ğŸ“Š ê²€ì¶œ ì‹ ë¢°ë„ ë²”ìœ„: {raw_confidences.min():.3f} - {raw_confidences.max():.3f}")
        else:
            st.write("âŒ ê²€ì¶œ ê²°ê³¼ ì—†ìŒ")
        
        detections = []
        st.write(f"YOLO ê²€ì¶œ ê²°ê³¼ - ì´ {len(results[0].boxes) if results and len(results) > 0 and results[0].boxes is not None else 0}ê°œ ê°ì²´ ê²€ì¶œ")
        if results and len(results) > 0:
            result = results[0]
            if result.boxes is not None and len(result.boxes) > 0:
                boxes = result.boxes.xyxy.cpu().numpy()
                confidences = result.boxes.conf.cpu().numpy()
                classes = result.boxes.cls.cpu().numpy().astype(int)

                # data.yamlì˜ í´ë˜ìŠ¤ëª… ì‚¬ìš© (YOLO ëª¨ë¸ ë‚´ë¶€ ì´ë¦„ ëŒ€ì‹ )
                if self.data_yaml and 'names' in self.data_yaml:
                    class_names = self.data_yaml['names']
                else:
                    # data.yamlì´ ì—†ìœ¼ë©´ ëª¨ë¸ ë‚´ë¶€ ì´ë¦„ ì‚¬ìš© (fallback)
                    class_names = result.names

                for box, conf, cls in zip(boxes, confidences, classes):
                    x1, y1, x2, y2 = box.astype(int)
                    detection = {
                        'bbox': [x1, y1, x2, y2],
                        'confidence': float(conf),
                        'class_id': cls,
                        'class_name': class_names[cls],
                        'model': model_id
                    }

                    # OCR ê¸°ëŠ¥ ì œê±°ë¨

                    detections.append(detection)

        return detections

    # Detectron2 ê´€ë ¨ í•¨ìˆ˜ ì œê±°ë¨

    def render_detection_results(self):
        """ê²€ì¶œ ê²°ê³¼ í‘œì‹œ"""
        st.header("ğŸ” AI ê²€ì¶œ ê²°ê³¼")

        if not st.session_state.detection_results:
            return

        # Ground Truth ë¼ë²¨ ë¡œë“œ (ìˆëŠ” ê²½ìš°)
        ground_truth = self.load_ground_truth_for_current_image()

        # ê° ëª¨ë¸ë³„ ê²°ê³¼ í‘œì‹œ
        for model_id, detections in st.session_state.detection_results.items():
            # manual ëª¨ë¸ì€ model_registryì— ì—†ìœ¼ë¯€ë¡œ ë³„ë„ ì²˜ë¦¬
            if model_id == 'manual':
                model_info = {
                    'name': 'ìˆ˜ì‘ì—… ë¼ë²¨ë§',
                    'emoji': 'âœï¸',
                    'type': 'MANUAL',
                    'description': 'ì‚¬ìš©ìê°€ ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€í•œ ê²€ì¶œ'
                }
            else:
                model_info = self.model_registry.registry["models"][model_id]

            # F1 ìŠ¤ì½”ì–´ ê³„ì‚° (Ground Truthê°€ ìˆëŠ” ê²½ìš°)
            f1_score = None
            metrics = None
            if ground_truth:
                metrics = self.calculate_detection_metrics(detections, ground_truth)
                f1_score = metrics['f1_score']

            # í™•ì¥ íŒ¨ë„ ì œëª©ì— F1 ìŠ¤ì½”ì–´, ì •ë°€ë„, ì¬í˜„ìœ¨ í¬í•¨
            expander_title = f"ğŸ“Š {model_info['name']} - {len(detections)}ê°œ ê²€ì¶œ"
            if f1_score is not None:
                expander_title += f" (F1: {f1_score:.1%}, ì •ë°€ë„: {metrics['precision']:.1%}, ì¬í˜„ìœ¨: {metrics['recall']:.1%})"

            with st.expander(expander_title, expanded=True):
                if detections or ground_truth:
                    # ë””ë²„ê¹…: Ground Truth ìƒíƒœ í‘œì‹œ
                    if ground_truth:
                        st.info(f"âœ… Ground Truth ë¡œë“œë¨: {len(ground_truth)}ê°œ ë¼ë²¨")
                    else:
                        st.warning("âš ï¸ Ground Truth ì—†ìŒ")

                    # Ground Truthê°€ ìˆìœ¼ë©´ ë¶„ë¦¬ í‘œì‹œ, ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹
                    if ground_truth:
                        # Ground Truthì™€ ì˜ˆì¸¡ì„ ë¶„ë¦¬í•˜ì—¬ í‘œì‹œ
                        col_gt, col_det = st.columns(2)

                        with col_gt:
                            # Ground Truthë§Œ í‘œì‹œ (ì´ˆë¡ìƒ‰, ë‘êº¼ìš´ ì„ )
                            gt_image = self.draw_ground_truth_only(
                                st.session_state.current_image['image'].copy(),
                                ground_truth
                            )
                            gt_width = gt_image.shape[1]
                            gt_display_width = int(gt_width * 0.25)
                            st.image(gt_image, caption=f"ğŸŸ¢ Ground Truth ({len(ground_truth)}ê°œ)", width=gt_display_width)

                        with col_det:
                            # ê²€ì¶œ ê²°ê³¼ë§Œ í‘œì‹œ (ë¹¨ê°„ìƒ‰, ë‘êº¼ìš´ ì„ )
                            det_image = self.draw_detection_results(
                                st.session_state.current_image['image'].copy(),
                                detections,
                                style='simple'
                            )
                            det_width = det_image.shape[1]
                            det_display_width = int(det_width * 0.25)
                            st.image(det_image, caption=f"ğŸ”´ {model_info['name']} ê²€ì¶œ ({len(detections)}ê°œ)", width=det_display_width)
                    else:
                        # ê¸°ì¡´ ë°©ì‹: ë‹¤ì–‘í•œ ìƒ‰ìƒìœ¼ë¡œ í‘œì‹œ
                        result_image = self.draw_detection_results(
                            st.session_state.current_image['image'].copy(),
                            detections
                        )
                        caption = f"{model_info['name']} ê²€ì¶œ ê²°ê³¼"

                        # ê²€ì¶œ ê²°ê³¼ ì´ë¯¸ì§€ë„ 1/4 í¬ê¸°ë¡œ í‘œì‹œ
                        result_width = result_image.shape[1]
                        display_width = int(result_width * 0.25)
                        st.image(result_image, caption=caption, width=display_width)

                    # ê²€ì¶œ í†µê³„ ë° ì •í™•ë„ ë©”íŠ¸ë¦­
                    if f1_score is not None:
                        # Ground Truthê°€ ìˆì„ ë•Œ: 4ê°œ ì»¬ëŸ¼
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("ì´ ê²€ì¶œ ìˆ˜", len(detections))
                        with col2:
                            avg_conf = safe_mean([d['confidence'] for d in detections])
                            st.metric("í‰ê·  ì‹ ë¢°ë„", f"{avg_conf:.3f}")
                        with col3:
                            st.metric("Precision", f"{metrics['precision']:.1%}")
                        with col4:
                            st.metric("Recall", f"{metrics['recall']:.1%}")

                        # F1 ìŠ¤ì½”ì–´ë¥¼ ê°•ì¡° í‘œì‹œ
                        st.success(f"ğŸ¯ F1 Score: {f1_score:.1%} (TP:{metrics['true_positives']}, FP:{metrics['false_positives']}, FN:{metrics['false_negatives']})")
                    else:
                        # Ground Truthê°€ ì—†ì„ ë•Œ: ê¸°ì¡´ì²˜ëŸ¼ 3ê°œ ì»¬ëŸ¼
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ì´ ê²€ì¶œ ìˆ˜", len(detections))
                        with col2:
                            avg_conf = safe_mean([d['confidence'] for d in detections])
                            st.metric("í‰ê·  ì‹ ë¢°ë„", f"{avg_conf:.3f}")
                        with col3:
                            unique_classes = len(set(d['class_name'] for d in detections))
                            st.metric("ê²€ì¶œ í´ë˜ìŠ¤ ìˆ˜", unique_classes)
                else:
                    st.info("ê²€ì¶œëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤.")

    def draw_detection_results(self, image, detections, style='default', thickness=2):
        """í†µí•©ëœ ê²€ì¶œ ê²°ê³¼ ê·¸ë¦¬ê¸° í•¨ìˆ˜ - ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ ì§€ì›"""
        # ìŠ¤íƒ€ì¼ë³„ ìƒ‰ìƒ ì„¤ì •
        if style == 'simple':
            # ê°„ë‹¨í•œ ë¹¨ê°„ìƒ‰ (draw_detections_only ëŒ€ì²´)
            colors = [(0, 0, 255)] * len(detections)
            thickness = 4
        elif style == 'ground_truth':
            # Ground Truthìš© ì´ˆë¡ìƒ‰
            colors = [(0, 255, 0)] * len(detections)
            thickness = 3
        else:
            # ê¸°ë³¸ ë‹¤ì–‘í•œ ìƒ‰ìƒ
            standard_colors = [(0, 0, 255), (0, 50, 255), (50, 50, 255), (0, 100, 255), (100, 0, 255)]

        for i, detection in enumerate(detections):
            x1, y1, x2, y2 = detection['bbox']

            # ìŠ¤íƒ€ì¼ë³„ ìƒ‰ìƒ ë° ë‘ê»˜ ê²°ì •
            if style == 'simple':
                color = colors[0]
                prefix = ""
            elif style == 'ground_truth':
                color = colors[0]
                prefix = "GT: "
            else:
                # ê¸°ë³¸ ìŠ¤íƒ€ì¼
                color = standard_colors[i % len(standard_colors)]
                prefix = ""

            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)

            # ë¼ë²¨ í…ìŠ¤íŠ¸ (ê¸´ í˜•íƒœë¡œ í‘œì‹œí•˜ë˜ í™”ë©´ì—ì„œëŠ” ê°„ë‹¨í•˜ê²Œ)
            confidence_text = f"({detection['confidence']:.2f})" if 'confidence' in detection else ""
            # ì´ë¯¸ì§€ì—ì„œëŠ” ì›ë˜ ì§§ì€ ì´ë¦„ ì‚¬ìš© (ê³µê°„ ì ˆì•½)
            label = f"{prefix}{detection['class_name']} {confidence_text}"

            # ë¼ë²¨ ë°°ê²½ ë° í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
            if style != 'simple':  # simple ìŠ¤íƒ€ì¼ì—ì„œëŠ” ê°„ë‹¨íˆ í‘œì‹œ
                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
                cv2.rectangle(image, (x1, y1-30), (x1+label_size[0], y1), color, -1)
                cv2.putText(image, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            else:
                cv2.putText(image, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

# OCR ê¸°ëŠ¥ ì œê±°ë¨

        return image

    def create_final_verified_image(self, detections, prefix):
        """ìµœì¢… ê²€ì¦ëœ ê²°ê³¼ë¥¼ ì‹œê°í™” (ìŠ¹ì¸/ê±°ë¶€/ìˆ˜ì •/ìˆ˜ì‘ì—… í¬í•¨)"""
        if not st.session_state.get('current_image'):
            return None

        image = st.session_state.current_image['image'].copy()

        # ìƒíƒœë³„ ìƒ‰ìƒ ì •ì˜
        status_colors = {
            'approved': (0, 255, 0),     # ì´ˆë¡ìƒ‰ - ìŠ¹ì¸ë¨
            'rejected': (0, 0, 255),      # ë¹¨ê°„ìƒ‰ - ê±°ë¶€ë¨
            'modified': (255, 165, 0),    # ì£¼í™©ìƒ‰ - ìˆ˜ì •ë¨
            'pending': (128, 128, 128),   # íšŒìƒ‰ - ëŒ€ê¸°ì¤‘
            'manual': (255, 0, 255)       # ë³´ë¼ìƒ‰ - ìˆ˜ì‘ì—…
        }

        # ê° ê²€ì¶œì— ëŒ€í•´ ìƒíƒœì— ë”°ë¥¸ ìƒ‰ìƒìœ¼ë¡œ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        for i, detection in enumerate(detections):
            # ì›ë˜ ì¸ë±ìŠ¤ ì‚¬ìš© (ìˆìœ¼ë©´), ì—†ìœ¼ë©´ í˜„ì¬ ì¸ë±ìŠ¤ ì‚¬ìš©
            original_idx = detection.get('original_index')
            if original_idx is not None:
                status_key = f"{prefix}_{original_idx}"
                display_num = original_idx + 1
            else:
                status_key = f"{prefix}_{i}"
                display_num = i + 1

            current_status = st.session_state.verification_status.get(status_key, "pending")

            # ìˆ˜ì‘ì—… ê²€ì¶œì¸ ê²½ìš° - ìŠ¹ì¸ ìƒíƒœì—¬ë„ ë³´ë¼ìƒ‰ìœ¼ë¡œ í‘œì‹œ
            if detection.get('model_id') == 'manual' or detection.get('model') == 'manual':
                current_status = 'manual'
            # ìˆ˜ì •ëœ ê²½ìš° ìƒíƒœë¥¼ modifiedë¡œ ì„¤ì •
            elif status_key in st.session_state.get('modified_classes', {}):
                current_status = 'modified'

            # ìƒ‰ìƒ ì„ íƒ
            color = status_colors.get(current_status, status_colors['pending'])

            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            bbox = detection.get('bbox', detection.get('box', []))
            if bbox and len(bbox) >= 4:
                x1, y1, x2, y2 = map(int, bbox[:4])

                # ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)

                # ë°•ìŠ¤ ì˜¤ë¥¸ìª½ì— ë²ˆí˜¸ë§Œ í‘œì‹œ
                label = f"{display_num}"
                font_scale = 1.5
                thickness = 3
                label_size, baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)

                label_x = x2 + 10
                label_y = y1 + 30

                # í°ìƒ‰ ë°°ê²½
                cv2.rectangle(image,
                            (label_x - 5, label_y - label_size[1] - 5),
                            (label_x + label_size[0] + 5, label_y + baseline + 5),
                            (255, 255, 255), -1)

                # í…Œë‘ë¦¬
                cv2.rectangle(image,
                            (label_x - 5, label_y - label_size[1] - 5),
                            (label_x + label_size[0] + 5, label_y + baseline + 5),
                            color, 2)

                # ë²ˆí˜¸ í…ìŠ¤íŠ¸
                cv2.putText(image, label, (label_x, label_y),
                           cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness)

        return image

    def load_ground_truth_for_current_image(self):
        """í˜„ì¬ ì´ë¯¸ì§€ì— ëŒ€í•œ Ground Truth ë¼ë²¨ ë¡œë“œ"""
        if not st.session_state.current_image:
            return None

        # ì´ë¯¸ì§€ íŒŒì¼ëª…ì—ì„œ ë¼ë²¨ íŒŒì¼ëª… ì¶”ì¶œ
        image_filename = st.session_state.current_image.get('filename', '')
        if not image_filename:
            return None

        # ë¼ë²¨ íŒŒì¼ ê²½ë¡œ êµ¬ì„±
        label_filename = os.path.splitext(image_filename)[0] + '.txt'
        label_path = os.path.join(self.test_drawings_path, 'labels', label_filename)

        if not os.path.exists(label_path):
            return None

        # YOLO í˜•ì‹ ë¼ë²¨ ë¡œë“œ
        ground_truth = []
        try:
            with open(label_path, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        parts = line.split()
                        if len(parts) >= 5:
                            class_id = int(parts[0])
                            # data.yamlì—ì„œ í´ë˜ìŠ¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
                            class_name = str(class_id)  # ê¸°ë³¸ê°’
                            if self.data_yaml and 'names' in self.data_yaml:
                                class_names = self.data_yaml['names']
                                if class_id < len(class_names):
                                    class_name = class_names[class_id]

                            ground_truth.append({
                                'class_id': class_id,
                                'class_name': class_name,
                                'x_center': float(parts[1]),
                                'y_center': float(parts[2]),
                                'width': float(parts[3]),
                                'height': float(parts[4])
                            })
            return ground_truth if ground_truth else None
        except Exception as e:
            st.warning(f"ë¼ë²¨ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None

    def yolo_to_xyxy(self, x_center, y_center, width, height, img_width, img_height):
        """YOLO í˜•ì‹ì„ xyxy ì¢Œí‘œë¡œ ë³€í™˜ (ë” ì •í™•í•œ ë°˜ì˜¬ë¦¼ ì ìš©)"""
        x_center_abs = x_center * img_width
        y_center_abs = y_center * img_height
        width_abs = width * img_width
        height_abs = height * img_height

        # round()ë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ì •í™•í•œ ì¢Œí‘œ ê³„ì‚°
        x1 = round(x_center_abs - width_abs / 2)
        y1 = round(y_center_abs - height_abs / 2)
        x2 = round(x_center_abs + width_abs / 2)
        y2 = round(y_center_abs + height_abs / 2)

        # ì´ë¯¸ì§€ ê²½ê³„ ë‚´ë¡œ ì œí•œ
        x1 = max(0, min(x1, img_width - 1))
        y1 = max(0, min(y1, img_height - 1))
        x2 = max(0, min(x2, img_width - 1))
        y2 = max(0, min(y2, img_height - 1))

        return x1, y1, x2, y2

    def calculate_detection_metrics(self, predictions, ground_truth, iou_threshold=0.3):
        """ì˜ˆì¸¡ê³¼ Ground Truthë¥¼ ë¹„êµí•˜ì—¬ ì •í™•ë„ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        if not predictions or not ground_truth:
            return {
                'true_positives': 0,
                'false_positives': len(predictions) if predictions else 0,
                'false_negatives': len(ground_truth) if ground_truth else 0,
                'precision': 0.0,
                'recall': 0.0,
                'f1_score': 0.0
            }

        # ì´ë¯¸ì§€ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
        image = st.session_state.current_image.get('image')
        if image is None:
            return {
                'true_positives': 0,
                'false_positives': len(predictions),
                'false_negatives': len(ground_truth),
                'precision': 0.0,
                'recall': 0.0,
                'f1_score': 0.0
            }

        img_height, img_width = image.shape[:2]

        true_positives = 0
        false_positives = len(predictions)
        false_negatives = len(ground_truth)
        matched_gt = set()

        # ê° ì˜ˆì¸¡ì— ëŒ€í•´ ê°€ì¥ ì˜ ë§¤ì¹­ë˜ëŠ” GT ì°¾ê¸°
        for pred in predictions:
            best_iou = 0
            best_gt_idx = -1

            pred_bbox = pred.get('bbox', [0, 0, 0, 0])
            pred_class_id = pred.get('class_id', -1)

            # ëª¨ë“  GTì™€ ë¹„êµ
            for gt_idx, gt in enumerate(ground_truth):
                if gt_idx not in matched_gt:
                    # GT bboxë¥¼ xyxyë¡œ ë³€í™˜
                    gt_bbox = self.yolo_to_xyxy(
                        gt['x_center'], gt['y_center'],
                        gt['width'], gt['height'],
                        img_width, img_height
                    )

                    # IoU ê³„ì‚°
                    iou = self.calculate_iou(pred_bbox, gt_bbox)

                    # ê°™ì€ í´ë˜ìŠ¤ì´ê³  IoUê°€ ë” ë†’ìœ¼ë©´ ì—…ë°ì´íŠ¸
                    if pred_class_id == gt['class_id'] and iou > best_iou:
                        best_iou = iou
                        best_gt_idx = gt_idx

            # IoU ì„ê³„ê°’ì„ ë„˜ê³  ë§¤ì¹­ë˜ë©´ TP
            if best_iou >= iou_threshold and best_gt_idx >= 0:
                true_positives += 1
                matched_gt.add(best_gt_idx)
                false_positives -= 1
                false_negatives -= 1

        # ë©”íŠ¸ë¦­ ê³„ì‚°
        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0
        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

        return {
            'true_positives': true_positives,
            'false_positives': false_positives,
            'false_negatives': false_negatives,
            'precision': precision,
            'recall': recall,
            'f1_score': f1_score
        }

    def calculate_iou(self, box1, box2):
        """ë‘ ë°”ìš´ë”© ë°•ìŠ¤ì˜ IoU(Intersection over Union) ê³„ì‚°"""
        x1 = max(box1[0], box2[0])
        y1 = max(box1[1], box2[1])
        x2 = min(box1[2], box2[2])
        y2 = min(box1[3], box2[3])

        intersection = max(0, x2 - x1) * max(0, y2 - y1)
        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
        union = area1 + area2 - intersection

        return intersection / union if union > 0 else 0

    def remove_duplicate_detections(self, detections, iou_threshold=0.5):
        """ì¤‘ë³µ ê²€ì¶œ ì œê±° (IoU ê¸°ë°˜)"""
        if not detections:
            return []

        # ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)

        unique_detections = []
        for detection in sorted_detections:
            is_duplicate = False
            for unique in unique_detections:
                if self.calculate_iou(detection['bbox'], unique['bbox']) > iou_threshold:
                    # ê°™ì€ í´ë˜ìŠ¤ì¸ ê²½ìš°ë§Œ ì¤‘ë³µìœ¼ë¡œ ì²˜ë¦¬
                    if detection['class_name'] == unique['class_name']:
                        is_duplicate = True
                        break

            if not is_duplicate:
                unique_detections.append(detection)

        return unique_detections

    def remove_duplicate_detections_with_voting(self, detections, iou_threshold=0.5, min_votes=2):
        """Votingê³¼ Weighted Ensembleì„ ì‚¬ìš©í•œ ì¤‘ë³µ ê²€ì¶œ ì œê±°"""
        if not detections:
            return [], {}

        # ê²€ì¶œ ê·¸ë£¹ ìƒì„± (IoU ê¸°ë°˜)
        detection_groups = []
        for detection in detections:
            added_to_group = False
            for group in detection_groups:
                # ê·¸ë£¹ì˜ ì²« ë²ˆì§¸ ê²€ì¶œê³¼ ë¹„êµ
                if self.calculate_iou(detection['bbox'], group[0]['bbox']) > iou_threshold:
                    # ê°™ì€ í´ë˜ìŠ¤ì´ê±°ë‚˜ ë¹„ìŠ·í•œ ìœ„ì¹˜ì¸ ê²½ìš° ê·¸ë£¹ì— ì¶”ê°€
                    group.append(detection)
                    added_to_group = True
                    break

            if not added_to_group:
                detection_groups.append([detection])

        # ê° ê·¸ë£¹ì— ëŒ€í•´ Voting ìˆ˜í–‰
        unique_detections = []
        voting_info = {}

        for group_idx, group in enumerate(detection_groups):
            if len(group) >= min_votes:
                # í´ë˜ìŠ¤ë³„ íˆ¬í‘œ ìˆ˜ ê³„ì‚°
                class_votes = {}
                weighted_scores = {}

                for detection in group:
                    class_name = detection['class_name']
                    model_id = detection.get('model_id', 'unknown')
                    weight = self.model_weights.get(model_id, 1.0)

                    if class_name not in class_votes:
                        class_votes[class_name] = 0
                        weighted_scores[class_name] = 0

                    class_votes[class_name] += 1
                    weighted_scores[class_name] += detection['confidence'] * weight

                # ê°€ì¥ ë§ì€ íˆ¬í‘œë¥¼ ë°›ì€ í´ë˜ìŠ¤ ì„ íƒ
                best_class = max(class_votes.keys(), key=lambda k: (class_votes[k], weighted_scores[k]))

                # í•´ë‹¹ í´ë˜ìŠ¤ì˜ ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ë¥¼ ê°€ì§„ ê²€ì¶œ ì„ íƒ
                best_detection = None
                best_weighted_score = 0

                for detection in group:
                    if detection['class_name'] == best_class:
                        model_id = detection.get('model_id', 'unknown')
                        weight = self.model_weights.get(model_id, 1.0)
                        weighted_score = detection['confidence'] * weight

                        if weighted_score > best_weighted_score:
                            best_weighted_score = weighted_score
                            best_detection = detection.copy()

                if best_detection:
                    # Voting ì •ë³´ ì¶”ê°€
                    best_detection['voting_info'] = {
                        'total_votes': len(group),
                        'class_votes': class_votes,
                        'weighted_scores': weighted_scores,
                        'models_agreed': [d.get('model_id', 'unknown') for d in group]
                    }
                    unique_detections.append(best_detection)
                    voting_info[f"group_{group_idx}"] = best_detection['voting_info']

        return unique_detections, voting_info

    def render_symbol_verification(self):
        """ì‹¬ë³¼ ê²€ì¦ ì„¹ì…˜"""
        _start_total = time.time()
        st.header("âœ… ì‹¬ë³¼ ê²€ì¦ ë° ìˆ˜ì •")

        # ìŠ¹ì¸/ê±°ë¶€ ìƒíƒœ ì´ˆê¸°í™”
        if 'verification_status' not in st.session_state:
            st.session_state.verification_status = {}

        # í¸ì§‘ ìƒíƒœ ì´ˆê¸°í™”
        if 'edit_mode' not in st.session_state:
            st.session_state.edit_mode = {}

        # ìˆ˜ì •ëœ í´ë˜ìŠ¤ ì´ë¦„ ì €ì¥
        if 'modified_classes' not in st.session_state:
            st.session_state.modified_classes = {}

        # ê²€ì¶œ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ë¦¬í„´
        if not st.session_state.detection_results:
            st.info("ê²€ì¶œëœ ì‹¬ë³¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ë©”ì¸ ì»¨í…ì¸ ì™€ ì‚¬ì´ë“œ íŒ¨ë„ë¡œ ë ˆì´ì•„ì›ƒ ë¶„ë¦¬
        main_col, side_panel = st.columns([4, 1])  # 80% ë©”ì¸, 20% ì‚¬ì´ë“œ

        with side_panel:
            # ì‹¬ë³¼ ì°¸ì¡° ë¦¬ìŠ¤íŠ¸ í‘œì‹œ
            self.render_symbol_reference_panel()

        with main_col:
            # í†µí•© ê²°ê³¼ë§Œ í‘œì‹œ (íƒ­ ì œê±°í•˜ì—¬ ë‹¨ìˆœí™”)
            st.subheader("ğŸ“Š í†µí•© ê²°ê³¼ (ì¤‘ë³µ ì œê±°)")

            # ëª¨ë“  ê²€ì¶œ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê¸°
            all_detections = []
            for model_id, detections in st.session_state.detection_results.items():
                for detection in detections:
                    detection_with_model = detection.copy()
                    detection_with_model['model_id'] = model_id
                    all_detections.append(detection_with_model)

            if not all_detections:
                st.info("ê²€ì¶œëœ ì‹¬ë³¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # ì¤‘ë³µ ì œê±°
                unique_detections = self.remove_duplicate_detections(all_detections)

                # í†µê³„ í‘œì‹œ
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ì „ì²´ ê²€ì¶œ", len(all_detections))
                with col2:
                    st.metric("ì¤‘ë³µ ì œê±° í›„", len(unique_detections))
                with col3:
                    if len(all_detections) > 0:
                        st.metric("ì¤‘ë³µë¥ ", f"{((len(all_detections)-len(unique_detections))/len(all_detections)*100):.1f}%")

                st.write(f"ì¤‘ë³µ ì œê±° í›„ {len(unique_detections)}ê°œì˜ ê³ ìœ í•œ ì‹¬ë³¼ì´ ê²€ì¶œë˜ì—ˆìŠµë‹ˆë‹¤:")

                # ì¼ê´„ ì²˜ë¦¬ ë²„íŠ¼
                col1, col2, col3 = st.columns(3)
                with col1:
                    if st.button("ğŸ”˜ ëª¨ë‘ ìŠ¹ì¸", key="approve_all_unified"):
                        for i, detection in enumerate(unique_detections):
                            st.session_state.verification_status[f"unified_{i}"] = "approved"
                        st.success("ëª¨ë“  ê²€ì¶œì´ ìŠ¹ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
                with col2:
                    if st.button("âŒ ëª¨ë‘ ê±°ë¶€", key="reject_all_unified"):
                        for i, detection in enumerate(unique_detections):
                            st.session_state.verification_status[f"unified_{i}"] = "rejected"
                        st.warning("ëª¨ë“  ê²€ì¶œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                with col3:
                    if st.button("ğŸ”„ ìƒíƒœ ì´ˆê¸°í™”", key="reset_status_unified"):
                        # í†µí•© ê²°ê³¼ ìƒíƒœë§Œ ì´ˆê¸°í™”
                        keys_to_remove = [k for k in st.session_state.verification_status.keys() if k.startswith("unified_")]
                        for k in keys_to_remove:
                            del st.session_state.verification_status[k]
                        st.info("ìƒíƒœê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

                # Ground Truthë¥¼ í•œë²ˆë§Œ ë¡œë“œ (ì„±ëŠ¥ ê°œì„ )
                _start_gt = time.time()
                ground_truth = self.load_ground_truth_for_current_image()
                _elapsed_gt = time.time() - _start_gt
                st.write(f"â±ï¸ Ground Truth ë¡œë“œ: {_elapsed_gt:.3f}ì´ˆ")

                # ê²€ì¶œ ê²°ê³¼ í‘œì‹œ
                _start_list = time.time()
                self.render_detection_list(unique_detections, "unified", ground_truth=ground_truth)
                _elapsed_list = time.time() - _start_list
                st.write(f"â±ï¸ ê²€ì¶œ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ë Œë”ë§: {_elapsed_list:.3f}ì´ˆ")

                # ìµœì¢… í†µí•© ì´ë¯¸ì§€ í‘œì‹œ
                st.divider()
                st.subheader("ğŸ–¼ï¸ ìµœì¢… ê²€ì¦ ê²°ê³¼ ì´ë¯¸ì§€")

                # ìŠ¹ì¸ëœ ê²€ì¶œê³¼ ìˆ˜ì‘ì—… ê²€ì¶œë§Œ í•„í„°ë§
                final_detections = []

                # ìŠ¹ì¸/ìˆ˜ì •ëœ ê²€ì¶œ ì¶”ê°€ (ì›ë˜ ì¸ë±ìŠ¤ ì •ë³´ í¬í•¨)
                for i, detection in enumerate(unique_detections):
                    status_key = f"unified_{i}"
                    current_status = st.session_state.verification_status.get(status_key, "pending")

                    # ìŠ¹ì¸ë˜ì—ˆê±°ë‚˜ ìˆ˜ì •ëœ ê²€ì¶œë§Œ í¬í•¨
                    if current_status == "approved" or status_key in st.session_state.get('modified_classes', {}):
                        # ì›ë˜ ì¸ë±ìŠ¤ ì •ë³´ë¥¼ detectionì— ì¶”ê°€
                        detection_with_index = detection.copy()
                        detection_with_index['original_index'] = i
                        final_detections.append(detection_with_index)

                # ìˆ˜ì‘ì—… ê²€ì¶œ ì¶”ê°€
                if 'manual' in st.session_state.detection_results:
                    manual_detections = st.session_state.detection_results['manual']
                    for manual_det in manual_detections:
                        manual_det_copy = manual_det.copy()
                        manual_det_copy['original_index'] = None  # ìˆ˜ì‘ì—…ì€ ì¸ë±ìŠ¤ ì—†ìŒ
                        final_detections.append(manual_det_copy)

                # ê²€ì¶œ ì •ë³´ í‘œì‹œ
                if final_detections:
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        approved_count = sum(1 for i, d in enumerate(unique_detections)
                                           if st.session_state.verification_status.get(f"unified_{i}", "") == "approved")
                        st.metric("âœ… ìŠ¹ì¸ë¨", approved_count)
                    with col2:
                        modified_count = len(st.session_state.get('modified_classes', {}))
                        st.metric("âœï¸ ìˆ˜ì •ë¨", modified_count)
                    with col3:
                        manual_count = len(st.session_state.detection_results.get('manual', []))
                        st.metric("ğŸ¨ ìˆ˜ì‘ì—…", manual_count)

                # ìµœì¢… ì´ë¯¸ì§€ ìƒì„± (ìŠ¹ì¸/ìˆ˜ì •/ìˆ˜ì‘ì—…ë§Œ í‘œì‹œ)
                _start_final = time.time()
                final_image = self.create_final_verified_image(final_detections, "unified")
                _elapsed_final = time.time() - _start_final
                st.write(f"â±ï¸ ìµœì¢… ì´ë¯¸ì§€ ìƒì„±: {_elapsed_final:.3f}ì´ˆ")
                if final_image is not None:
                    # ì´ë¯¸ì§€ì™€ ì‹¬ë³¼ í…Œì´ë¸”ì„ ë‚˜ë€íˆ í‘œì‹œ
                    col_img, col_table = st.columns([3, 1])

                    with col_img:
                        st.image(final_image, caption=f"ìµœì¢… ì„ ì •ëœ ë¶€í’ˆ: ì´ {len(final_detections)}ê°œ | ğŸŸ¢ì´ˆë¡:ìŠ¹ì¸ ğŸŸ£ë³´ë¼:ìˆ˜ì‘ì—… ğŸŸ ì£¼í™©:ìˆ˜ì •")

                    with col_table:
                        st.markdown("### ğŸ“‹ ì‹¬ë³¼ ëª©ë¡")
                        import pandas as pd
                        table_data = []
                        for i, detection in enumerate(final_detections):
                            original_idx = detection.get('original_index')
                            display_num = original_idx + 1 if original_idx is not None else i + 1
                            class_name = detection.get('class_name', '')
                            table_data.append({
                                "ë²ˆí˜¸": display_num,
                                "ì‹¬ë³¼ëª…": class_name
                            })

                        if table_data:
                            df_symbols = pd.DataFrame(table_data)
                            st.dataframe(df_symbols, use_container_width=True, hide_index=True, height=600)
                        else:
                            st.info("ì‹¬ë³¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.info("ê²€ì¶œëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

                _elapsed_total = time.time() - _start_total
                st.write(f"â±ï¸ **ì „ì²´ render_symbol_verification: {_elapsed_total:.3f}ì´ˆ**")


    # Enhanced OCR ë¶„ì„ í•¨ìˆ˜ ì œê±°ë¨

    def render_symbol_reference_panel(self):
        """ì˜¤ë¥¸ìª½ ì‚¬ì´ë“œ íŒ¨ë„ì— ì‹¬ë³¼ ì°¸ì¡° ë¦¬ìŠ¤íŠ¸ í‘œì‹œ"""
        st.markdown("### ğŸ“š ì‹¬ë³¼ ì°¸ì¡°")

        # expanderë¡œ ì ‘ì„ ìˆ˜ ìˆê²Œ í•˜ì—¬ ì„±ëŠ¥ ê°œì„ 
        with st.expander("ìŠ¹ì¸/ê±°ë¶€ ì‹œ ì°¸ê³ ìš© (í´ë¦­í•˜ì—¬ ì—´ê¸°)", expanded=False):
            # class_examples í´ë”ì˜ ëª¨ë“  ì´ë¯¸ì§€ ë¡œë“œ
            import glob
            from PIL import Image
            example_images = glob.glob(os.path.join(self.class_examples_path, "*.jpg"))
            example_images.sort()  # íŒŒì¼ëª… ìˆœìœ¼ë¡œ ì •ë ¬

            if not example_images:
                st.info("ì‹¬ë³¼ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return

            # ìŠ¤í¬ë¡¤ ê°€ëŠ¥í•œ ì»¨í…Œì´ë„ˆ ìƒì„±
            for img_path in example_images:
                filename = os.path.basename(img_path)
                # íŒŒì¼ëª…ì—ì„œ ì •ë³´ ì¶”ì¶œ
                parts = filename.replace('.jpg', '').split('_')
                if len(parts) >= 3:
                    class_idx = parts[0].replace('class_', '')
                    class_nums = parts[1]
                    class_name = '_'.join(parts[2:])

                    # ì´ë¯¸ì§€ ë¡œë“œ ë° ë¦¬ì‚¬ì´ì¦ˆ (ìºì‹± ì‚¬ìš© - ì„±ëŠ¥ ê°œì„ )
                    img_resized = load_and_resize_image_cached(img_path, scale=0.5)

                    if img_resized is not None:
                        # í´ë˜ìŠ¤ ë²ˆí˜¸ì™€ ì´ë¦„ì„ í¬ê²Œ í‘œì‹œ
                        st.markdown(f"**<span style='font-size: 20px;'>{class_idx}</span>**", unsafe_allow_html=True)
                        st.markdown(f"<span style='font-size: 16px;'>{class_name}</span>", unsafe_allow_html=True)

                        # ì´ë¯¸ì§€ í‘œì‹œ (ê³ ì • í¬ê¸°)
                        st.image(img_resized)
                        st.markdown("---")  # êµ¬ë¶„ì„ 
                else:
                    # ì´ë¯¸ì§€ ë¡œë“œ ë° ë¦¬ì‚¬ì´ì¦ˆ (ìºì‹± ì‚¬ìš© - ì„±ëŠ¥ ê°œì„ )
                    img_resized = load_and_resize_image_cached(img_path, scale=0.5)

                    if img_resized is not None:
                        st.image(img_resized, caption=filename)
                        st.markdown("---")

    def get_class_example_image(self, class_name):
        """í´ë˜ìŠ¤ë³„ ì‹¤ì œ ì‹¬ë³¼ ì´ë¯¸ì§€ ì°¾ê¸°

        class_examples í´ë”ì—ì„œ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ì´ë¯¸ì§€ ì°¾ê¸°:
        - íŒ¨í„´: class_XX_YY_CLASS_NAME_*.jpg
        - ì˜ˆ: class_13_24,25_GRAPHIC PANEL_6AV7240-3MC07-0HA0(GP)_p01.jpg
        """
        if not os.path.exists(self.class_examples_path):
            return None

        # í´ë˜ìŠ¤ ì´ë¦„ìœ¼ë¡œ ì§ì ‘ ë§¤ì¹­ ì‹œë„
        import glob

        # íŒŒì¼ëª…ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì²˜ë¦¬
        safe_name = class_name.replace('/', '_').replace('\\', '_').replace(':', '_')

        # ì—¬ëŸ¬ íŒ¨í„´ìœ¼ë¡œ ì‹œë„
        patterns = [
            # ì •í™•í•œ í´ë˜ìŠ¤ ì´ë¦„ ë§¤ì¹­
            f"*_{safe_name}_*.jpg",
            # ë¶€ë¶„ ë§¤ì¹­ (ê³µë°± ì œê±°)
            f"*_{safe_name.replace(' ', '*')}*.jpg",
            # í´ë˜ìŠ¤ ì´ë¦„ì˜ ì¼ë¶€ë§Œ ë§¤ì¹­
            f"*{safe_name.split()[0] if ' ' in safe_name else safe_name}*.jpg"
        ]

        for pattern in patterns:
            matching_files = glob.glob(os.path.join(self.class_examples_path, pattern))
            if matching_files:
                # ì²« ë²ˆì§¸ ë§¤ì¹­ íŒŒì¼ ë°˜í™˜
                return matching_files[0]

        # data.yaml ê¸°ë°˜ ê²€ìƒ‰ (fallback)
        if self.data_yaml:
            class_names = self.data_yaml.get('names', [])
            try:
                class_idx = class_names.index(class_name)
                # ì¸ë±ìŠ¤ ê¸°ë°˜ íŒ¨í„´ìœ¼ë¡œ ê²€ìƒ‰
                pattern = f"class_{class_idx:02d}_*.jpg"
                matching_files = glob.glob(os.path.join(self.class_examples_path, pattern))
                if matching_files:
                    return matching_files[0]
            except (ValueError, IndexError):
                pass

        return None


    def render_detection_list(self, detections, prefix, show_voting=False, ground_truth=None):
        """í†µí•©ëœ ê²€ì¶œ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ í‘œì‹œ (ì •ë‹µ ë¹„êµ ë° Voting ì •ë³´ í¬í•¨)

        Args:
            ground_truth: ë¯¸ë¦¬ ë¡œë“œëœ Ground Truth ë°ì´í„° (ì„±ëŠ¥ ê°œì„ )
        """
        import os  # í•¨ìˆ˜ ë‚´ì—ì„œ ëª…ì‹œì ìœ¼ë¡œ import
        _start_render_list = time.time()
        _iou_time_total = 0
        _widget_time_total = 0

        # í˜ì´ì§€ë„¤ì´ì…˜ ì„¤ì •
        ITEMS_PER_PAGE = 7

        # ì„¸ì…˜ ìƒíƒœì— í˜ì´ì§€ ë²ˆí˜¸ ì´ˆê¸°í™” (prefixë³„ë¡œ ë…ë¦½ì ìœ¼ë¡œ ê´€ë¦¬)
        page_key = f"{prefix}_page"
        if page_key not in st.session_state:
            st.session_state[page_key] = 1

        total_items = len(detections)
        total_pages = max(1, (total_items + ITEMS_PER_PAGE - 1) // ITEMS_PER_PAGE)

        # í˜„ì¬ í˜ì´ì§€ê°€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´ ì¡°ì •
        if st.session_state[page_key] > total_pages:
            st.session_state[page_key] = total_pages
        if st.session_state[page_key] < 1:
            st.session_state[page_key] = 1

        current_page = st.session_state[page_key]
        start_idx = (current_page - 1) * ITEMS_PER_PAGE
        end_idx = min(start_idx + ITEMS_PER_PAGE, total_items)

        # í˜„ì¬ í˜ì´ì§€ì˜ ê²€ì¶œ ê²°ê³¼ë§Œ ì¶”ì¶œ
        page_detections = detections[start_idx:end_idx]

        # ê²€ì¶œ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ í‘œì‹œ
        st.subheader("ğŸ” ê²€ì¶œ ê²°ê³¼" + (" (Voting ì •ë³´ í¬í•¨)" if show_voting else ""))

        # í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë° ë„¤ë¹„ê²Œì´ì…˜
        col_nav1, col_nav2, col_nav3 = st.columns([1, 2, 1])
        with col_nav2:
            st.markdown(f"**ğŸ“„ {current_page} / {total_pages} í˜ì´ì§€** (ì „ì²´ {total_items}ê°œ ì¤‘ {start_idx+1}-{end_idx}ë²ˆì§¸)")

        # ë„¤ë¹„ê²Œì´ì…˜ ë²„íŠ¼
        nav_cols = st.columns([1, 1] + [0.7] * total_pages + [1, 1])

        # ì²˜ìŒ ë²„íŠ¼
        with nav_cols[0]:
            if st.button("â®ï¸ ì²˜ìŒ", key=f"{prefix}_first_page", disabled=(current_page == 1)):
                st.session_state[page_key] = 1
                st.rerun()

        # ì´ì „ ë²„íŠ¼
        with nav_cols[1]:
            if st.button("â—€ï¸ ì´ì „", key=f"{prefix}_prev_page", disabled=(current_page == 1)):
                st.session_state[page_key] -= 1
                st.rerun()

        # í˜ì´ì§€ ë²ˆí˜¸ ë²„íŠ¼ë“¤ (0ë¶€í„° ì‹œì‘í•˜ëŠ” ì¸ë±ìŠ¤)
        for page_num in range(total_pages):
            with nav_cols[2 + page_num]:
                # í˜„ì¬ í˜ì´ì§€ëŠ” disabledë¡œ í‘œì‹œ
                is_current = (page_num + 1 == current_page)
                button_label = f"**{page_num}**" if is_current else str(page_num)
                if st.button(button_label, key=f"{prefix}_page_{page_num}", disabled=is_current):
                    st.session_state[page_key] = page_num + 1
                    st.rerun()

        # ë‹¤ìŒ ë²„íŠ¼
        with nav_cols[-2]:
            if st.button("ë‹¤ìŒ â–¶ï¸", key=f"{prefix}_next_page", disabled=(current_page == total_pages)):
                st.session_state[page_key] += 1
                st.rerun()

        # ë§ˆì§€ë§‰ ë²„íŠ¼
        with nav_cols[-1]:
            if st.button("ë§ˆì§€ë§‰ â­ï¸", key=f"{prefix}_last_page", disabled=(current_page == total_pages)):
                st.session_state[page_key] = total_pages
                st.rerun()

        st.markdown("---")

        # ì´ë¯¸ì§€ í‘œì‹œ ì˜µì…˜ (ì²´í¬ë°•ìŠ¤)
        col_opt1, col_opt2, col_opt3 = st.columns([1, 1, 3])
        with col_opt1:
            show_gt_key = f"{prefix}_show_gt"
            if show_gt_key not in st.session_state:
                st.session_state[show_gt_key] = False
            show_gt_images = st.checkbox("ğŸ·ï¸ Ground Truth ì´ë¯¸ì§€ í‘œì‹œ", value=st.session_state[show_gt_key], key=f"{prefix}_gt_checkbox")
            st.session_state[show_gt_key] = show_gt_images

        with col_opt2:
            show_ref_key = f"{prefix}_show_ref"
            if show_ref_key not in st.session_state:
                st.session_state[show_ref_key] = False
            show_ref_images = st.checkbox("ğŸ“š ì°¸ì¡° ì´ë¯¸ì§€ í‘œì‹œ", value=st.session_state[show_ref_key], key=f"{prefix}_ref_checkbox")
            st.session_state[show_ref_key] = show_ref_images

        st.markdown("---")

        for page_i, detection in enumerate(page_detections):
            # ì›ë˜ ì¸ë±ìŠ¤ ê³„ì‚° (ì „ì²´ ë¦¬ìŠ¤íŠ¸ì—ì„œì˜ ìœ„ì¹˜)
            i = start_idx + page_i
            status_key = f"{prefix}_{i}"
            current_status = st.session_state.verification_status.get(status_key, "pending")

            # ìƒíƒœì— ë”°ë¥¸ ì»¨í…Œì´ë„ˆ ìŠ¤íƒ€ì¼
            if current_status == "approved":
                container_style = "background-color: #d4edda; border: 1px solid #c3e6cb; padding: 10px; border-radius: 5px; margin-bottom: 10px;"
            elif current_status == "rejected":
                container_style = "background-color: #f8d7da; border: 1px solid #f5c6cb; padding: 10px; border-radius: 5px; margin-bottom: 10px;"
            else:
                container_style = "background-color: #f8f9fa; border: 1px solid #dee2e6; padding: 10px; border-radius: 5px; margin-bottom: 10px;"

            with st.container():
                col1, col2, col3, col4 = st.columns([2, 4, 2, 2])

                with col1:
                    # ê²€ì¶œëœ ì´ë¯¸ì§€ì™€ ì •ë‹µ ì´ë¯¸ì§€ë¥¼ ë‚˜ë€íˆ í‘œì‹œ
                    x1, y1, x2, y2 = detection['bbox']
                    image = st.session_state.current_image['image']
                    h, w = image.shape[:2]
                    x1, y1, x2, y2 = max(0, x1), max(0, y1), min(w, x2), min(h, y2)
                    cropped = image[y1:y2, x1:x2]

                    # ì´ë¯¸ì§€ë¥¼ ê°€ë¡œë¡œ í‘œì‹œí•˜ê¸° ìœ„í•œ êµ¬ì¡°
                    st.write("**ğŸ” ê²€ì¶œ ê²°ê³¼**")

                    # ì„¸ ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì¤€ë¹„
                    images_to_show = []
                    captions = []

                    # 1. Ground Truth ì´ë¯¸ì§€ (ë§¤ê°œë³€ìˆ˜ë¡œ ì „ë‹¬ë°›ìŒ - ì„±ëŠ¥ ê°œì„ )
                    # ì²´í¬ë°•ìŠ¤ê°€ í™œì„±í™”ë˜ì–´ ìˆì„ ë•Œë§Œ í‘œì‹œ
                    gt_img = None
                    if show_gt_images and ground_truth:
                        _start_iou = time.time()
                        # í˜„ì¬ ê²€ì¶œ ìœ„ì¹˜ì™€ ê°€ì¥ ê°€ê¹Œìš´ Ground Truth ì°¾ê¸°
                        best_gt = None
                        best_iou = 0
                        # ê²€ì¶œ bboxë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
                        det_bbox = [int(x) for x in detection['bbox']]

                        for gt in ground_truth:
                            gt_bbox = self.yolo_to_xyxy(
                                gt['x_center'], gt['y_center'],
                                gt['width'], gt['height'],
                                w, h
                            )
                            iou = self.calculate_iou(det_bbox, gt_bbox)
                            if iou > best_iou:
                                best_iou = iou
                                best_gt = gt

                        _iou_time_total += (time.time() - _start_iou)

                        # IoU ì„ê³„ê°’ì„ 0.1ë¡œ ë‚®ì¶¤ (10% ì´ìƒ ê²¹ì¹˜ë©´ ë§¤ì¹­)
                        if best_gt and best_iou > 0.1:
                            # Ground Truth ë°•ìŠ¤ ì˜ì—­ crop
                            gt_x1, gt_y1, gt_x2, gt_y2 = self.yolo_to_xyxy(
                                best_gt['x_center'], best_gt['y_center'],
                                best_gt['width'], best_gt['height'],
                                w, h
                            )
                            gt_x1, gt_y1, gt_x2, gt_y2 = max(0, gt_x1), max(0, gt_y1), min(w, gt_x2), min(h, gt_y2)
                            gt_cropped = image[gt_y1:gt_y2, gt_x1:gt_x2]
                            if gt_cropped.size > 0:
                                gt_img = gt_cropped
                                images_to_show.append(gt_cropped)
                                captions.append(f"ğŸ·ï¸ GT: {best_gt['class_name']} (IoU:{best_iou:.2f})")

                        if gt_img is None:
                            # GT ì´ë¯¸ì§€ê°€ ì—†ì„ ë•Œ placeholder
                            import numpy as np
                            placeholder = np.ones((100, 100, 3), dtype=np.uint8) * 200
                            images_to_show.append(placeholder)
                            captions.append("ğŸ·ï¸ GT: ì—†ìŒ")

                    # 2. ëª¨ë¸ ê²€ì¶œ ê²°ê³¼
                    if cropped.size > 0:
                        images_to_show.append(cropped)
                        display_name = self.get_display_class_name(detection['class_name'])
                        captions.append(f"ğŸ” ê²€ì¶œ: {display_name}")
                    else:
                        import numpy as np
                        placeholder = np.ones((100, 100, 3), dtype=np.uint8) * 200
                        images_to_show.append(placeholder)
                        captions.append("ğŸ” ê²€ì¶œ: ì˜¤ë¥˜")

                    # 3. ì‹¤ì œ ì‹¬ë³¼ ì´ë¯¸ì§€ (ìºì‹± ì‚¬ìš© - ì„±ëŠ¥ ê°œì„ )
                    # ì²´í¬ë°•ìŠ¤ê°€ í™œì„±í™”ë˜ì–´ ìˆì„ ë•Œë§Œ í‘œì‹œ
                    if show_ref_images:
                        example_path = self.get_class_example_image(detection['class_name'])
                        if example_path and os.path.exists(example_path):
                            # ìºì‹±ëœ ì´ë¯¸ì§€ ë¡œë“œ ì‚¬ìš©
                            example_np = load_and_resize_image_cached(example_path, scale=1.0)
                            if example_np is not None:
                                images_to_show.append(example_np)
                                display_name = self.get_display_class_name(detection['class_name'])
                                captions.append(f"ğŸ“š ì‹¤ì œ: {display_name}")
                        else:
                            import numpy as np
                            placeholder = np.ones((100, 100, 3), dtype=np.uint8) * 200
                            images_to_show.append(placeholder)
                            captions.append("ğŸ“š ì‹¤ì œ: ì—†ìŒ")

                    # ì´ë¯¸ì§€ë“¤ì„ ê°€ë¡œë¡œ í‘œì‹œ - HTMLê³¼ base64 ì¸ì½”ë”© ì‚¬ìš©
                    import base64
                    from io import BytesIO
                    import numpy as np

                    # HTML êµ¬ì¡°ë¥¼ ë” ì•ˆì •ì ìœ¼ë¡œ êµ¬ì„±
                    html_parts = ['<div style="display: flex; gap: 15px; align-items: center; margin: 10px 0;">']

                    for img, cap in zip(images_to_show, captions):
                        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”© (ìºì‹± ì‚¬ìš© - ì„±ëŠ¥ ê°œì„ )
                        img_base64 = image_to_base64_cached(img)

                        # ê° ì´ë¯¸ì§€ ì•„ì´í…œì„ ë³„ë„ì˜ ë¬¸ìì—´ë¡œ ìƒì„±
                        item_html = (
                            '<div style="text-align: center; flex-shrink: 0;">'
                            f'<img src="data:image/png;base64,{img_base64}" '
                            'style="width: 100px; height: auto; border: 1px solid #ddd; padding: 2px; display: block;">'
                            f'<p style="font-size: 11px; margin-top: 5px; word-wrap: break-word; max-width: 100px;">{cap}</p>'
                            '</div>'
                        )
                        html_parts.append(item_html)

                    html_parts.append('</div>')
                    final_html = ''.join(html_parts)
                    st.markdown(final_html, unsafe_allow_html=True)

                    # ê²€ì¶œ ì •ë³´ í‘œì‹œ
                    st.caption(f"ëª¨ë¸: {detection.get('model', 'ì•Œ ìˆ˜ ì—†ìŒ')}")

                with col2:
                    # í˜„ì¬ í´ë˜ìŠ¤ ì´ë¦„ (ìˆ˜ì •ëœ ê²ƒì´ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©)
                    current_class_name = st.session_state.modified_classes.get(
                        status_key, detection['class_name']
                    )

                    # ê¸´ í˜•íƒœë¡œ í‘œì‹œ
                    display_class_name = self.get_display_class_name(current_class_name)

                    # í•­ìƒ í´ë˜ìŠ¤ ì´ë¦„ í‘œì‹œ
                    st.markdown(f"### {display_class_name}")
                    if current_class_name != detection['class_name']:
                        original_display = self.get_display_class_name(detection['class_name'])
                        st.caption(f"(ì›ë˜: {original_display})")

                    # í¸ì§‘ ëª¨ë“œì¸ì§€ í™•ì¸
                    is_editing = st.session_state.edit_mode.get(status_key, False)

                    # í¸ì§‘ ëª¨ë“œì¼ ë•Œ ë“œë¡­ë‹¤ìš´ í‘œì‹œ (í† ê¸€ í˜•íƒœ)
                    if is_editing:
                        # ì‚¬ìš© ê°€ëŠ¥í•œ í´ë˜ìŠ¤ ëª©ë¡ (class_examples ë””ë ‰í† ë¦¬ ê¸°ë°˜)
                        available_classes = load_class_names_from_examples_cached()
                        if current_class_name not in available_classes:
                            available_classes.append(current_class_name)

                        # ì´ë¯¸ load_class_names_from_examples()ì—ì„œ ì •ë ¬ë¨

                        # ë“œë¡­ë‹¤ìš´ì„ ë°”ë¡œ í‘œì‹œ (on_change ì—†ì´)
                        new_class_name = st.selectbox(
                            "ğŸ”„ ìƒˆ í´ë˜ìŠ¤ ì„ íƒ:",
                            available_classes,
                            index=available_classes.index(current_class_name) if current_class_name in available_classes else 0,
                            key=f"select_new_{prefix}_{i}",
                            help="í´ë˜ìŠ¤ë¥¼ ì„ íƒí•œ í›„ 'ğŸ’¾ ìˆ˜ì • ì™„ë£Œ' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”"
                        )

                        # ì„ íƒëœ ê°’ì„ ì„ì‹œë¡œ ì €ì¥
                        st.session_state[f"temp_class_{status_key}"] = new_class_name

                    # ì •ë³´ë¥¼ ì„¸ë¡œë¡œ ë‚˜ì—´
                    st.write(f"ğŸ“Š **ì‹ ë¢°ë„**: {detection['confidence']:.1%}")
                    model_name = detection.get('model', detection.get('model_id', 'unknown'))
                    st.write(f"ğŸ¤– **ëª¨ë¸**: {model_name}")
                    st.write(f"ğŸ“ **ìœ„ì¹˜**: ({x1}, {y1})")
                    st.write(f"ğŸ“ **í¬ê¸°**: {x2-x1}Ã—{y2-y1}px")


                with col3:
                    # í˜„ì¬ ìƒíƒœ í‘œì‹œ
                    if current_status == "approved":
                        st.success("âœ… ìŠ¹ì¸ë¨")
                    elif current_status == "rejected":
                        st.error("âŒ ê±°ë¶€ë¨")
                    else:
                        st.info("â³ ëŒ€ê¸°ì¤‘")

                with col4:
                    _start_widget = time.time()
                    # ì•¡ì…˜ ë²„íŠ¼
                    is_editing = st.session_state.edit_mode.get(status_key, False)

                    # ëª¨ë“  ë²„íŠ¼ì„ ì„¸ë¡œë¡œ ë°°ì¹˜
                    if st.button("âœ… ìŠ¹ì¸", key=f"approve_{prefix}_{i}",
                                disabled=(current_status=="approved" or is_editing),
                                use_container_width=True):
                        st.session_state.verification_status[status_key] = "approved"
                        # st.rerun() ì œê±° - ìƒíƒœ ë³€ê²½ í›„ ìë™ ì—…ë°ì´íŠ¸

                    if st.button("âŒ ê±°ë¶€", key=f"reject_{prefix}_{i}",
                                disabled=(current_status=="rejected" or is_editing),
                                use_container_width=True):
                        st.session_state.verification_status[status_key] = "rejected"
                        # st.rerun() ì œê±° - ìƒíƒœ ë³€ê²½ í›„ ìë™ ì—…ë°ì´íŠ¸

                    # í† ê¸€ ë°©ì‹ìœ¼ë¡œ ìˆ˜ì • ë²„íŠ¼ ë™ì‘
                    edit_button_label = "ğŸ’¾ ìˆ˜ì • ì™„ë£Œ" if is_editing else "âœï¸ ìˆ˜ì •"
                    edit_button_type = "primary" if is_editing else "secondary"
                    if st.button(edit_button_label, key=f"edit_{prefix}_{i}",
                                use_container_width=True,
                                type=edit_button_type):
                        if is_editing:
                            # ìˆ˜ì • ì™„ë£Œ - ì„ íƒëœ í´ë˜ìŠ¤ ì €ì¥
                            temp_class = st.session_state.get(f"temp_class_{status_key}")
                            if temp_class:
                                st.session_state.modified_classes[status_key] = temp_class
                                # ìˆ˜ì • ì™„ë£Œ ì‹œ ìƒíƒœë¥¼ approvedë¡œ ë³€ê²½
                                st.session_state.verification_status[status_key] = 'approved'
                            st.session_state.edit_mode[status_key] = False
                        else:
                            # ìˆ˜ì • ì‹œì‘
                            st.session_state.edit_mode[status_key] = True
                        # st.rerun() ì œê±° - ìƒíƒœ ë³€ê²½ í›„ ìë™ ì—…ë°ì´íŠ¸

                    _widget_time_total += (time.time() - _start_widget)

        _elapsed_render_list = time.time() - _start_render_list
        st.write(f"  â†³ IoU ë¹„êµ ì‹œê°„: {_iou_time_total:.3f}ì´ˆ")
        st.write(f"  â†³ ìœ„ì ¯ ìƒì„± ì‹œê°„: {_widget_time_total:.3f}ì´ˆ")
        st.write(f"  â†³ ê¸°íƒ€ ì‹œê°„: {_elapsed_render_list - _iou_time_total - _widget_time_total:.3f}ì´ˆ")

        # ìˆ˜ì‘ì—… ë¼ë²¨ë§ ì„¹ì…˜
        st.subheader("ğŸ¨ ìˆ˜ì‘ì—… ë¼ë²¨ë§")
        st.write("ëª¨ë¸ì´ ë†“ì¹œ ë¶€í’ˆì´ ìˆë‹¤ë©´ ë„ë©´ ì´ë¯¸ì§€ ìœ„ì— ì§ì ‘ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë ¤ì„œ ì¶”ê°€í•˜ì„¸ìš”:")

        # ìˆ˜ì‘ì—… ë¼ë²¨ë§ í•­ìƒ í™œì„±í™”
        if True:  # í•­ìƒ í™œì„±í™”
            if not CANVAS_AVAILABLE:
                st.error("âŒ streamlit-drawable-canvasê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                st.code("pip install streamlit-drawable-canvas")
                return

            try:
                # ì´ë¯¸ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
                if not (st.session_state.current_image and 'image' in st.session_state.current_image):
                    st.info("ì´ë¯¸ì§€ë¥¼ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”.")
                    return

                img_array = st.session_state.current_image['image']
                # BGR to RGB ë³€í™˜ (OpenCV ì´ë¯¸ì§€ì¸ ê²½ìš°)
                if len(img_array.shape) == 3 and img_array.shape[2] == 3:
                    img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)

                # ìŠ¹ì¸ëœ ê²€ì¶œ ê²°ê³¼ë¥¼ ë¨¼ì € ì´ë¯¸ì§€ì— ê·¸ë¦¼
                approved_detections = []
                for i, detection in enumerate(detections):
                    status_key = f"{prefix}_{i}"
                    if st.session_state.verification_status.get(status_key) == "approved":
                        approved_detections.append(detection)

                # ìµœì¢… ê²€ì¦ ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ ë°°ê²½ìœ¼ë¡œ ì‚¬ìš© (ìºì‹± ì‚¬ìš© - ì„±ëŠ¥ ê°œì„ )
                # ê²€ì¦ ìƒíƒœ í•´ì‹œ ìƒì„±
                import hashlib
                import json
                status_dict = {f"{prefix}_{i}": st.session_state.verification_status.get(f"{prefix}_{i}", "pending")
                              for i in range(len(detections))}
                verification_status_hash = hashlib.md5(json.dumps(status_dict, sort_keys=True).encode()).hexdigest()

                # ê²€ì¶œ ë°ì´í„° ì¤€ë¹„ (JSON-serializable)
                detections_data = []
                for i, detection in enumerate(detections):
                    status_key = f"{prefix}_{i}"
                    current_status = st.session_state.verification_status.get(status_key, "pending")
                    detections_data.append({
                        'bbox': detection['bbox'],
                        'status': current_status,
                        'class_name': detection['class_name']
                    })

                # ìºì‹±ëœ í•¨ìˆ˜ë¡œ ë°°ê²½ ì´ë¯¸ì§€ ìƒì„±
                background_img = create_background_image_with_boxes_cached(
                    img_array,
                    detections_data,
                    verification_status_hash
                )

                # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (ìº”ë²„ìŠ¤ìš©) - 2ë°° í¬ê¸°ë¡œ í™•ëŒ€
                canvas_height = 1400
                img_height, img_width = background_img.shape[:2]
                aspect_ratio = img_width / img_height
                canvas_width = int(canvas_height * aspect_ratio)

                # ì´ë¯¸ì§€ë¥¼ ìº”ë²„ìŠ¤ í¬ê¸°ì— ë§ê²Œ ë¦¬ì‚¬ì´ì¦ˆ
                img_resized = cv2.resize(background_img, (canvas_width, canvas_height))

                st.markdown("### âœï¸ ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°:")

                # ìˆ˜ì‘ì—… ê²€ì¶œ ì‹œ ì‚¬ìš©í•  í´ë˜ìŠ¤ ì„ íƒ (ìº”ë²„ìŠ¤ ìœ„ì— ìœ„ì¹˜)
                available_classes = load_class_names_from_examples_cached()
                selected_class = st.selectbox(
                    "ğŸ¯ ì¶”ê°€í•  ë¶€í’ˆ ì¢…ë¥˜ë¥¼ ë¨¼ì € ì„ íƒí•˜ì„¸ìš”:",
                    available_classes,
                    key=f"manual_class_{prefix}"
                )
                st.info(f"ì„ íƒëœ ë¶€í’ˆ: **{selected_class}** - ì´ í´ë˜ìŠ¤ë¡œ ë°”ìš´ë”© ë°•ìŠ¤ê°€ ì¶”ê°€ë©ë‹ˆë‹¤")

                st.caption("ğŸ“Œ ë§ˆìš°ìŠ¤ë¡œ ë“œë˜ê·¸í•˜ì—¬ ë¶€í’ˆ ìœ„ì¹˜ì— ë°•ìŠ¤ë¥¼ ê·¸ë ¤ì£¼ì„¸ìš”. ê·¸ë ¤ì§„ ë°•ìŠ¤ì˜ ì¢Œí‘œ ì •ë³´ê°€ ì•„ë˜ì— ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.")

                col1, col2 = st.columns([3, 1])

                with col1:
                    st.caption("â€¢ ğŸŸ¢ ì´ˆë¡ìƒ‰: ìŠ¹ì¸ëœ ë¶€í’ˆ | ğŸ”´ ë¹¨ê°„ìƒ‰: ê±°ë¶€ëœ ë¶€í’ˆ | ğŸŸ¡ ë…¸ë€ìƒ‰: ëŒ€ê¸°ì¤‘")
                    st.caption("â€¢ ğŸ”µ ìƒˆë¡œ ê·¸ë¦¬ëŠ” ë°•ìŠ¤: ì¶”ê°€í•  ë¶€í’ˆ")

                with col2:
                    if st.button("ğŸ—‘ï¸ ëª¨ë“  ë°•ìŠ¤ ì§€ìš°ê¸°", key=f"clear_canvas_{prefix}", use_container_width=True):
                        # ìº”ë²„ìŠ¤ë¥¼ ì´ˆê¸°í™”í•˜ê¸° ìœ„í•´ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
                        canvas_key = f"manual_labeling_canvas_{prefix}"
                        if canvas_key in st.session_state:
                            del st.session_state[canvas_key]
                        # st.rerun() ì œê±° - ìº”ë²„ìŠ¤ ì´ˆê¸°í™” í›„ ìë™ ì—…ë°ì´íŠ¸

                # ìº”ë²„ìŠ¤ ìƒì„± - ë„ë©´ ì´ë¯¸ì§€ì™€ í•¨ê»˜ í‘œì‹œ
                # img_resizedë¥¼ uint8 íƒ€ì…ìœ¼ë¡œ í™•ì‹¤íˆ ë³€í™˜í•˜ê³  RGBë¡œ í™•ì¸
                img_resized_uint8 = img_resized.astype('uint8')

                # RGB ì±„ë„ í™•ì¸ (ê·¸ë ˆì´ìŠ¤ì¼€ì¼ì¸ ê²½ìš° RGBë¡œ ë³€í™˜)
                if len(img_resized_uint8.shape) == 2:
                    img_resized_rgb = cv2.cvtColor(img_resized_uint8, cv2.COLOR_GRAY2RGB)
                elif img_resized_uint8.shape[2] == 3:
                    # BGR to RGB ë³€í™˜ (OpenCVëŠ” BGR ì‚¬ìš©)
                    img_resized_rgb = cv2.cvtColor(img_resized_uint8, cv2.COLOR_BGR2RGB)
                else:
                    img_resized_rgb = img_resized_uint8

                # streamlit-drawable-canvasë¥¼ ì‚¬ìš©í•œ ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                if CANVAS_AVAILABLE and st_canvas:
                    try:
                        # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜ (RGB í˜•ì‹) - ìŠ¹ì¸/ê±°ë¶€ ìƒíƒœê°€ í‘œì‹œëœ ì´ë¯¸ì§€ ì‚¬ìš©
                        pil_img = Image.fromarray(background_img.astype('uint8')).convert('RGB')

                        # ìº”ë²„ìŠ¤ ìƒì„± - PIL ì´ë¯¸ì§€ë¥¼ ë°°ê²½ìœ¼ë¡œ ì‚¬ìš©
                        canvas_result = st_canvas(
                            fill_color="rgba(255, 0, 0, 0.3)",  # ë°˜íˆ¬ëª… ë¹¨ê°„ìƒ‰ ì±„ìš°ê¸°
                            stroke_width=3,
                            stroke_color="#FF0000",  # ë¹¨ê°„ìƒ‰ í…Œë‘ë¦¬
                            background_image=pil_img,  # PIL ì´ë¯¸ì§€ë¥¼ ë°°ê²½ìœ¼ë¡œ
                            update_streamlit=True,  # Streamlit ì—…ë°ì´íŠ¸ í™œì„±í™”
                            height=canvas_height,
                            width=canvas_width,
                            drawing_mode="rect",
                            key=f"manual_labeling_canvas_{prefix}",
                            display_toolbar=True,
                        )

                        # ìˆ˜ì‘ì—…ìœ¼ë¡œ ê·¸ë¦° ë°•ìŠ¤ë“¤ ì²˜ë¦¬
                        if canvas_result and canvas_result.json_data is not None:
                            all_objects = canvas_result.json_data.get("objects", [])
                            if len(all_objects) > 0:
                                # ëª¨ë“  ê°ì²´ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
                                objects_df = pd.json_normalize(all_objects)

                                # ë°•ìŠ¤ ì •ë³´ í‘œì‹œ - ë” ëª…í™•í•˜ê²Œ êµ¬ë¶„
                                st.markdown("---")
                                st.markdown("#### ğŸ“¦ ê·¸ë ¤ì§„ ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ (ì‹¤ì‹œê°„)")
                                st.success(f"âœ… ì´ **{len(objects_df)}ê°œ**ì˜ ë°•ìŠ¤ê°€ ê·¸ë ¤ì¡ŒìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ ê° ë°•ìŠ¤ì˜ ì¢Œí‘œë¥¼ í™•ì¸í•˜ì„¸ìš”.")

                                # ë°•ìŠ¤ ì •ë³´ë¥¼ í…Œì´ë¸”ë¡œ í‘œì‹œ
                                box_data = []
                                for idx, row in objects_df.iterrows():
                                    # ìº”ë²„ìŠ¤ ì¢Œí‘œë¥¼ ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜
                                    scale_x = st.session_state.current_image['image'].shape[1] / canvas_width
                                    scale_y = st.session_state.current_image['image'].shape[0] / canvas_height

                                    x1 = int(row['left'] * scale_x)
                                    y1 = int(row['top'] * scale_y)
                                    x2 = int((row['left'] + row['width']) * scale_x)
                                    y2 = int((row['top'] + row['height']) * scale_y)

                                    # ë°•ìŠ¤ ë„ˆë¹„ì™€ ë†’ì´
                                    width = x2 - x1
                                    height = y2 - y1

                                    box_data.append({
                                        "ë²ˆí˜¸": idx + 1,
                                        "ì‹¬ë³¼ ì¢…ë¥˜": selected_class,
                                        "X": x1,
                                        "Y": y1,
                                        "ë„ˆë¹„(W)": width,
                                        "ë†’ì´(H)": height,
                                        "ì¢Œí‘œ (X1,Y1)-(X2,Y2)": f"({x1},{y1})-({x2},{y2})"
                                    })

                                # ë°•ìŠ¤ ì •ë³´ í…Œì´ë¸” í‘œì‹œ
                                if box_data:
                                    df_boxes = pd.DataFrame(box_data)
                                    st.dataframe(df_boxes, use_container_width=True, hide_index=True)

                                # ìµœì¢… ë°˜ì˜ ë²„íŠ¼ì„ ë” ëª…í™•í•˜ê²Œ í‘œì‹œ
                                st.markdown("---")
                                st.info("ğŸ’¡ ìœ„ í‘œì—ì„œ ì¢Œí‘œë¥¼ í™•ì¸í•œ í›„, ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ 'ğŸ–¼ï¸ ìµœì¢… ê²€ì¦ ê²°ê³¼ ì´ë¯¸ì§€'ì— ë°˜ì˜í•˜ì„¸ìš”.")

                                col1, col2 = st.columns([2, 1])

                                with col1:
                                    if st.button("âœ… ìµœì¢… ê²€ì¦ ê²°ê³¼ì— ë°˜ì˜í•˜ê¸°",
                                                key=f"add_manual_detections_{prefix}",
                                                type="primary",
                                                use_container_width=True,
                                                help="ìœ„ì— ê·¸ë ¤ì§„ ëª¨ë“  ë°•ìŠ¤ë¥¼ ìµœì¢… ê²€ì¦ ê²°ê³¼ì— ì¶”ê°€í•©ë‹ˆë‹¤. ì¶”ê°€ëœ ë°•ìŠ¤ëŠ” 'ğŸ–¼ï¸ ìµœì¢… ê²€ì¦ ê²°ê³¼ ì´ë¯¸ì§€' ì„¹ì…˜ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."):
                                        manual_detections = []

                                        # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
                                        original_img = st.session_state.current_image['image']
                                        orig_height, orig_width = original_img.shape[:2]

                                        # ìŠ¤ì¼€ì¼ë§ íŒ©í„° ê³„ì‚° (ìº”ë²„ìŠ¤ â†’ ì›ë³¸ ì´ë¯¸ì§€)
                                        scale_x = orig_width / canvas_width
                                        scale_y = orig_height / canvas_height

                                        for index, row in objects_df.iterrows():
                                            # ìº”ë²„ìŠ¤ ì¢Œí‘œë¥¼ ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜
                                            left = int(row['left'] * scale_x)
                                            top = int(row['top'] * scale_y)
                                            right = int((row['left'] + row['width']) * scale_x)
                                            bottom = int((row['top'] + row['height']) * scale_y)

                                            # í´ë˜ìŠ¤ ID ì¶”ì¶œ (í´ë˜ìŠ¤ëª…ì˜ ì²« ë²ˆì§¸ ìˆ«ì ë¶€ë¶„)
                                            class_id = 0  # ê¸°ë³¸ê°’
                                            try:
                                                # í´ë˜ìŠ¤ëª…ì—ì„œ ì²« ë²ˆì§¸ ìˆ«ì ì¶”ì¶œ
                                                parts = selected_class.split('_')
                                                if parts and parts[0].replace(',', '').isdigit():
                                                    class_id = int(parts[0].split(',')[0])
                                            except:
                                                class_id = available_classes.index(selected_class) if selected_class in available_classes else 0

                                            # YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                                            manual_det = {
                                                'class_name': selected_class,
                                                'class_id': class_id,
                                                'confidence': 1.0,  # ìˆ˜ì‘ì—…ì€ 100% ì‹ ë¢°ë„
                                                'bbox': [left, top, right, bottom],
                                                'model_id': 'manual',
                                                'model': 'manual'  # render_detection_listì—ì„œ ì‚¬ìš©í•˜ëŠ” í•„ë“œ
                                            }
                                            manual_detections.append(manual_det)

                                        # detection_results['manual']ì— ì¶”ê°€
                                        if manual_detections:
                                            if 'manual' not in st.session_state.detection_results:
                                                st.session_state.detection_results['manual'] = []

                                            # ìˆ˜ì‘ì—… ê²€ì¶œì„ ìŠ¹ì¸ ìƒíƒœë¡œ ìë™ ì„¤ì •
                                            start_idx = len(st.session_state.detection_results.get('manual', []))
                                            for idx, det in enumerate(manual_detections):
                                                status_key = f"manual_{start_idx + idx}"
                                                st.session_state.verification_status[status_key] = "approved"

                                            st.session_state.detection_results['manual'].extend(manual_detections)

                                            st.success(f"âœ… {len(manual_detections)}ê°œì˜ ìˆ˜ì‘ì—… ê²€ì¶œì´ ìµœì¢… ê²€ì¦ ê²°ê³¼ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                            st.info("ğŸ“ ì•„ë˜ 'ğŸ–¼ï¸ ìµœì¢… ê²€ì¦ ê²°ê³¼ ì´ë¯¸ì§€' ì„¹ì…˜ìœ¼ë¡œ ìŠ¤í¬ë¡¤í•˜ì—¬ ì¶”ê°€ëœ ë°•ìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                                            # st.balloons() ì œê±° - ì‚¬ìš©ì ìš”ì²­
                                            # time.sleep(1) ì œê±° - Streamlit running ìƒíƒœ ë°©ì§€
                                            # st.rerun() ì œê±° - BOM ìƒì„± í›„ ìë™ ì—…ë°ì´íŠ¸

                                with col2:
                                    if st.button("ğŸ—‘ï¸ ë°•ìŠ¤ ëª¨ë‘ ì§€ìš°ê¸°",
                                                key=f"clear_all_boxes_{prefix}",
                                                use_container_width=True,
                                                help="í˜„ì¬ ê·¸ë ¤ì§„ ëª¨ë“  ë°•ìŠ¤ë¥¼ ì§€ì›ë‹ˆë‹¤"):
                                        # ìº”ë²„ìŠ¤ë¥¼ ì´ˆê¸°í™”í•˜ê¸° ìœ„í•´ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
                                        canvas_key = f"manual_labeling_canvas_{prefix}"
                                        if canvas_key in st.session_state:
                                            del st.session_state[canvas_key]
                                        # st.rerun() ì œê±° - ìº”ë²„ìŠ¤ ì§€ìš°ê¸° í›„ ìë™ ì—…ë°ì´íŠ¸

                            else:
                                st.info("ğŸ“ ë°•ìŠ¤ë¥¼ ê·¸ë ¤ì£¼ì„¸ìš”. ì„ íƒí•œ ë¶€í’ˆ ì¢…ë¥˜: **" + selected_class + "**")

                    except Exception as e:
                        st.error(f"ìº”ë²„ìŠ¤ ìƒì„± ì˜¤ë¥˜: {str(e)}")
                        st.info("streamlit-drawable-canvas íŒ¨í‚¤ì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

                else:
                    st.error("âŒ streamlit-drawable-canvas ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    st.info("pip install streamlit-drawable-canvasë¥¼ ì‹¤í–‰í•˜ì—¬ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")

            except AttributeError as e:
                if "image_to_url" in str(e):
                    # image_to_url ì—ëŸ¬ - ëŒ€ì²´ ë°©ë²• ì‚¬ìš©
                    st.warning("âš ï¸ ìº”ë²„ìŠ¤ ë°°ê²½ ì´ë¯¸ì§€ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")
                    st.info("ğŸ“Œ ë„ë©´ ì´ë¯¸ì§€ë¥¼ ë³„ë„ë¡œ í‘œì‹œí•©ë‹ˆë‹¤. ì•„ë˜ ìº”ë²„ìŠ¤ì— ë°•ìŠ¤ë¥¼ ê·¸ë ¤ì£¼ì„¸ìš”.")

                    # ìµœì¢… ê²€ì¦ ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ ë¨¼ì € í‘œì‹œ
                    if 'background_img' in locals():
                        # ì´ë¯¸ì§€ë¥¼ ìº”ë²„ìŠ¤ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
                        display_img = cv2.resize(background_img, (700, 700))
                        st.image(display_img, caption="ğŸ“ ìµœì¢… ê²€ì¦ ê²°ê³¼ (ì°¸ê³ ìš©)", use_column_width=False, width=700)

                    # ê°„ë‹¨í•œ ìº”ë²„ìŠ¤ë§Œ ìƒì„±
                    if CANVAS_AVAILABLE and st_canvas:
                        try:
                            canvas_result = st_canvas(
                                fill_color="rgba(255, 0, 0, 0.3)",
                                stroke_width=3,
                                stroke_color="#FF0000",
                                background_color="rgba(255, 255, 255, 0.95)",
                                update_streamlit=False,
                                height=700,
                                width=700,
                                drawing_mode="rect",
                                key=f"manual_labeling_canvas_{prefix}_fallback",
                                display_toolbar=True,
                            )

                            # ìº”ë²„ìŠ¤ ê²°ê³¼ ì²˜ë¦¬ ë¡œì§ì€ ë™ì¼í•˜ê²Œ ìœ ì§€
                            if canvas_result and canvas_result.json_data is not None:
                                # ê¸°ì¡´ ë°•ìŠ¤ ì²˜ë¦¬ ë¡œì§...
                                pass
                        except Exception as canvas_err:
                            st.error(f"ìº”ë²„ìŠ¤ ìƒì„± ì‹¤íŒ¨: {str(canvas_err)}")
                    else:
                        st.error("streamlit-drawable-canvas ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”: pip install streamlit-drawable-canvas")
                else:
                    # ë‹¤ë¥¸ AttributeError
                    st.error(f"ìˆ˜ì‘ì—… ë¼ë²¨ë§ ì˜¤ë¥˜: {str(e)}")
                    import traceback
                    with st.expander("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´"):
                        st.code(traceback.format_exc())
            except Exception as e:
                st.error(f"ìˆ˜ì‘ì—… ë¼ë²¨ë§ ì˜¤ë¥˜: {str(e)}")
                st.info("streamlit-drawable-canvas íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”: pip install streamlit-drawable-canvas")
                import traceback
                with st.expander("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´"):
                    st.code(traceback.format_exc())


    def render_bom_generation(self):
        """BOM ìƒì„± ë° ë‚´ë³´ë‚´ê¸°"""
        st.header("ğŸ“Š BOM ìƒì„± ë° ë‚´ë³´ë‚´ê¸°")

        # ìŠ¹ì¸ëœ ê²€ì¶œ ê²°ê³¼ë§Œ í•„í„°ë§
        approved_detections = []

        # ê²€ì¦ ìƒíƒœ í™•ì¸í•˜ì—¬ ìŠ¹ì¸ëœ ê²€ì¶œë§Œ ìˆ˜ì§‘
        if 'verification_status' in st.session_state:
            # í†µí•© ê²°ê³¼ì—ì„œ ìŠ¹ì¸ëœ ê²ƒë“¤
            for key, status in st.session_state.verification_status.items():
                if status == "approved":
                    # key í˜•ì‹: "unified_0", "voting_1", "model_id_2" ë“±
                    parts = key.split('_')
                    if len(parts) >= 2:
                        prefix = parts[0]
                        index = int(parts[-1])

                        # í•´ë‹¹í•˜ëŠ” ê²€ì¶œ ì°¾ê¸°
                        if prefix == "unified":
                            # í†µí•© ê²°ê³¼ì—ì„œ ì°¾ê¸°
                            all_dets = []
                            for model_id, dets in st.session_state.detection_results.items():
                                for det in dets:
                                    det_copy = det.copy()
                                    det_copy['model_id'] = model_id
                                    all_dets.append(det_copy)
                            unique_dets = self.remove_duplicate_detections(all_dets)
                            if index < len(unique_dets):
                                detection = unique_dets[index].copy()
                                # ìˆ˜ì •ëœ í´ë˜ìŠ¤ ì´ë¦„ì´ ìˆìœ¼ë©´ ì ìš©
                                if key in st.session_state.modified_classes:
                                    detection['class_name'] = st.session_state.modified_classes[key]
                                approved_detections.append(detection)
                        elif prefix == "voting":
                            # Voting ê²°ê³¼ì—ì„œ ì°¾ê¸°
                            all_dets = []
                            for model_id, dets in st.session_state.detection_results.items():
                                for det in dets:
                                    det_copy = det.copy()
                                    det_copy['model_id'] = model_id
                                    all_dets.append(det_copy)
                            voting_dets, _ = self.remove_duplicate_detections_with_voting(all_dets)
                            if index < len(voting_dets):
                                detection = voting_dets[index].copy()
                                # ìˆ˜ì •ëœ í´ë˜ìŠ¤ ì´ë¦„ì´ ìˆìœ¼ë©´ ì ìš©
                                if key in st.session_state.modified_classes:
                                    detection['class_name'] = st.session_state.modified_classes[key]
                                approved_detections.append(detection)
                        elif prefix in st.session_state.detection_results:
                            # ê°œë³„ ëª¨ë¸ ê²°ê³¼ì—ì„œ ì°¾ê¸°
                            model_dets = st.session_state.detection_results[prefix]
                            if index < len(model_dets):
                                detection = model_dets[index].copy()
                                # ìˆ˜ì •ëœ í´ë˜ìŠ¤ ì´ë¦„ì´ ìˆìœ¼ë©´ ì ìš©
                                if key in st.session_state.modified_classes:
                                    detection['class_name'] = st.session_state.modified_classes[key]
                                approved_detections.append(detection)

        # ìŠ¹ì¸ëœ ê²€ì¶œì´ ì—†ìœ¼ë©´ ì „ì²´ ê²€ì¶œ ì‚¬ìš© (ê¸°ë³¸ê°’)
        if not approved_detections:
            st.info("ìŠ¹ì¸ëœ ê²€ì¶œì´ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ ê²€ì¶œ ê²°ê³¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            all_detections = []
            for model_id, detections in st.session_state.detection_results.items():
                all_detections.extend(detections)
            approved_detections = all_detections

        if not approved_detections:
            st.info("BOM ìƒì„±ì„ ìœ„í•œ ê²€ì¶œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # BOM í…Œì´ë¸” ìƒì„±
        bom_data = self.create_bom_table(approved_detections)

        st.subheader("ğŸ“‹ ìƒì„±ëœ BOM")

        # ìŠ¹ì¸ëœ ê²€ì¶œ ìˆ˜ í‘œì‹œ
        st.success(f"âœ… ìŠ¹ì¸ëœ ê²€ì¶œ {len(approved_detections)}ê°œë¡œ BOM ìƒì„±")

        st.dataframe(bom_data)

        # í†µê³„ ì •ë³´
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ì´ ë¶€í’ˆ ìˆ˜", len(bom_data))
        with col2:
            total_cost = bom_data['ì´ ê°€ê²©'].sum()
            st.metric("ì´ ì˜ˆìƒ ë¹„ìš©", f"{total_cost:,}ì›")
        with col3:
            unique_types = len(bom_data['ë¶€í’ˆëª…'].unique())
            st.metric("ë¶€í’ˆ ì¢…ë¥˜", unique_types)
        with col4:
            avg_confidence = safe_mean([d['confidence'] for d in approved_detections])
            st.metric("í‰ê·  ì‹ ë¢°ë„", f"{avg_confidence:.3f}")
        
        # ë‚´ë³´ë‚´ê¸° ì˜µì…˜
        st.subheader("ğŸ“¤ ë‚´ë³´ë‚´ê¸°")
        
        col1, col2 = st.columns(2)
        with col1:
            # Excel ë‚´ë³´ë‚´ê¸°
            excel_data = self.create_excel_export(bom_data)
            st.download_button(
                label="ğŸ“Š Excelë¡œ ë‚´ë³´ë‚´ê¸°",
                data=excel_data,
                file_name=f"BOM_{st.session_state.current_image['filename'].split('.')[0]}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        
        with col2:
            # PDF ë‚´ë³´ë‚´ê¸°
            if st.button("ğŸ“„ PDF ë³´ê³ ì„œ ìƒì„±"):
                pdf_data = self.create_pdf_report(bom_data, all_detections)
                st.download_button(
                    label="ğŸ“„ PDF ë‹¤ìš´ë¡œë“œ",
                    data=pdf_data,
                    file_name=f"BOM_Report_{st.session_state.current_image['filename'].split('.')[0]}.pdf",
                    mime="application/pdf"
                )

    def create_bom_table(self, detections):
        """ê²€ì¶œ ê²°ê³¼ë¡œë¶€í„° BOM í…Œì´ë¸” ìƒì„±"""
        # ë™ì¼ ë¶€í’ˆë³„ë¡œ ì§‘ê³„
        component_counts = {}
        for detection in detections:
            original_class_name = detection['class_name']
            display_class_name = self.get_display_class_name(original_class_name)

            # í‘œì‹œìš© ì´ë¦„ìœ¼ë¡œ ì§‘ê³„í•˜ë˜, ì›ë³¸ í´ë˜ìŠ¤ëª…ë„ ì €ì¥
            if display_class_name in component_counts:
                component_counts[display_class_name]['ìˆ˜ëŸ‰'] += 1
                component_counts[display_class_name]['ì‹ ë¢°ë„ë“¤'].append(detection['confidence'])
            else:
                component_counts[display_class_name] = {
                    'ìˆ˜ëŸ‰': 1,
                    'ì‹ ë¢°ë„ë“¤': [detection['confidence']],
                    'ëª¨ë¸': detection['model'],
                    'ì›ë³¸í´ë˜ìŠ¤ëª…': original_class_name  # ì›ë³¸ í´ë˜ìŠ¤ëª… ì €ì¥
                }
        
        # BOM í…Œì´ë¸” ìƒì„±
        bom_rows = []
        for i, (class_name, info) in enumerate(component_counts.items(), 1):
            # ê°€ê²© ì •ë³´ ì¡°íšŒ
            price_info = self.pricing_data.get(class_name, {})
            unit_price = price_info.get('unit_price', 10000)  # ê¸°ë³¸ê°’
            
            avg_confidence = safe_mean(info['ì‹ ë¢°ë„ë“¤'])
            total_price = unit_price * info['ìˆ˜ëŸ‰']
            
            bom_rows.append({
                'ë²ˆí˜¸': i,
                'ë¶€í’ˆëª…': class_name,
                'ìˆ˜ëŸ‰': info['ìˆ˜ëŸ‰'],
                'ë‹¨ê°€': unit_price,
                'ì´ ê°€ê²©': total_price,
                'í‰ê·  ì‹ ë¢°ë„': round(avg_confidence, 3),
                'ê²€ì¶œ ëª¨ë¸': info['ëª¨ë¸'],
                'ë¹„ê³ ': price_info.get('description', '')
            })
        
        return pd.DataFrame(bom_rows)

    def create_excel_export(self, bom_data):
        """Excel íŒŒì¼ ìƒì„±"""
        import io
        output = io.BytesIO()
        
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            bom_data.to_excel(writer, sheet_name='BOM', index=False)
            
            # ì¶”ê°€ ì •ë³´ ì‹œíŠ¸
            info_data = pd.DataFrame([
                ['ë„ë©´ íŒŒì¼', st.session_state.current_image['filename']],
                ['ìƒì„± ì¼ì‹œ', pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')],
                ['ì‚¬ìš© ëª¨ë¸', ', '.join(st.session_state.selected_models)],
                ['ì´ ë¶€í’ˆ ìˆ˜', len(bom_data)],
                ['ì´ ì˜ˆìƒ ë¹„ìš©', f"{bom_data['ì´ ê°€ê²©'].sum():,}ì›"]
            ], columns=['í•­ëª©', 'ê°’'])
            
            info_data.to_excel(writer, sheet_name='ì •ë³´', index=False)
        
        return output.getvalue()

    def create_pdf_report(self, bom_data, detections):
        """PDF ë³´ê³ ì„œ ìƒì„±"""
        from io import BytesIO
        
        buffer = BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4)
        styles = getSampleStyleSheet()
        story = []
        
        # ì œëª©
        title = Paragraph("AI ê¸°ë°˜ BOM ë¶„ì„ ë³´ê³ ì„œ", styles['Title'])
        story.append(title)
        story.append(Spacer(1, 12))
        
        # ê¸°ë³¸ ì •ë³´
        info_data = [
            ['ë„ë©´ íŒŒì¼', st.session_state.current_image['filename']],
            ['ë¶„ì„ ì¼ì‹œ', pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')],
            ['ì‚¬ìš© ëª¨ë¸', ', '.join(st.session_state.selected_models)],
            ['ì´ ê²€ì¶œ ìˆ˜', str(len(detections))],
            ['ë¶€í’ˆ ì¢…ë¥˜', str(len(bom_data))],
            ['ì´ ì˜ˆìƒ ë¹„ìš©', f"{bom_data['ì´ ê°€ê²©'].sum():,}ì›"]
        ]
        
        info_table = Table(info_data)
        info_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 14),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        
        story.append(info_table)
        story.append(Spacer(1, 12))
        
        # BOM í…Œì´ë¸”
        bom_title = Paragraph("ë¶€í’ˆ ëª©ë¡ (BOM)", styles['Heading2'])
        story.append(bom_title)
        story.append(Spacer(1, 12))
        
        # BOM ë°ì´í„°ë¥¼ í…Œì´ë¸”ë¡œ ë³€í™˜
        bom_table_data = [bom_data.columns.tolist()]
        for _, row in bom_data.iterrows():
            bom_table_data.append(row.tolist())
        
        bom_table = Table(bom_table_data)
        bom_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 10),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        
        story.append(bom_table)
        
        doc.build(story)
        buffer.seek(0)
        return buffer.getvalue()

    def draw_ground_truth_only(self, image, ground_truth):
        """Ground Truthë§Œ í‘œì‹œ (ì´ˆë¡ìƒ‰, ë‘êº¼ìš´ ì„ )"""
        h, w = image.shape[:2]

        for gt in ground_truth:
            # YOLO ì •ê·œí™” ì¢Œí‘œë¥¼ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
            x_center = gt['x_center'] * w
            y_center = gt['y_center'] * h
            width = gt['width'] * w
            height = gt['height'] * h

            x1 = int(x_center - width/2)
            y1 = int(y_center - height/2)
            x2 = int(x_center + width/2)
            y2 = int(y_center + height/2)

            # ì´ˆë¡ìƒ‰ ë‘êº¼ìš´ ë°”ìš´ë”© ë°•ìŠ¤
            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 4)  # ë‘ê»˜ 4

            # í´ë˜ìŠ¤ ID í‘œì‹œ
            label = f"GT_{gt['class_id']}"
            cv2.putText(image, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

        return image


    # OCR ê´€ë ¨ í•¨ìˆ˜ë“¤ ì œê±°ë¨

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    system = SmartBOMSystemV2()
    
    # ì‚¬ì´ë“œë°” ë Œë”ë§
    system.render_sidebar()
    
    # ë©”ì¸ ì›Œí¬í”Œë¡œìš° ë Œë”ë§
    system.render_main_workflow()
    
    # í‘¸í„°
    st.markdown("---")
    st.markdown("**AI ì‹¬ë³¼ ì¸ì‹ ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ BOM ë¶„ì„ ë° ê²¬ì  ìë™í™” ì†”ë£¨ì…˜ v2.0** | Powered by YOLOv11")

if __name__ == "__main__":
    main()