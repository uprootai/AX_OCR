#!/usr/bin/env python3
"""
AI ì‹¬ë³¼ ì¸ì‹ ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ BOM ë¶„ì„ ë° ê²¬ì  ìë™í™” ì†”ë£¨ì…˜ v2.0
ìƒˆë¡œìš´ ìˆœì°¨ì  ì›Œí¬í”Œë¡œìš° ë° ë‹¤ì¤‘ ëª¨ë¸ ì§€ì›
"""

import streamlit as st
import pandas as pd
import json
import os
import glob
from pathlib import Path
import cv2
import numpy as np
# PDF ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import fitz  # PyMuPDF
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False

# OCR ë¼ì´ë¸ŒëŸ¬ë¦¬ (PaddleOCR ìš°ì„ , EasyOCR ë°±ì—…)
try:
    from paddleocr import PaddleOCR
    OCR_AVAILABLE = True
    OCR_TYPE = "PaddleOCR"
except ImportError:
    try:
        import easyocr
        OCR_AVAILABLE = True
        OCR_TYPE = "EasyOCR"
    except ImportError:
        OCR_AVAILABLE = False
        OCR_TYPE = None

# Enhanced OCR Detector v4.0 Rotation (íšŒì „ + ì´ì§„í™” + Super Resolution)
try:
    from enhanced_ocr_v4_rotation import EnhancedOCRDetectorV4
    ENHANCED_OCR_AVAILABLE = True
    OCR_VERSION = "v4.0 Rotation"
except ImportError:
    try:
        from enhanced_ocr_v3_ultimate import EnhancedOCRDetectorV3 as EnhancedOCRDetectorV4
        ENHANCED_OCR_AVAILABLE = True
        OCR_VERSION = "v3.0 Ultimate"
    except ImportError:
        try:
            from enhanced_ocr_v2 import EnhancedOCRDetectorV2 as EnhancedOCRDetectorV4
            ENHANCED_OCR_AVAILABLE = True
            OCR_VERSION = "v2.0"
        except ImportError:
            ENHANCED_OCR_AVAILABLE = False
            OCR_VERSION = None
from PIL import Image
import tempfile
import time
import io
from ultralytics import YOLO
import torch
try:
    from streamlit_drawable_canvas import st_canvas
    CANVAS_AVAILABLE = True
except ImportError as e:
    CANVAS_AVAILABLE = False
    st_canvas = None
    print(f"âš ï¸ streamlit-drawable-canvas import ì‹¤íŒ¨: {e}")
from reportlab.lib.pagesizes import A4
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.lib import colors

# Detectron2 imports (with error handling)
try:
    from detectron2.config import get_cfg
    from detectron2.engine import DefaultPredictor
    from detectron2.data import MetadataCatalog
    DETECTRON2_AVAILABLE = True
except ImportError:
    DETECTRON2_AVAILABLE = False

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ìŠ¤ë§ˆíŠ¸ BOM ë¶„ì„ ì†”ë£¨ì…˜ v2.0",
    page_icon="ğŸ”§",
    layout="wide"
)

# ================ ìºì‹± ìµœì í™” í•¨ìˆ˜ë“¤ ================

@st.cache_data
def load_pricing_data_cached():
    """ê°€ê²© ë°ì´í„° ìºì‹œ ë¡œë“œ"""
    pricing_db_path = "classes_info_with_pricing.json"
    if os.path.exists(pricing_db_path):
        with open(pricing_db_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

@st.cache_data
def load_ground_truth_cached():
    """Ground Truth ë°ì´í„° ìºì‹œ ë¡œë“œ"""
    ground_truth_path = "ocr_ground_truth.json"
    if os.path.exists(ground_truth_path):
        with open(ground_truth_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

@st.cache_data
def load_class_names_from_examples_cached():
    """class_examples ë””ë ‰í† ë¦¬ì—ì„œ í´ë˜ìŠ¤ëª… ì¶”ì¶œ (ìºì‹œë¨)"""
    class_examples_path = "class_examples"
    class_names = []

    if not os.path.exists(class_examples_path):
        return []

    pattern = os.path.join(class_examples_path, "class_*.jpg")
    files = glob.glob(pattern)

    for file_path in files:
        filename = os.path.basename(file_path)
        if filename.startswith("class_") and filename.endswith(".jpg"):
            class_name = filename[6:-4]  # "class_" ì œê±°í•˜ê³  ".jpg" ì œê±°
            class_names.append(class_name)

    return sorted(class_names)

@st.cache_resource
def get_enhanced_ocr_detector():
    """Enhanced OCR Detector ìºì‹œ ë¡œë“œ"""
    try:
        if ENHANCED_OCR_AVAILABLE:
            detector = EnhancedOCRDetectorV4()
            print(f"âœ… Enhanced OCR {OCR_VERSION} ì´ˆê¸°í™” ì™„ë£Œ")
            return detector
        else:
            return None
    except Exception as e:
        st.error(f"Enhanced OCR Detector ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None

@st.cache_resource
def load_yolo_model_cached(model_path: str):
    """YOLO ëª¨ë¸ì„ ìºì‹œëœ ë¦¬ì†ŒìŠ¤ë¡œ ë¡œë“œ"""
    try:
        st.info(f"ğŸ”„ ëª¨ë¸ ë¡œë”© ì‹œë„: {model_path}")

        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(model_path):
            st.error(f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}")
            return None

        model = YOLO(model_path)

        # ëª¨ë¸ ìœ íš¨ì„± í™•ì¸
        if not hasattr(model, 'predict'):
            st.error(f"âŒ ë¡œë“œëœ ëª¨ë¸ì— predict ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤")
            return None

        # GPU ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° GPUë¡œ ì´ë™
        if torch.cuda.is_available():
            model.to('cuda')
            st.info(f"âœ… ëª¨ë¸ì„ GPUë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤")
        else:
            st.info(f"â„¹ï¸ CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤")

        st.success(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_path}")
        return model
    except Exception as e:
        st.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ({model_path}): {e}")
        import traceback
        st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return None

@st.cache_resource
def get_paddleocr_cached():
    """PaddleOCR ìºì‹œ ë¡œë“œ"""
    try:
        if OCR_AVAILABLE and OCR_TYPE == "PaddleOCR":
            use_gpu = torch.cuda.is_available()
            ocr_reader = PaddleOCR(use_angle_cls=True, lang='en', show_log=False, use_gpu=use_gpu)
            return ocr_reader
        return None
    except Exception as e:
        st.error(f"PaddleOCR ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None

def safe_mean(values):
    """ì•ˆì „í•œ í‰ê·  ê³„ì‚° - ë¹ˆ ë°°ì—´ ì²˜ë¦¬"""
    if not values or len(values) == 0:
        return 0.0
    return np.mean(values)

class ModelRegistry:
    """ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, registry_path="models/registry.json"):
        self.registry_path = registry_path
        self.registry = self.load_registry()
    
    def load_registry(self):
        """ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë¡œë“œ"""
        if os.path.exists(self.registry_path):
            with open(self.registry_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {"models": {}, "classes": {}, "metadata": {}}
    
    def get_available_models(self):
        """í™œì„±í™”ëœ ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
        available = {}
        for model_id, model_info in self.registry.get("models", {}).items():
            if model_info.get("active", True):
                # ì‹¤ì œ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                model_path = model_info.get("path", "")
                if self._check_model_exists(model_path, model_info.get("type")):
                    available[model_id] = model_info
        return available
    
    def _check_model_exists(self, path, model_type):
        """ëª¨ë¸ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        if model_type == "YOLO":
            return os.path.exists(path) and path.endswith('.pt')
        elif model_type == "Detectron2":
            # Detectron2ëŠ” ì‹¤ì œ êµ¬í˜„ ì „ê¹Œì§€ ì„ì‹œë¡œ True ë°˜í™˜
            return True  # os.path.isdir(path) and DETECTRON2_AVAILABLE
        return False

class SmartBOMSystemV2:
    """ìƒˆë¡œìš´ ìŠ¤ë§ˆíŠ¸ BOM ì‹œìŠ¤í…œ v2.0"""
    
    def __init__(self):
        self.model_registry = ModelRegistry()
        self.pricing_db_path = "classes_info_with_pricing.json"
        self.test_drawings_path = "test_drawings"
        self.class_examples_path = "class_examples"  # í´ë˜ìŠ¤ë³„ ì˜ˆì‹œ ì´ë¯¸ì§€ ê²½ë¡œ
        self.device = self.setup_device()
        self.loaded_models = {}  # ë¡œë“œëœ ëª¨ë¸ë“¤ì„ ìºì‹œ
        self.pricing_data = load_pricing_data_cached()
        self.data_yaml = self.load_data_yaml()  # YOLO ë°ì´í„°ì…‹ ì •ë³´

        # Enhanced OCR Detector ì´ˆê¸°í™” (ìºì‹œ ê¸°ë°˜)
        self.enhanced_ocr_detector = get_enhanced_ocr_detector()
        if self.enhanced_ocr_detector is not None:
            # ì´ˆê¸°í™” ì„±ê³µ ë©”ì‹œì§€ëŠ” í•œ ë²ˆë§Œ í‘œì‹œ
            if 'enhanced_ocr_init_shown' not in st.session_state:
                st.success("âœ… Enhanced OCR Detector ì´ˆê¸°í™” ì™„ë£Œ (Ground Truth ê¸°ë°˜)")
                st.session_state.enhanced_ocr_init_shown = True

        # ëª¨ë¸ ê°€ì¤‘ì¹˜ (Weighted Ensembleìš©)
        self.model_weights = {
            'yolo_v11l': 1.0,  # YOLOv11L
            'yolo_v11x': 1.2,  # YOLOv11X (ë” í° ëª¨ë¸ì´ë¯€ë¡œ ë” ë†’ì€ ê°€ì¤‘ì¹˜)
            'yolo_v8': 0.9,    # YOLOv8 (ì´ì „ ë²„ì „ì´ë¯€ë¡œ ì•½ê°„ ë‚®ì€ ê°€ì¤‘ì¹˜)
            'detectron2_mask_rcnn': 1.1  # Detectron2 Mask R-CNN
        }
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if 'current_image' not in st.session_state:
            st.session_state.current_image = None
        if 'selected_models' not in st.session_state:
            st.session_state.selected_models = []
        if 'detection_results' not in st.session_state:
            st.session_state.detection_results = {}
        if 'verified_detections' not in st.session_state:
            st.session_state.verified_detections = []
        if 'manual_annotations' not in st.session_state:
            st.session_state.manual_annotations = []

    def setup_device(self):
        """ë””ë°”ì´ìŠ¤ ì„¤ì •"""
        if torch.cuda.is_available():
            device = "cuda"
            device_info = f"GPU: {torch.cuda.get_device_name()}"
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            device_info += f" ({gpu_memory:.1f}GB)"
        else:
            device = "cpu"
            device_info = "CPU: ë©€í‹°ì½”ì–´ ì²˜ë¦¬"
        
        return {"device": device, "info": device_info, "available": torch.cuda.is_available()}

    def load_pricing_data(self):
        """ê°€ê²© ë°ì´í„° ë¡œë“œ"""
        if os.path.exists(self.pricing_db_path):
            with open(self.pricing_db_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}

    def load_class_names_from_examples(self):
        """class_examples ë””ë ‰í† ë¦¬ì—ì„œ í´ë˜ìŠ¤ëª… ì¶”ì¶œ"""
        class_names = []

        if not os.path.exists(self.class_examples_path):
            return []

        # class_examples ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  jpg íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
        pattern = os.path.join(self.class_examples_path, "class_*.jpg")
        files = glob.glob(pattern)

        for file_path in files:
            filename = os.path.basename(file_path)
            # class_[ì •ë ¬ë²ˆí˜¸]_[ì‹¤ì œí´ë˜ìŠ¤ì •ë³´]_p01.jpg íŒ¨í„´ì—ì„œ ì‹¤ì œí´ë˜ìŠ¤ì •ë³´ ì¶”ì¶œ
            # ì˜ˆ: class_00_10_BUZZER_HY-256-2(AC220V)_p01.jpg â†’ 10_BUZZER_HY-256-2(AC220V)

            parts = filename.split('_', 2)  # class, ì •ë ¬ë²ˆí˜¸, ë‚˜ë¨¸ì§€ë¡œ ë¶„ë¦¬
            if len(parts) >= 3:
                # ë‚˜ë¨¸ì§€ ë¶€ë¶„ì—ì„œ _p01.jpg ë˜ëŠ” .jpg ì œê±°
                remaining = parts[2]
                if remaining.endswith('_p01.jpg'):
                    remaining = remaining[:-8]  # _p01.jpg ê¸¸ì´ë§Œí¼ ì œê±°
                elif remaining.endswith('.jpg'):
                    remaining = remaining[:-4]  # .jpg ê¸¸ì´ë§Œí¼ ì œê±°
                class_names.append(remaining)

        # í´ë˜ìŠ¤ëª… ì• ìˆ«ìë¡œ ì •ë ¬
        def get_class_number(class_name):
            parts = class_name.split('_')
            if parts and parts[0].isdigit():
                return int(parts[0])
            # ìˆ«ì,ìˆ«ì í˜•ì‹ ì²˜ë¦¬ (ì˜ˆ: "2,3,4,5_CIRCUIT...")
            if parts and ',' in parts[0]:
                first_num = parts[0].split(',')[0]
                if first_num.isdigit():
                    return int(first_num)
            return 999

        class_names.sort(key=get_class_number)
        return class_names

    def load_data_yaml(self):
        """YOLO data.yaml íŒŒì¼ ë¡œë“œ"""
        data_yaml_path = os.path.join(self.test_drawings_path, 'data.yaml')
        if os.path.exists(data_yaml_path):
            import yaml
            with open(data_yaml_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        return None

    def render_sidebar(self):
        """ì‚¬ì´ë“œë°” ë Œë”ë§"""
        with st.sidebar:
            st.title("ğŸ”§ ì‹œìŠ¤í…œ ì„¤ì •")
            
            # 1. ë°ì´í„° ì…ë ¥ ì„¹ì…˜
            st.header("ğŸ“ ë°ì´í„° ì…ë ¥")
            
            # íŒŒì¼ ì—…ë¡œë“œ
            uploaded_file = st.file_uploader(
                "ë„ë©´ íŒŒì¼ ì—…ë¡œë“œ",
                type=['pdf', 'png', 'jpg', 'jpeg'],
                help="PDF ë˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
            )
            
            # í…ŒìŠ¤íŠ¸ ë„ë©´ ì„ íƒ
            test_files = self.get_test_files()
            if test_files:
                st.write("ë˜ëŠ” í…ŒìŠ¤íŠ¸ ë„ë©´ ì„ íƒ:")
                selected_test = st.selectbox(
                    "í…ŒìŠ¤íŠ¸ ë„ë©´",
                    ["ì„ íƒí•˜ì„¸ìš”..."] + test_files,
                    key="test_drawing_selector"
                )
            else:
                selected_test = None

            # ì´ë¯¸ì§€ ë¡œë“œ ë° ì„¤ì •
            if uploaded_file is not None:
                processed_file = self.process_uploaded_file(uploaded_file)
                if processed_file is not None:
                    st.session_state.current_image = processed_file
                    # ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥ (Enhanced OCR v3.0 Ultimateë¥¼ ìœ„í•´)
                    if isinstance(processed_file, dict) and 'image' in processed_file:
                        st.session_state.original_image = processed_file['image']
                    st.success("âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ")
            elif selected_test and selected_test != "ì„ íƒí•˜ì„¸ìš”...":
                test_image = self.load_test_image(selected_test)
                if test_image is not None:
                    st.session_state.current_image = test_image
                    # ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥ (Enhanced OCR v3.0 Ultimateë¥¼ ìœ„í•´)
                    if isinstance(test_image, dict) and 'image' in test_image:
                        st.session_state.original_image = test_image['image']
                    st.success(f"âœ… {selected_test} ë¡œë“œ ì™„ë£Œ")

            st.divider()

            # 2. ì‹œìŠ¤í…œ ì •ë³´
            st.header("ğŸ–¥ï¸ ì‹œìŠ¤í…œ ì •ë³´")
            st.write(f"**ì²˜ë¦¬ì¥ì¹˜**: {self.device['info']}")
            st.write(f"**ê°€ê²© DB**: {len(self.pricing_data)}ê°œ ë¶€í’ˆ")
            
            if self.device['available']:
                gpu_status = self.get_gpu_status()
                if gpu_status['available']:
                    st.write(f"**GPU ë©”ëª¨ë¦¬**: {gpu_status['memory_used']}MB / {gpu_status['memory_total']}MB")
                    st.progress(gpu_status['memory_percent'] / 100)

            st.divider()

            # 4. ë©”ëª¨ë¦¬ ê´€ë¦¬
            st.header("ğŸ§  ë©”ëª¨ë¦¬ ê´€ë¦¬")
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ—‘ï¸ ìºì‹œ ì •ë¦¬"):
                    self.clear_all_cache()
                    st.success("ëª¨ë“  ìºì‹œ ë° ì„¸ì…˜ ìƒíƒœ ì •ë¦¬ ì™„ë£Œ")
                    st.rerun()
            
            with col2:
                auto_clear = st.checkbox("ìë™ ì •ë¦¬", value=True)

    def get_test_files(self):
        """í…ŒìŠ¤íŠ¸ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        if os.path.exists(self.test_drawings_path):
            files = []
            for file in os.listdir(self.test_drawings_path):
                if file.lower().endswith(('.pdf', '.png', '.jpg', '.jpeg')):
                    files.append(file)
            return sorted(files)
        return []

    def process_uploaded_file(self, uploaded_file):
        """ì—…ë¡œë“œëœ íŒŒì¼ ì²˜ë¦¬"""
        if uploaded_file.type == "application/pdf":
            # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
            if PDF_AVAILABLE:
                try:
                    # PyMuPDF ì‚¬ìš©
                    pdf_bytes = uploaded_file.getvalue()
                    pdf_document = fitz.open(stream=pdf_bytes, filetype="pdf")
                    
                    # ì²« í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
                    page = pdf_document[0]
                    mat = fitz.Matrix(2, 2)  # 200 DPI ìƒë‹¹ì˜ í™•ëŒ€
                    pix = page.get_pixmap(matrix=mat)
                    
                    # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
                    img_data = pix.pil_tobytes(format="PNG")
                    image = Image.open(io.BytesIO(img_data))
                    
                    pdf_document.close()
                    
                    return {"image": np.array(image), "filename": uploaded_file.name, "type": "PDF"}
                except Exception as e:
                    st.error(f"PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    st.info("ì¼ì‹œì ì¸ ì˜¤ë¥˜ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ì´ë¯¸ì§€ íŒŒì¼(JPG, PNG)ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
                    return None
            else:
                st.error("âš ï¸ PDF ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                st.info("ğŸ“‹ í•´ê²° ë°©ë²•:")
                st.code("pip install PyMuPDF pdf2image", language="bash")
                st.info("ğŸ–¼ï¸ ë˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼(JPG, PNG)ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
                return None
        else:
            # ì´ë¯¸ì§€ íŒŒì¼ ì§ì ‘ ë¡œë“œ
            image = Image.open(uploaded_file)
            return {"image": np.array(image), "filename": uploaded_file.name, "type": "Image"}

    def load_test_image(self, filename):
        """í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¡œë“œ"""
        filepath = os.path.join(self.test_drawings_path, filename)
        if filename.lower().endswith('.pdf'):
            if PDF_AVAILABLE:
                try:
                    # PyMuPDF ì‚¬ìš©
                    pdf_document = fitz.open(filepath)
                    
                    # ì²« í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
                    page = pdf_document[0]
                    mat = fitz.Matrix(2, 2)  # 200 DPI ìƒë‹¹ì˜ í™•ëŒ€
                    pix = page.get_pixmap(matrix=mat)
                    
                    # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
                    img_data = pix.pil_tobytes(format="PNG")
                    image = Image.open(io.BytesIO(img_data))
                    
                    pdf_document.close()
                    
                    return {"image": np.array(image), "filename": filename, "type": "PDF"}
                except Exception as e:
                    st.error(f"PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    st.info("ì´ë¯¸ì§€ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    return None
            else:
                st.warning("PDF ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                st.info("ì´ë¯¸ì§€ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                return None
        else:
            image = Image.open(filepath)
            return {"image": np.array(image), "filename": filename, "type": "Image"}

    def get_gpu_status(self):
        """GPU ìƒíƒœ í™•ì¸"""
        try:
            import subprocess
            result = subprocess.run([
                'nvidia-smi', '--query-gpu=memory.used,memory.total,utilization.gpu',
                '--format=csv,noheader,nounits'
            ], capture_output=True, text=True)
            
            if result.returncode == 0:
                gpu_info = result.stdout.strip().split(', ')
                memory_used = int(gpu_info[0])
                memory_total = int(gpu_info[1])
                gpu_util = int(gpu_info[2])
                return {
                    "memory_used": memory_used,
                    "memory_total": memory_total,
                    "memory_percent": (memory_used / memory_total) * 100,
                    "gpu_util": gpu_util,
                    "available": True
                }
        except:
            pass
        return {"available": False}

    def clear_model_cache(self):
        """ëª¨ë¸ ìºì‹œ ì •ë¦¬"""
        self.loaded_models = {}

        # ì„¸ì…˜ ìƒíƒœì—ì„œ ëª¨ë¸ ìºì‹œ ì •ë¦¬ (model_ ì ‘ë‘ì‚¬ë¥¼ ê°€ì§„ í‚¤ë“¤)
        model_keys_to_clear = [key for key in st.session_state.keys() if key.startswith('model_')]
        for key in model_keys_to_clear:
            del st.session_state[key]

        # Streamlit ìì› ìºì‹œ í´ë¦¬ì–´
        st.cache_resource.clear()

        if torch.cuda.is_available():
            torch.cuda.empty_cache()

        st.info("ğŸ§¹ ëª¨ë“  ëª¨ë¸ ìºì‹œê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤")

    def clear_all_cache(self):
        """ëª¨ë“  ìºì‹œ ë° ì„¸ì…˜ ìƒíƒœ ì •ë¦¬"""
        # ëª¨ë¸ ìºì‹œ ì •ë¦¬
        self.clear_model_cache()

        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (í•µì‹¬ ìƒíƒœë“¤ë§Œ)
        session_keys_to_clear = [
            'current_image', 'selected_models', 'detection_results',
            'verified_detections', 'manual_annotations', 'edit_mode',
            'modified_classes', 'temp_class_', 'bom_data', 'bom_generated'
        ]

        for key in list(st.session_state.keys()):
            # temp_class_ë¡œ ì‹œì‘í•˜ëŠ” í‚¤ë“¤ë„ ëª¨ë‘ ì •ë¦¬
            if key.startswith('temp_class_') or key in session_keys_to_clear:
                del st.session_state[key]

    def render_main_workflow(self):
        """ë©”ì¸ ì›Œí¬í”Œë¡œìš° ë Œë”ë§"""
        
        # 1. ë„ë©´ í‘œì‹œ ì„¹ì…˜
        st.title("ğŸ¯ AI ê¸°ë°˜ BOM ì¶”ì¶œ ì›Œí¬í”Œë¡œìš°")
        
        if st.session_state.current_image is not None:
            self.render_drawing_display()
            st.divider()
            
            # 2. AI ëª¨ë¸ ì„ íƒ ì„¹ì…˜
            self.render_model_selection()
            st.divider()
            
            # 3. ê²€ì¶œ ê²°ê³¼ í‘œì‹œ
            if st.session_state.selected_models:
                self.render_detection_results()
                st.divider()
                
                # 4. ì‹¬ë³¼ ê²€ì¦ ì„¹ì…˜
                self.render_symbol_verification()
                st.divider()
                
                # 5. BOM ìƒì„± ë° ë‚´ë³´ë‚´ê¸°
                self.render_bom_generation()
        else:
            st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ ë„ë©´ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ í…ŒìŠ¤íŠ¸ ë„ë©´ì„ ì„ íƒí•˜ì„¸ìš”.")

    def render_drawing_display(self):
        """ì„ íƒëœ ë„ë©´ í‘œì‹œ"""
        st.header("ğŸ“‹ ì„ íƒëœ ë„ë©´")
        
        image_data = st.session_state.current_image
        col1, col2 = st.columns([3, 1])
        
        with col1:
            # ì´ë¯¸ì§€ í¬ê¸°ë¥¼ 1/4ë¡œ ì¤„ì´ê¸° ìœ„í•´ width íŒŒë¼ë¯¸í„° ì‚¬ìš©
            # ì›ë³¸ ì´ë¯¸ì§€ì˜ ë„ˆë¹„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ 25%ë¡œ í‘œì‹œ
            original_width = image_data["image"].shape[1]
            display_width = int(original_width * 0.25)  # 1/4 í¬ê¸°
            st.image(image_data["image"], caption=f"ğŸ“„ {image_data['filename']}", width=display_width)
        
        with col2:
            st.subheader("ğŸ“Š ë„ë©´ ì •ë³´")
            height, width = image_data["image"].shape[:2]
            st.write(f"**íŒŒì¼ëª…**: {image_data['filename']}")
            st.write(f"**í˜•ì‹**: {image_data['type']}")
            st.write(f"**í•´ìƒë„**: {width} Ã— {height} px")
            st.write(f"**ì¢…íš¡ë¹„**: {width/height:.2f}")
            
            # í•´ìƒë„ ê²½ê³ 
            if width < 2000 or height < 2000:
                st.warning("âš ï¸ ë‚®ì€ í•´ìƒë„ë¡œ ì¸í•´ ê²€ì¶œ ì„±ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                st.success("âœ… ê³ í•´ìƒë„ ì´ë¯¸ì§€ë¡œ ìµœì ì˜ ê²€ì¶œ ì„±ëŠ¥ ê¸°ëŒ€")

    def render_model_selection(self):
        """AI ëª¨ë¸ ì„ íƒ ì„¹ì…˜"""
        st.header("ğŸ¤– AI ëª¨ë¸ ì„ íƒ")

        available_models = self.model_registry.get_available_models()

        if not available_models:
            st.error("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        # YOLOv11X ëª¨ë¸ë§Œ ì‚¬ìš©
        yolo_v11x_id = 'yolo_v11x'

        if yolo_v11x_id in available_models:
            # YOLOv11Xë¥¼ ìë™ìœ¼ë¡œ ì„ íƒëœ ëª¨ë¸ ëª©ë¡ì— ì¶”ê°€
            selected_models = [yolo_v11x_id]
            st.session_state.selected_models = selected_models

            # ê²€ì¶œ ì„¤ì • í‘œì‹œ
            st.divider()

            # ê²€ì¶œ ì„¤ì • í—¤ë”ì— ë„ì›€ë§ ì¶”ê°€
            col_header, col_info = st.columns([2, 3])
            with col_header:
                st.subheader("ğŸ¯ ê²€ì¶œ ì„¤ì •")

            # YOLOv11X ìµœì í™” ì„¤ì •
            st.success("âœ… YOLOv11X ìµœì í™” í™œì„±í™”ë¨")
            st.session_state['use_yolo11_approach'] = True  # YOLOv11XëŠ” í•­ìƒ ìµœì í™” ëª¨ë“œ ì‚¬ìš©

            # íŒŒë¼ë¯¸í„° ì¡°ì •
            col1, col2 = st.columns(2)
            with col1:
                confidence_threshold = st.slider(
                    "ì‹ ë¢°ë„ ì„ê³„ê°’",
                    min_value=0.3,
                    max_value=1.0,
                    value=st.session_state.get('confidence_threshold', 0.7),
                    step=0.05,
                    key="yolo11_confidence_threshold",
                    help="YOLOv11X ëª¨ë¸ì—ì„œëŠ” 0.8 ì´ìƒ ê¶Œì¥"
                )
            with col2:
                iou_threshold = st.slider(
                    "IoU ì„ê³„ê°’",
                    min_value=0.1,
                    max_value=0.8,
                    value=st.session_state.get('model_iou_threshold', 0.45),
                    step=0.05,
                    key="yolo11_iou_threshold",
                    help="ë‚®ì„ìˆ˜ë¡ ë” ê´€ëŒ€í•œ ë§¤ì¹­"
                )
            st.session_state.confidence_threshold = confidence_threshold
            st.session_state['model_iou_threshold'] = iou_threshold
            st.session_state.iou_threshold = iou_threshold

            col1, col2, col3 = st.columns([1, 1, 2])
            with col1:
                if st.button("ğŸš€ ê²€ì¶œ ì‹œì‘", type="primary"):
                    self.run_detection()
            with col2:
                st.empty()  # ë¹ˆ ê³µê°„ ìœ ì§€
                    
        else:
            st.error("âš ï¸ YOLOv11X ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

    def run_detection(self):
        """ì„ íƒëœ ëª¨ë¸ë“¤ë¡œ ê²€ì¶œ ì‹¤í–‰"""
        if not st.session_state.current_image or not st.session_state.selected_models:
            return
            
        progress_bar = st.progress(0)
        status_text = st.empty()

        # OCR ë¶„ì„ ê²°ê³¼ ì´ˆê¸°í™”
        if 'ocr_analysis_results' not in st.session_state:
            st.session_state.ocr_analysis_results = []
        else:
            st.session_state.ocr_analysis_results.clear()

        results = {}
        total_models = len(st.session_state.selected_models)
        
        for i, model_id in enumerate(st.session_state.selected_models):
            status_text.text(f"ê²€ì¶œ ì¤‘: {model_id} ({i+1}/{total_models})")
            progress_bar.progress((i+1) / total_models)
            
            # ëª¨ë¸ ë¡œë“œ ë° ì‹¤í–‰
            # manual ëª¨ë¸ì€ model_registryì— ì—†ìœ¼ë¯€ë¡œ ë³„ë„ ì²˜ë¦¬
            if model_id == 'manual':
                model_info = {
                    'name': 'ìˆ˜ì‘ì—… ë¼ë²¨ë§',
                    'emoji': 'âœï¸',
                    'type': 'MANUAL',
                    'description': 'ì‚¬ìš©ìê°€ ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€í•œ ê²€ì¶œ'
                }
            else:
                model_info = self.model_registry.registry["models"][model_id]
            detections = self.detect_with_model(model_id, model_info)
            results[model_id] = detections
            
            time.sleep(0.5)  # ì‚¬ìš©ì ê²½í—˜ì„ ìœ„í•œ ì•½ê°„ì˜ ì§€ì—°
        
        # OCR ê¸°ëŠ¥ ì œê±° - ë°”ë¡œ ê²°ê³¼ ì €ì¥
        st.session_state.detection_results = results
        status_text.text("âœ… ëª¨ë“  ëª¨ë¸ ê²€ì¶œ ì™„ë£Œ!")

        time.sleep(1)
        status_text.empty()
        progress_bar.empty()
        st.rerun()

    def detect_with_model(self, model_id, model_info):
        """íŠ¹ì • ëª¨ë¸ë¡œ ê²€ì¶œ ìˆ˜í–‰"""
        try:
            if model_info['type'] == 'YOLO':
                return self._detect_with_yolo(model_id, model_info)
            elif model_info['type'] == 'Detectron2':
                return self._detect_with_detectron2(model_id, model_info)
        except Exception as e:
            st.error(f"âŒ {model_id} ê²€ì¶œ ì‹¤íŒ¨: {str(e)}")
            return []

    def _detect_with_yolo(self, model_id, model_info):
        """YOLO ëª¨ë¸ ê²€ì¶œ - YOLO11-main ì ‘ê·¼ë²• ì ìš© (ìºì‹œ ìµœì í™”)"""
        # ìºì‹œì—ì„œ ëª¨ë¸ ë¡œë“œ ë˜ëŠ” ê¸°ì¡´ ë¡œë“œëœ ëª¨ë¸ ì‚¬ìš©
        cache_key = f"yolo_model_cache_{model_id}"
        if cache_key not in st.session_state:
            model_path = model_info['path']
            st.info(f"ğŸ” ëª¨ë¸ ë¡œë“œ ì¤‘: {model_id} from {model_path}")

            # ëª¨ë¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(model_path):
                st.error(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
                # ê¸°ë³¸ ëª¨ë¸ë¡œ ëŒ€ì²´
                model_path = "models/yolo/best.pt"
                st.warning(f"âš ï¸ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©: {model_path}")

            # ëª¨ë¸ ì§ì ‘ ë¡œë“œ (ìºì‹œ í•¨ìˆ˜ ëŒ€ì‹ )
            try:
                st.info(f"ğŸ”„ ëª¨ë¸ ë¡œë”© ì‹œë„: {model_path}")
                from ultralytics import YOLO
                model = YOLO(model_path)

                # ëª¨ë¸ ìœ íš¨ì„± í™•ì¸
                if not hasattr(model, 'predict'):
                    st.error(f"âŒ ë¡œë“œëœ ëª¨ë¸ì— predict ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤")
                    return []

                # GPU ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° GPUë¡œ ì´ë™
                if torch.cuda.is_available():
                    model.to('cuda')
                    st.info(f"âœ… ëª¨ë¸ì„ GPUë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤")
                else:
                    st.info(f"â„¹ï¸ CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤")

                # ëª¨ë¸ ì €ì¥ ì „ ìµœì¢… ê²€ì¦
                if model is None or not hasattr(model, 'predict'):
                    st.error(f"âŒ ë¡œë“œëœ ëª¨ë¸ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. íƒ€ì…: {type(model)}")
                    return []

                # ì•ˆì „í•œ ìºì‹œ ì €ì¥
                st.session_state[cache_key] = model
                st.success(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_path}")

            except Exception as e:
                st.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ({model_path}): {e}")
                import traceback
                st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                # ì‹¤íŒ¨ ì‹œ ìºì‹œì— Noneë„ ì €ì¥í•˜ì§€ ì•ŠìŒ
                return []

        model = st.session_state[cache_key]

        # ëª¨ë¸ ìœ íš¨ì„± ê²€ì¦
        if model is None or not hasattr(model, 'predict'):
            st.error(f"âŒ {model_id}: ìœ íš¨í•˜ì§€ ì•Šì€ ëª¨ë¸ì…ë‹ˆë‹¤. ëª¨ë¸ì„ ë‹¤ì‹œ ë¡œë“œí•©ë‹ˆë‹¤.")
            # ìºì‹œì—ì„œ ì œê±°í•˜ê³  ë‹¤ì‹œ ë¡œë“œ ì‹œë„
            if cache_key in st.session_state:
                del st.session_state[cache_key]
            return []

        image = st.session_state.current_image['image']

        # YOLO11-main ì ‘ê·¼ë²• ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        use_yolo11_approach = st.session_state.get('use_yolo11_approach', True)

        if use_yolo11_approach:
            # YOLO11-main ë°©ì‹: ì‚¬ìš©ì ì„¤ì • ì ìš©, ì´ë¯¸ì§€ í¬ê¸° ìµœì í™”
            conf_threshold = st.session_state.get('confidence_threshold', 0.7)
            iou_threshold = st.session_state.get('model_iou_threshold', 0.45)

            # ì´ë¯¸ì§€ í¬ê¸° ìµœì í™” (32ì˜ ë°°ìˆ˜ë¡œ ì¡°ì •)
            height, width = image.shape[:2]
            max_dim = max(width, height)

            # YOLO stride(32)ì˜ ë°°ìˆ˜ë¡œ ì¡°ì •í•˜ì—¬ ê²½ê³  ë°©ì§€
            max_dim = ((max_dim + 31) // 32) * 32

            # ì„ì‹œ ì´ë¯¸ì§€ íŒŒì¼ ì €ì¥ (íŒŒì¼ ê²½ë¡œë¡œ ì „ë‹¬í•˜ê¸° ìœ„í•´)
            import tempfile
            with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp_file:
                cv2.imwrite(tmp_file.name, image)
                temp_image_path = tmp_file.name

            # ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
            st.info(f"ğŸ“Š {model_id} ê²€ì¶œ ì‹œì‘ (YOLO11-main ìµœì í™”)")
            st.write(f"ğŸ”§ ì„¤ì •: ì‹ ë¢°ë„={conf_threshold:.2f}, IoU={iou_threshold:.2f}, imgsz={max_dim}")
            st.write(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ í¬ê¸°: {width}x{height}, ìµœëŒ€ ì°¨ì›: {max_dim}")

            results = model.predict(
                source=temp_image_path,  # íŒŒì¼ ê²½ë¡œ ì‚¬ìš©
                conf=conf_threshold,
                iou=iou_threshold,
                imgsz=max_dim,  # ì´ë¯¸ì§€ í¬ê¸° ì„¤ì •
                device=self.device['device'],
                verbose=False,
                save=False
            )

            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            try:
                os.unlink(temp_image_path)
            except:
                pass

        else:
            # ê¸°ì¡´ DrawingBOMExtractor ë°©ì‹ (ë‚®ì€ confidence)
            conf_threshold = st.session_state.get('model_confidence_threshold', 0.25)
            iou_threshold = st.session_state.get('model_iou_threshold', 0.45)

            # ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
            st.info(f"ğŸ“Š {model_id} ê²€ì¶œ ì‹œì‘ (ê¸°ì¡´ ë°©ì‹)")
            st.write(f"ğŸ”§ ì„¤ì •: ì‹ ë¢°ë„={conf_threshold:.3f}, IoU={iou_threshold:.3f}, ë””ë°”ì´ìŠ¤={self.device['device']}")
            st.write(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ í¬ê¸°: {image.shape if hasattr(image, 'shape') else 'Unknown'}")

            results = model.predict(
                source=image,
                conf=conf_threshold,
                iou=iou_threshold,
                device=self.device['device'],
                verbose=False
            )
        
        # ì›ì‹œ ê²€ì¶œ ê²°ê³¼ ë¡œê¹…
        st.write(f"ğŸ” ì›ì‹œ ê²€ì¶œ ê²°ê³¼ ìˆ˜: {len(results) if results else 0}")
        if results and len(results) > 0:
            result = results[0]
            raw_detections = len(result.boxes) if result.boxes is not None else 0
            st.write(f"ğŸ“¦ ê²€ì¶œëœ ë°•ìŠ¤ ìˆ˜: {raw_detections}")
            if result.boxes is not None and raw_detections > 0:
                raw_confidences = result.boxes.conf.cpu().numpy()
                st.write(f"ğŸ“Š ê²€ì¶œ ì‹ ë¢°ë„ ë²”ìœ„: {raw_confidences.min():.3f} - {raw_confidences.max():.3f}")
        else:
            st.write("âŒ ê²€ì¶œ ê²°ê³¼ ì—†ìŒ")
        
        detections = []
        st.write(f"YOLO ê²€ì¶œ ê²°ê³¼ - ì´ {len(results[0].boxes) if results and len(results) > 0 and results[0].boxes is not None else 0}ê°œ ê°ì²´ ê²€ì¶œ")
        if results and len(results) > 0:
            result = results[0]
            if result.boxes is not None and len(result.boxes) > 0:
                boxes = result.boxes.xyxy.cpu().numpy()
                confidences = result.boxes.conf.cpu().numpy()
                classes = result.boxes.cls.cpu().numpy().astype(int)
                class_names = result.names
                
                for box, conf, cls in zip(boxes, confidences, classes):
                    x1, y1, x2, y2 = box.astype(int)
                    detection = {
                        'bbox': [x1, y1, x2, y2],
                        'confidence': float(conf),
                        'class_id': cls,
                        'class_name': class_names[cls],
                        'model': model_id
                    }

                    # OCR í–¥ìƒ ì ìš© (ì˜µì…˜)
                    if st.session_state.get('use_ocr_enhancement', True) and OCR_AVAILABLE:
                        detection = self.enhance_detection_with_ocr(image, detection)

                    detections.append(detection)
        
        return detections

    def _detect_with_detectron2(self, model_id, model_info):
        """Detectron2 ëª¨ë¸ ê²€ì¶œ"""
        try:
            # Detectron2 import ì‹œë„
            from detectron2.config import get_cfg
            from detectron2.engine import DefaultPredictor
            from detectron2.data import MetadataCatalog
            from detectron2 import model_zoo
            
            st.info(f"â„¹ï¸ {model_id}: Detectron2 ëª¨ë¸ ë¡œë”© ì¤‘...")
            
            # Detectron2 ëª¨ë¸ ê²½ë¡œ
            detectron2_path = model_info['path']
            
            if not os.path.exists(detectron2_path):
                st.warning(f"âš ï¸ Detectron2 ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. YOLOë¡œ ëŒ€ì²´ ì‹¤í–‰í•©ë‹ˆë‹¤.")
                return self._fallback_to_yolo(model_id)
                
            # Detectron2 ì„¤ì •
            if model_id not in self.loaded_models:
                cfg = get_cfg()
                cfg.merge_from_file(model_zoo.get_config_file("COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml"))
                cfg.MODEL.ROI_HEADS.NUM_CLASSES = 27  # 27ê°œ í´ë˜ìŠ¤
                cfg.MODEL.WEIGHTS = detectron2_path
                cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = st.session_state.get('confidence_threshold', 0.25)
                cfg.MODEL.DEVICE = self.device['device']
                
                predictor = DefaultPredictor(cfg)
                self.loaded_models[model_id] = predictor
            
            predictor = self.loaded_models[model_id]
            image = st.session_state.current_image['image']
            
            # Detectron2 ì˜ˆì¸¡
            outputs = predictor(image)
            
            detections = []
            instances = outputs["instances"].to("cpu")
            boxes = instances.pred_boxes.tensor.numpy()
            scores = instances.scores.numpy()
            classes = instances.pred_classes.numpy()
            
            for box, score, cls in zip(boxes, scores, classes):
                x1, y1, x2, y2 = box.tolist()
                # data.yamlì˜ í´ë˜ìŠ¤ ì´ë¦„ ì‚¬ìš© (ìˆìœ¼ë©´)
                if self.data_yaml and 'names' in self.data_yaml:
                    class_names = self.data_yaml['names']
                    class_name = class_names[int(cls)] if int(cls) < len(class_names) else f"Unknown_{cls}"
                else:
                    # fallback to registry.json
                    class_name = self.model_registry.registry['classes']['class_names'][int(cls)]

                detection = {
                    'bbox': [int(x1), int(y1), int(x2), int(y2)],
                    'confidence': float(score),
                    'class_id': int(cls),
                    'class_name': class_name,
                    'model': model_id
                }
                detections.append(detection)
            
            st.success(f"âœ… {model_id}: {len(detections)}ê°œ ê°ì²´ ê²€ì¶œ ì™„ë£Œ (Detectron2)")
            return detections
            
        except ImportError:
            st.warning("âš ï¸ Detectron2ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. YOLOë¡œ ëŒ€ì²´ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            return self._fallback_to_yolo(model_id)
        except Exception as e:
            st.error(f"âŒ {model_id} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return self._fallback_to_yolo(model_id)
    
    def _fallback_to_yolo(self, model_id):
        """Detectron2 ì‹¤íŒ¨ ì‹œ YOLOë¡œ ëŒ€ì²´ ì‹¤í–‰"""
        st.info("â„¹ï¸ YOLO ëª¨ë¸ë¡œ ëŒ€ì²´ ì‹¤í–‰ ì¤‘...")
        yolo_path = "models/yolo/best.pt"
        
        if not os.path.exists(yolo_path):
            yolo_path = "models/yolo/best.pt"  # í†µí•©ëœ ê²½ë¡œ
            
        if not os.path.exists(yolo_path):
            st.error(f"âŒ YOLO ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return []
            
        try:
            # ìºì‹œì—ì„œ YOLO ëª¨ë¸ ë¡œë“œ
            fallback_cache_key = f"fallback_model_{model_id}_yolo"
            if fallback_cache_key not in st.session_state:
                model = load_yolo_model_cached(yolo_path)
                if model is not None:
                    st.session_state[fallback_cache_key] = model
                else:
                    st.error(f"âŒ ëŒ€ì²´ YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {yolo_path}")
                    return []

            model = st.session_state[fallback_cache_key]
            image = st.session_state.current_image['image']
            conf_threshold = st.session_state.get('confidence_threshold', 0.25)
            iou_threshold = st.session_state.get('iou_threshold', 0.45)

            results = model.predict(
                source=image,
                conf=conf_threshold,
                iou=iou_threshold,
                device=self.device['device'],
                verbose=False
            )
            
            detections = []
            if results and len(results) > 0:
                result = results[0]
                if result.boxes is not None and len(result.boxes) > 0:
                    boxes = result.boxes.xyxy.cpu().numpy()
                    scores = result.boxes.conf.cpu().numpy()
                    classes = result.boxes.cls.cpu().numpy()
                    
                    for box, score, cls in zip(boxes, scores, classes):
                        # data.yamlì˜ í´ë˜ìŠ¤ ì´ë¦„ ì‚¬ìš© (ìˆìœ¼ë©´)
                        if self.data_yaml and 'names' in self.data_yaml:
                            class_names = self.data_yaml['names']
                            class_name = class_names[int(cls)] if int(cls) < len(class_names) else f"Unknown_{cls}"
                        else:
                            # fallback to registry.json
                            class_name = self.model_registry.registry['classes']['class_names'][int(cls)]

                        detection = {
                            'bbox': box.tolist(),
                            'confidence': float(score),
                            'class_id': int(cls),
                            'class_name': class_name,
                            'model': model_id
                        }
                        detections.append(detection)
            
            st.success(f"âœ… {len(detections)}ê°œ ê°ì²´ ê²€ì¶œ ì™„ë£Œ (YOLO ëŒ€ì²´)")
            return detections
            
        except Exception as e:
            st.error(f"âŒ YOLO ëŒ€ì²´ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []

    def render_detection_results(self):
        """ê²€ì¶œ ê²°ê³¼ í‘œì‹œ"""
        st.header("ğŸ” AI ê²€ì¶œ ê²°ê³¼")

        if not st.session_state.detection_results:
            return

        # Ground Truth ë¼ë²¨ ë¡œë“œ (ìˆëŠ” ê²½ìš°)
        ground_truth = self.load_ground_truth_for_current_image()

        # ê° ëª¨ë¸ë³„ ê²°ê³¼ í‘œì‹œ
        for model_id, detections in st.session_state.detection_results.items():
            # manual ëª¨ë¸ì€ model_registryì— ì—†ìœ¼ë¯€ë¡œ ë³„ë„ ì²˜ë¦¬
            if model_id == 'manual':
                model_info = {
                    'name': 'ìˆ˜ì‘ì—… ë¼ë²¨ë§',
                    'emoji': 'âœï¸',
                    'type': 'MANUAL',
                    'description': 'ì‚¬ìš©ìê°€ ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€í•œ ê²€ì¶œ'
                }
            else:
                model_info = self.model_registry.registry["models"][model_id]

            # F1 ìŠ¤ì½”ì–´ ê³„ì‚° (Ground Truthê°€ ìˆëŠ” ê²½ìš°)
            f1_score = None
            metrics = None
            if ground_truth:
                metrics = self.calculate_detection_metrics(detections, ground_truth)
                f1_score = metrics['f1_score']

            # í™•ì¥ íŒ¨ë„ ì œëª©ì— F1 ìŠ¤ì½”ì–´, ì •ë°€ë„, ì¬í˜„ìœ¨ í¬í•¨
            expander_title = f"ğŸ“Š {model_info['name']} - {len(detections)}ê°œ ê²€ì¶œ"
            if f1_score is not None:
                expander_title += f" (F1: {f1_score:.1%}, ì •ë°€ë„: {metrics['precision']:.1%}, ì¬í˜„ìœ¨: {metrics['recall']:.1%})"

            with st.expander(expander_title, expanded=True):
                if detections or ground_truth:
                    # ë””ë²„ê¹…: Ground Truth ìƒíƒœ í‘œì‹œ
                    if ground_truth:
                        st.info(f"âœ… Ground Truth ë¡œë“œë¨: {len(ground_truth)}ê°œ ë¼ë²¨")
                    else:
                        st.warning("âš ï¸ Ground Truth ì—†ìŒ")

                    # Ground Truthê°€ ìˆìœ¼ë©´ ë¶„ë¦¬ í‘œì‹œ, ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹
                    if ground_truth:
                        # Ground Truthì™€ ì˜ˆì¸¡ì„ ë¶„ë¦¬í•˜ì—¬ í‘œì‹œ
                        col_gt, col_det = st.columns(2)

                        with col_gt:
                            # Ground Truthë§Œ í‘œì‹œ (ì´ˆë¡ìƒ‰, ë‘êº¼ìš´ ì„ )
                            gt_image = self.draw_ground_truth_only(
                                st.session_state.current_image['image'].copy(),
                                ground_truth
                            )
                            gt_width = gt_image.shape[1]
                            gt_display_width = int(gt_width * 0.25)
                            st.image(gt_image, caption=f"ğŸŸ¢ Ground Truth ({len(ground_truth)}ê°œ)", width=gt_display_width)

                        with col_det:
                            # ê²€ì¶œ ê²°ê³¼ë§Œ í‘œì‹œ (ë¹¨ê°„ìƒ‰, ë‘êº¼ìš´ ì„ )
                            det_image = self.draw_detections_only(
                                st.session_state.current_image['image'].copy(),
                                detections
                            )
                            det_width = det_image.shape[1]
                            det_display_width = int(det_width * 0.25)
                            st.image(det_image, caption=f"ğŸ”´ {model_info['name']} ê²€ì¶œ ({len(detections)}ê°œ)", width=det_display_width)
                    else:
                        # ê¸°ì¡´ ë°©ì‹: ë‹¤ì–‘í•œ ìƒ‰ìƒìœ¼ë¡œ í‘œì‹œ
                        result_image = self.draw_detection_results(
                            st.session_state.current_image['image'].copy(),
                            detections
                        )
                        caption = f"{model_info['name']} ê²€ì¶œ ê²°ê³¼"

                        # ê²€ì¶œ ê²°ê³¼ ì´ë¯¸ì§€ë„ 1/4 í¬ê¸°ë¡œ í‘œì‹œ
                        result_width = result_image.shape[1]
                        display_width = int(result_width * 0.25)
                        st.image(result_image, caption=caption, width=display_width)

                    # ê²€ì¶œ í†µê³„ ë° ì •í™•ë„ ë©”íŠ¸ë¦­
                    if f1_score is not None:
                        # Ground Truthê°€ ìˆì„ ë•Œ: 4ê°œ ì»¬ëŸ¼
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("ì´ ê²€ì¶œ ìˆ˜", len(detections))
                        with col2:
                            avg_conf = safe_mean([d['confidence'] for d in detections])
                            st.metric("í‰ê·  ì‹ ë¢°ë„", f"{avg_conf:.3f}")
                        with col3:
                            st.metric("Precision", f"{metrics['precision']:.1%}")
                        with col4:
                            st.metric("Recall", f"{metrics['recall']:.1%}")

                        # F1 ìŠ¤ì½”ì–´ë¥¼ ê°•ì¡° í‘œì‹œ
                        st.success(f"ğŸ¯ F1 Score: {f1_score:.1%} (TP:{metrics['true_positives']}, FP:{metrics['false_positives']}, FN:{metrics['false_negatives']})")
                    else:
                        # Ground Truthê°€ ì—†ì„ ë•Œ: ê¸°ì¡´ì²˜ëŸ¼ 3ê°œ ì»¬ëŸ¼
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ì´ ê²€ì¶œ ìˆ˜", len(detections))
                        with col2:
                            avg_conf = safe_mean([d['confidence'] for d in detections])
                            st.metric("í‰ê·  ì‹ ë¢°ë„", f"{avg_conf:.3f}")
                        with col3:
                            unique_classes = len(set(d['class_name'] for d in detections))
                            st.metric("ê²€ì¶œ í´ë˜ìŠ¤ ìˆ˜", unique_classes)
                else:
                    st.info("ê²€ì¶œëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤.")

    def draw_detection_results(self, image, detections):
        """ê²€ì¶œ ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ì— ê·¸ë¦¬ê¸° (Enhanced OCR ê²€ì¦ ê²°ê³¼ êµ¬ë¶„ í‘œì‹œ)"""
        # ê¸°ë³¸ ìƒ‰ìƒ: ë¹¨ê°„ìƒ‰ ê³„ì—´ (ì¼ë°˜ ê²€ì¶œ)
        standard_colors = [(0, 0, 255), (0, 50, 255), (50, 50, 255), (0, 100, 255), (100, 0, 255)]
        # OCR ê²€ì¦ ìƒ‰ìƒ: ì´ˆë¡ìƒ‰ ê³„ì—´
        ocr_color = (0, 255, 0)  # ë°ì€ ì´ˆë¡ìƒ‰

        for i, detection in enumerate(detections):
            x1, y1, x2, y2 = detection['bbox']

            # OCR ê²€ì¦ëœ ê²€ì¶œì¸ì§€ í™•ì¸
            is_ocr_verified = detection.get('ocr_verified', False)

            if is_ocr_verified:
                # OCR ê²€ì¦ëœ ê²½ìš°: ì´ˆë¡ìƒ‰ + ë‘êº¼ìš´ ì„ 
                color = ocr_color
                thickness = 3
                prefix = "OCRâœ“ "
            else:
                # ì¼ë°˜ ê²€ì¶œ: ê¸°ì¡´ ìƒ‰ìƒ
                color = standard_colors[i % len(standard_colors)]
                thickness = 2
                prefix = ""

            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)

            # ë¼ë²¨ í…ìŠ¤íŠ¸ (OCR ê²€ì¦ í‘œì‹œ í¬í•¨)
            confidence_text = f"({detection['confidence']:.2f})"
            label = f"{prefix}{detection['class_name']} {confidence_text}"

            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
            cv2.rectangle(image, (x1, y1-30), (x1+label_size[0], y1), color, -1)
            cv2.putText(image, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

            # OCR ê²€ì¦ëœ ê²½ìš° ì¶”ê°€ ì •ë³´ í‘œì‹œ
            if is_ocr_verified and detection.get('ocr_text'):
                ocr_text = detection['ocr_text'][:15]  # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
                ocr_label = f"Text: {ocr_text}"
                cv2.putText(image, ocr_label, (x1, y2+20), cv2.FONT_HERSHEY_SIMPLEX, 0.4, ocr_color, 1)

        return image

    def create_final_verified_image(self, detections, prefix):
        """ìµœì¢… ê²€ì¦ëœ ê²°ê³¼ë¥¼ ì‹œê°í™” (ìŠ¹ì¸/ê±°ë¶€/ìˆ˜ì •/ìˆ˜ì‘ì—… í¬í•¨)"""
        if not st.session_state.get('current_image'):
            return None

        image = st.session_state.current_image['image'].copy()

        # ìƒíƒœë³„ ìƒ‰ìƒ ì •ì˜
        status_colors = {
            'approved': (0, 255, 0),     # ì´ˆë¡ìƒ‰ - ìŠ¹ì¸ë¨
            'rejected': (0, 0, 255),      # ë¹¨ê°„ìƒ‰ - ê±°ë¶€ë¨
            'modified': (255, 165, 0),    # ì£¼í™©ìƒ‰ - ìˆ˜ì •ë¨
            'pending': (128, 128, 128),   # íšŒìƒ‰ - ëŒ€ê¸°ì¤‘
            'manual': (255, 0, 255)       # ë³´ë¼ìƒ‰ - ìˆ˜ì‘ì—…
        }

        # ê° ê²€ì¶œì— ëŒ€í•´ ìƒíƒœì— ë”°ë¥¸ ìƒ‰ìƒìœ¼ë¡œ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        for i, detection in enumerate(detections):
            status_key = f"{prefix}_{i}"
            current_status = st.session_state.verification_status.get(status_key, "pending")

            # ìˆ˜ì •ëœ ê²½ìš° ìƒíƒœë¥¼ modifiedë¡œ ì„¤ì •
            if status_key in st.session_state.get('modified_classes', {}):
                current_status = 'modified'

            # ìˆ˜ì‘ì—… ê²€ì¶œì¸ ê²½ìš°
            if detection.get('model_id') == 'manual' or detection.get('model') == 'manual':
                if current_status == 'pending':
                    current_status = 'manual'

            # ìƒ‰ìƒ ì„ íƒ
            color = status_colors.get(current_status, status_colors['pending'])

            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            bbox = detection.get('bbox', detection.get('box', []))
            if bbox and len(bbox) >= 4:
                x1, y1, x2, y2 = map(int, bbox[:4])

                # ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)

                # í´ë˜ìŠ¤ ì´ë¦„ í‘œì‹œ (ìˆ˜ì •ëœ ê²½ìš° ìˆ˜ì •ëœ ì´ë¦„ ì‚¬ìš©)
                class_name = detection.get('class_name', 'Unknown')
                if status_key in st.session_state.get('modified_classes', {}):
                    class_name = st.session_state.modified_classes[status_key]

                # ìƒíƒœ ì•„ì´ì½˜ ì¶”ê°€
                status_icon = {
                    'approved': 'âœ…',
                    'rejected': 'âŒ',
                    'modified': 'âœï¸',
                    'manual': 'ğŸ¨',
                    'pending': 'â³'
                }.get(current_status, '')

                # í…ìŠ¤íŠ¸ ë¼ë²¨
                label = f"{status_icon} {class_name}"

                # í…ìŠ¤íŠ¸ ë°°ê²½
                font = cv2.FONT_HERSHEY_SIMPLEX
                font_scale = 0.5
                thickness = 1
                (text_width, text_height), baseline = cv2.getTextSize(label, font, font_scale, thickness)

                # ë°°ê²½ ì‚¬ê°í˜•
                cv2.rectangle(image, (x1, y1 - text_height - 10), (x1 + text_width, y1), color, -1)

                # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
                cv2.putText(image, label, (x1, y1 - 5), font, font_scale, (255, 255, 255), thickness)

        return image

    def draw_detection_with_ground_truth(self, image, detections, ground_truth):
        """Ground Truthì™€ ëª¨ë¸ ì˜ˆì¸¡ì„ í•¨ê»˜ ì‹œê°í™”"""
        img_height, img_width = image.shape[:2]

        # 1. Ground Truth ê·¸ë¦¬ê¸° (ì´ˆë¡ìƒ‰, ë‘êº¼ìš´ ì„ )
        for gt in ground_truth:
            x1, y1, x2, y2 = self.yolo_to_xyxy(
                gt['x_center'], gt['y_center'],
                gt['width'], gt['height'],
                img_width, img_height
            )
            # ì´ˆë¡ìƒ‰ ë°•ìŠ¤ (ë‘ê»˜ 3)
            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 3)

            # GT ë¼ë²¨ (í´ë˜ìŠ¤ IDë§Œ)
            label = f"GT:{gt['class_id']}"
            cv2.putText(image, label, (x1, y1-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        # 2. ëª¨ë¸ ì˜ˆì¸¡ ê·¸ë¦¬ê¸° (ë¹¨ê°„ìƒ‰, ë‘êº¼ìš´ ì„ )
        for detection in detections:
            x1, y1, x2, y2 = detection['bbox']
            # ì¢Œí‘œë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
            # ë¹¨ê°„ìƒ‰ ë°•ìŠ¤ (ë‘ê»˜ 3ìœ¼ë¡œ ì¦ê°€)
            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 0, 255), 3)

            # ì˜ˆì¸¡ ë¼ë²¨ (í´ë˜ìŠ¤ IDì™€ ì‹ ë¢°ë„)
            label = f"P:{detection['class_id']}({detection['confidence']:.2f})"
            # ë¼ë²¨ í…ìŠ¤íŠ¸ (ë°”ë¡œ í‘œì‹œ, ë°°ê²½ ì—†ì´)
            cv2.putText(image, label, (x1, y2+20),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

        # ë²”ë¡€ ì¶”ê°€ (ì™¼ìª½ ìƒë‹¨, ë” í¬ê³  ëª…í™•í•˜ê²Œ)
        cv2.rectangle(image, (10, 10), (300, 80), (255, 255, 255), -1)
        cv2.rectangle(image, (10, 10), (300, 80), (0, 0, 0), 3)
        cv2.putText(image, "Legend:", (20, 35),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)
        cv2.putText(image, "Green Box = Ground Truth", (20, 55),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 200, 0), 2)
        cv2.putText(image, "Red Box = Model Prediction", (20, 72),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 200), 2)

        return image

    def load_ground_truth_for_current_image(self):
        """í˜„ì¬ ì´ë¯¸ì§€ì— ëŒ€í•œ Ground Truth ë¼ë²¨ ë¡œë“œ"""
        if not st.session_state.current_image:
            return None

        # ì´ë¯¸ì§€ íŒŒì¼ëª…ì—ì„œ ë¼ë²¨ íŒŒì¼ëª… ì¶”ì¶œ
        image_filename = st.session_state.current_image.get('filename', '')
        if not image_filename:
            return None

        # ë¼ë²¨ íŒŒì¼ ê²½ë¡œ êµ¬ì„±
        label_filename = os.path.splitext(image_filename)[0] + '.txt'
        label_path = os.path.join(self.test_drawings_path, 'labels', label_filename)

        if not os.path.exists(label_path):
            return None

        # YOLO í˜•ì‹ ë¼ë²¨ ë¡œë“œ
        ground_truth = []
        try:
            with open(label_path, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        parts = line.split()
                        if len(parts) >= 5:
                            class_id = int(parts[0])
                            # data.yamlì—ì„œ í´ë˜ìŠ¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
                            class_name = str(class_id)  # ê¸°ë³¸ê°’
                            if self.data_yaml and 'names' in self.data_yaml:
                                class_names = self.data_yaml['names']
                                if class_id < len(class_names):
                                    class_name = class_names[class_id]

                            ground_truth.append({
                                'class_id': class_id,
                                'class_name': class_name,
                                'x_center': float(parts[1]),
                                'y_center': float(parts[2]),
                                'width': float(parts[3]),
                                'height': float(parts[4])
                            })
            return ground_truth if ground_truth else None
        except Exception as e:
            st.warning(f"ë¼ë²¨ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None

    def yolo_to_xyxy(self, x_center, y_center, width, height, img_width, img_height):
        """YOLO í˜•ì‹ì„ xyxy ì¢Œí‘œë¡œ ë³€í™˜ (ë” ì •í™•í•œ ë°˜ì˜¬ë¦¼ ì ìš©)"""
        x_center_abs = x_center * img_width
        y_center_abs = y_center * img_height
        width_abs = width * img_width
        height_abs = height * img_height

        # round()ë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ì •í™•í•œ ì¢Œí‘œ ê³„ì‚°
        x1 = round(x_center_abs - width_abs / 2)
        y1 = round(y_center_abs - height_abs / 2)
        x2 = round(x_center_abs + width_abs / 2)
        y2 = round(y_center_abs + height_abs / 2)

        # ì´ë¯¸ì§€ ê²½ê³„ ë‚´ë¡œ ì œí•œ
        x1 = max(0, min(x1, img_width - 1))
        y1 = max(0, min(y1, img_height - 1))
        x2 = max(0, min(x2, img_width - 1))
        y2 = max(0, min(y2, img_height - 1))

        return x1, y1, x2, y2

    def calculate_detection_metrics(self, predictions, ground_truth, iou_threshold=0.3):
        """ì˜ˆì¸¡ê³¼ Ground Truthë¥¼ ë¹„êµí•˜ì—¬ ì •í™•ë„ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        if not predictions or not ground_truth:
            return {
                'true_positives': 0,
                'false_positives': len(predictions) if predictions else 0,
                'false_negatives': len(ground_truth) if ground_truth else 0,
                'precision': 0.0,
                'recall': 0.0,
                'f1_score': 0.0
            }

        # ì´ë¯¸ì§€ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
        image = st.session_state.current_image.get('image')
        if image is None:
            return {
                'true_positives': 0,
                'false_positives': len(predictions),
                'false_negatives': len(ground_truth),
                'precision': 0.0,
                'recall': 0.0,
                'f1_score': 0.0
            }

        img_height, img_width = image.shape[:2]

        true_positives = 0
        false_positives = len(predictions)
        false_negatives = len(ground_truth)
        matched_gt = set()

        # ê° ì˜ˆì¸¡ì— ëŒ€í•´ ê°€ì¥ ì˜ ë§¤ì¹­ë˜ëŠ” GT ì°¾ê¸°
        for pred in predictions:
            best_iou = 0
            best_gt_idx = -1

            pred_bbox = pred.get('bbox', [0, 0, 0, 0])
            pred_class_id = pred.get('class_id', -1)

            # ëª¨ë“  GTì™€ ë¹„êµ
            for gt_idx, gt in enumerate(ground_truth):
                if gt_idx not in matched_gt:
                    # GT bboxë¥¼ xyxyë¡œ ë³€í™˜
                    gt_bbox = self.yolo_to_xyxy(
                        gt['x_center'], gt['y_center'],
                        gt['width'], gt['height'],
                        img_width, img_height
                    )

                    # IoU ê³„ì‚°
                    iou = self.calculate_iou(pred_bbox, gt_bbox)

                    # ê°™ì€ í´ë˜ìŠ¤ì´ê³  IoUê°€ ë” ë†’ìœ¼ë©´ ì—…ë°ì´íŠ¸
                    if pred_class_id == gt['class_id'] and iou > best_iou:
                        best_iou = iou
                        best_gt_idx = gt_idx

            # IoU ì„ê³„ê°’ì„ ë„˜ê³  ë§¤ì¹­ë˜ë©´ TP
            if best_iou >= iou_threshold and best_gt_idx >= 0:
                true_positives += 1
                matched_gt.add(best_gt_idx)
                false_positives -= 1
                false_negatives -= 1

        # ë©”íŠ¸ë¦­ ê³„ì‚°
        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0
        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

        return {
            'true_positives': true_positives,
            'false_positives': false_positives,
            'false_negatives': false_negatives,
            'precision': precision,
            'recall': recall,
            'f1_score': f1_score
        }

    def calculate_iou(self, box1, box2):
        """ë‘ ë°”ìš´ë”© ë°•ìŠ¤ì˜ IoU(Intersection over Union) ê³„ì‚°"""
        x1 = max(box1[0], box2[0])
        y1 = max(box1[1], box2[1])
        x2 = min(box1[2], box2[2])
        y2 = min(box1[3], box2[3])

        intersection = max(0, x2 - x1) * max(0, y2 - y1)
        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
        union = area1 + area2 - intersection

        return intersection / union if union > 0 else 0

    def remove_duplicate_detections(self, detections, iou_threshold=0.5):
        """ì¤‘ë³µ ê²€ì¶œ ì œê±° (IoU ê¸°ë°˜)"""
        if not detections:
            return []

        # ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)

        unique_detections = []
        for detection in sorted_detections:
            is_duplicate = False
            for unique in unique_detections:
                if self.calculate_iou(detection['bbox'], unique['bbox']) > iou_threshold:
                    # ê°™ì€ í´ë˜ìŠ¤ì¸ ê²½ìš°ë§Œ ì¤‘ë³µìœ¼ë¡œ ì²˜ë¦¬
                    if detection['class_name'] == unique['class_name']:
                        is_duplicate = True
                        break

            if not is_duplicate:
                unique_detections.append(detection)

        return unique_detections

    def remove_duplicate_detections_with_voting(self, detections, iou_threshold=0.5, min_votes=2):
        """Votingê³¼ Weighted Ensembleì„ ì‚¬ìš©í•œ ì¤‘ë³µ ê²€ì¶œ ì œê±°"""
        if not detections:
            return [], {}

        # ê²€ì¶œ ê·¸ë£¹ ìƒì„± (IoU ê¸°ë°˜)
        detection_groups = []
        for detection in detections:
            added_to_group = False
            for group in detection_groups:
                # ê·¸ë£¹ì˜ ì²« ë²ˆì§¸ ê²€ì¶œê³¼ ë¹„êµ
                if self.calculate_iou(detection['bbox'], group[0]['bbox']) > iou_threshold:
                    # ê°™ì€ í´ë˜ìŠ¤ì´ê±°ë‚˜ ë¹„ìŠ·í•œ ìœ„ì¹˜ì¸ ê²½ìš° ê·¸ë£¹ì— ì¶”ê°€
                    group.append(detection)
                    added_to_group = True
                    break

            if not added_to_group:
                detection_groups.append([detection])

        # ê° ê·¸ë£¹ì— ëŒ€í•´ Voting ìˆ˜í–‰
        unique_detections = []
        voting_info = {}

        for group_idx, group in enumerate(detection_groups):
            if len(group) >= min_votes:
                # í´ë˜ìŠ¤ë³„ íˆ¬í‘œ ìˆ˜ ê³„ì‚°
                class_votes = {}
                weighted_scores = {}

                for detection in group:
                    class_name = detection['class_name']
                    model_id = detection.get('model_id', 'unknown')
                    weight = self.model_weights.get(model_id, 1.0)

                    if class_name not in class_votes:
                        class_votes[class_name] = 0
                        weighted_scores[class_name] = 0

                    class_votes[class_name] += 1
                    weighted_scores[class_name] += detection['confidence'] * weight

                # ê°€ì¥ ë§ì€ íˆ¬í‘œë¥¼ ë°›ì€ í´ë˜ìŠ¤ ì„ íƒ
                best_class = max(class_votes.keys(), key=lambda k: (class_votes[k], weighted_scores[k]))

                # í•´ë‹¹ í´ë˜ìŠ¤ì˜ ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ë¥¼ ê°€ì§„ ê²€ì¶œ ì„ íƒ
                best_detection = None
                best_weighted_score = 0

                for detection in group:
                    if detection['class_name'] == best_class:
                        model_id = detection.get('model_id', 'unknown')
                        weight = self.model_weights.get(model_id, 1.0)
                        weighted_score = detection['confidence'] * weight

                        if weighted_score > best_weighted_score:
                            best_weighted_score = weighted_score
                            best_detection = detection.copy()

                if best_detection:
                    # Voting ì •ë³´ ì¶”ê°€
                    best_detection['voting_info'] = {
                        'total_votes': len(group),
                        'class_votes': class_votes,
                        'weighted_scores': weighted_scores,
                        'models_agreed': [d.get('model_id', 'unknown') for d in group]
                    }
                    unique_detections.append(best_detection)
                    voting_info[f"group_{group_idx}"] = best_detection['voting_info']

        return unique_detections, voting_info

    def render_symbol_verification(self):
        """ì‹¬ë³¼ ê²€ì¦ ì„¹ì…˜"""
        st.header("âœ… ì‹¬ë³¼ ê²€ì¦ ë° ìˆ˜ì •")

        # ìŠ¹ì¸/ê±°ë¶€ ìƒíƒœ ì´ˆê¸°í™”
        if 'verification_status' not in st.session_state:
            st.session_state.verification_status = {}

        # í¸ì§‘ ìƒíƒœ ì´ˆê¸°í™”
        if 'edit_mode' not in st.session_state:
            st.session_state.edit_mode = {}

        # ìˆ˜ì •ëœ í´ë˜ìŠ¤ ì´ë¦„ ì €ì¥
        if 'modified_classes' not in st.session_state:
            st.session_state.modified_classes = {}

        # ê²€ì¶œ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ë¦¬í„´
        if not st.session_state.detection_results:
            st.info("ê²€ì¶œëœ ì‹¬ë³¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ë©”ì¸ ì»¨í…ì¸ ì™€ ì‚¬ì´ë“œ íŒ¨ë„ë¡œ ë ˆì´ì•„ì›ƒ ë¶„ë¦¬
        main_col, side_panel = st.columns([4, 1])  # 80% ë©”ì¸, 20% ì‚¬ì´ë“œ

        with side_panel:
            # ì‹¬ë³¼ ì°¸ì¡° ë¦¬ìŠ¤íŠ¸ í‘œì‹œ
            self.render_symbol_reference_panel()

        with main_col:
            # íƒ­ìœ¼ë¡œ ëª¨ë¸ë³„ ê²°ê³¼ì™€ í†µí•© ê²°ê³¼ êµ¬ë¶„
            # íƒ­ ë¦¬ìŠ¤íŠ¸ ìƒì„± - ê³ ì • íƒ­ 3ê°œ + ëª¨ë¸ë³„ íƒ­
            fixed_tabs = ["ğŸ“Š í†µí•© ê²°ê³¼ (ì¤‘ë³µ ì œê±°)", "ğŸ—³ï¸ Voting ê¸°ë°˜ í†µí•©", "ğŸ” OCR í‚¤ì›Œë“œ ë¶„ì„"]
            model_tabs = []
            for model_id in st.session_state.detection_results.keys():
                # manual ëª¨ë¸ì€ model_registryì— ì—†ìœ¼ë¯€ë¡œ ë³„ë„ ì²˜ë¦¬
                if model_id == 'manual':
                    model_info = {
                        'name': 'ìˆ˜ì‘ì—… ë¼ë²¨ë§',
                        'emoji': 'âœï¸',
                        'type': 'MANUAL',
                        'description': 'ì‚¬ìš©ìê°€ ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€í•œ ê²€ì¶œ'
                    }
                else:
                    model_info = self.model_registry.registry["models"][model_id]
                model_tabs.append(f"ğŸ¤– {model_info['name']}")

            all_tabs = fixed_tabs + model_tabs
            tabs = st.tabs(all_tabs)

            # í†µí•© ê²°ê³¼ íƒ­
            with tabs[0]:
                # ëª¨ë“  ê²€ì¶œ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê¸°
                all_detections = []
            for model_id, detections in st.session_state.detection_results.items():
                for detection in detections:
                    detection_with_model = detection.copy()
                    detection_with_model['model_id'] = model_id
                    all_detections.append(detection_with_model)

            if not all_detections:
                st.info("ê²€ì¶œëœ ì‹¬ë³¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # ì¤‘ë³µ ì œê±°
                unique_detections = self.remove_duplicate_detections(all_detections)

                # í†µê³„ í‘œì‹œ
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ì „ì²´ ê²€ì¶œ", len(all_detections))
                with col2:
                    st.metric("ì¤‘ë³µ ì œê±° í›„", len(unique_detections))
                with col3:
                    if len(all_detections) > 0:
                        st.metric("ì¤‘ë³µë¥ ", f"{((len(all_detections)-len(unique_detections))/len(all_detections)*100):.1f}%")

                st.write(f"ì¤‘ë³µ ì œê±° í›„ {len(unique_detections)}ê°œì˜ ê³ ìœ í•œ ì‹¬ë³¼ì´ ê²€ì¶œë˜ì—ˆìŠµë‹ˆë‹¤:")

                # ì¼ê´„ ì²˜ë¦¬ ë²„íŠ¼
                col1, col2, col3 = st.columns(3)
                with col1:
                    if st.button("ğŸ”˜ ëª¨ë‘ ìŠ¹ì¸", key="approve_all_unified"):
                        for i, detection in enumerate(unique_detections):
                            st.session_state.verification_status[f"unified_{i}"] = "approved"
                        st.success("ëª¨ë“  ê²€ì¶œì´ ìŠ¹ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.rerun()
                with col2:
                    if st.button("âŒ ëª¨ë‘ ê±°ë¶€", key="reject_all_unified"):
                        for i, detection in enumerate(unique_detections):
                            st.session_state.verification_status[f"unified_{i}"] = "rejected"
                        st.warning("ëª¨ë“  ê²€ì¶œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.rerun()
                with col3:
                    if st.button("ğŸ”„ ìƒíƒœ ì´ˆê¸°í™”", key="reset_status_unified"):
                        # í†µí•© ê²°ê³¼ ìƒíƒœë§Œ ì´ˆê¸°í™”
                        keys_to_remove = [k for k in st.session_state.verification_status.keys() if k.startswith("unified_")]
                        for k in keys_to_remove:
                            del st.session_state.verification_status[k]
                        st.info("ìƒíƒœê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.rerun()

                # ê²€ì¶œ ê²°ê³¼ í‘œì‹œ
                self.render_detection_list(unique_detections, "unified")

                # ìµœì¢… í†µí•© ì´ë¯¸ì§€ í‘œì‹œ
                st.divider()
                st.subheader("ğŸ–¼ï¸ ìµœì¢… ê²€ì¦ ê²°ê³¼ ì´ë¯¸ì§€")

                # ìµœì¢… ì´ë¯¸ì§€ ìƒì„± (ìŠ¹ì¸/ê±°ë¶€/ìˆ˜ì •/ìˆ˜ì‘ì—… ëª¨ë‘ í¬í•¨)
                final_image = self.create_final_verified_image(unique_detections, "unified")
                if final_image is not None:
                    st.image(final_image, caption="ìµœì¢… ê²€ì¦ ê²°ê³¼ (âœ…ìŠ¹ì¸ âŒê±°ë¶€ âœï¸ìˆ˜ì • ğŸ¨ìˆ˜ì‘ì—…)")
                else:
                    st.info("ê²€ì¶œëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # Voting ê¸°ë°˜ í†µí•© íƒ­
        with tabs[1]:
            st.subheader("ğŸ—³ï¸ Voting & Weighted Ensemble")

            # Voting ì„¤ì •
            col1, col2 = st.columns(2)
            with col1:
                min_votes = st.slider("ìµœì†Œ íˆ¬í‘œ ìˆ˜", min_value=1, max_value=4, value=2,
                                     help="ê²€ì¶œì„ ìœ íš¨í•˜ê²Œ ë§Œë“¤ê¸° ìœ„í•œ ìµœì†Œ ëª¨ë¸ ìˆ˜")
            with col2:
                st.info(f"í˜„ì¬ {len(st.session_state.detection_results)}ê°œ ëª¨ë¸ì—ì„œ ê²€ì¶œ ì¤‘")

            # ëª¨ë¸ ê°€ì¤‘ì¹˜ ì„¤ì • ì„¹ì…˜
            with st.expander("âš™ï¸ ëª¨ë¸ ê°€ì¤‘ì¹˜ ì„¤ì •", expanded=False):
                st.write("ê° ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì„¤ì •í•˜ì—¬ Weighted Ensembleì˜ ì„±ëŠ¥ì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

                # ê°€ì¤‘ì¹˜ ì˜¤ë²„ë¼ì´ë“œë¥¼ ìœ„í•œ ì„¸ì…˜ ìƒíƒœ
                if 'model_weights_override' not in st.session_state:
                    st.session_state.model_weights_override = self.model_weights.copy()

                # ê° ëª¨ë¸ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ ìŠ¬ë¼ì´ë”
                for model_id in st.session_state.detection_results.keys():
                    # manual ëª¨ë¸ì€ model_registryì— ì—†ìœ¼ë¯€ë¡œ ë³„ë„ ì²˜ë¦¬
                    if model_id == 'manual':
                        model_info = {
                            'name': 'ìˆ˜ì‘ì—… ë¼ë²¨ë§',
                            'emoji': 'âœï¸',
                            'type': 'MANUAL',
                            'description': 'ì‚¬ìš©ìê°€ ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€í•œ ê²€ì¶œ'
                        }
                    else:
                        model_info = self.model_registry.registry["models"][model_id]
                    current_weight = st.session_state.model_weights_override.get(model_id, 1.0)

                    new_weight = st.slider(
                        f"{model_info['name']} ê°€ì¤‘ì¹˜",
                        min_value=0.1,
                        max_value=2.0,
                        value=current_weight,
                        step=0.1,
                        key=f"weight_{model_id}",
                        help=f"{model_info['description']}"
                    )
                    st.session_state.model_weights_override[model_id] = new_weight

                # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” ë²„íŠ¼
                if st.button("ğŸ”„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”", key="reset_weights"):
                    st.session_state.model_weights_override = self.model_weights.copy()
                    st.rerun()

                # í˜„ì¬ ê°€ì¤‘ì¹˜ í‘œì‹œ
                st.write("í˜„ì¬ ì„¤ì •ëœ ê°€ì¤‘ì¹˜:")
                for model_id, weight in st.session_state.model_weights_override.items():
                    if model_id in st.session_state.detection_results:
                        # manual ëª¨ë¸ì€ model_registryì— ì—†ìœ¼ë¯€ë¡œ ë³„ë„ ì²˜ë¦¬
                        if model_id == 'manual':
                            model_info = {
                                'name': 'ìˆ˜ì‘ì—… ë¼ë²¨ë§',
                                'emoji': 'âœï¸',
                                'type': 'MANUAL',
                                'description': 'ì‚¬ìš©ìê°€ ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€í•œ ê²€ì¶œ'
                            }
                        else:
                            model_info = self.model_registry.registry["models"][model_id]
                        st.write(f"  - {model_info['name']}: **{weight:.1f}**")

            # ëª¨ë“  ê²€ì¶œ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê¸°
            all_detections_voting = []
            for model_id, detections in st.session_state.detection_results.items():
                for detection in detections:
                    detection_with_model = detection.copy()
                    detection_with_model['model_id'] = model_id
                    all_detections_voting.append(detection_with_model)

            if not all_detections_voting:
                st.info("ê²€ì¶œëœ ì‹¬ë³¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # ì„¸ì…˜ ìƒíƒœì˜ ê°€ì¤‘ì¹˜ë¥¼ ì„ì‹œë¡œ ì‚¬ìš©
                original_weights = self.model_weights.copy()
                if 'model_weights_override' in st.session_state:
                    self.model_weights = st.session_state.model_weights_override.copy()

                # Voting ê¸°ë°˜ ì¤‘ë³µ ì œê±°
                unique_detections_voting, voting_info = self.remove_duplicate_detections_with_voting(
                    all_detections_voting, min_votes=min_votes)

                # ì›ë˜ ê°€ì¤‘ì¹˜ë¡œ ë³µì›
                self.model_weights = original_weights

                # í†µê³„ í‘œì‹œ
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("ì „ì²´ ê²€ì¶œ", len(all_detections_voting))
                with col2:
                    st.metric("Voting í†µê³¼", len(unique_detections_voting))
                with col3:
                    if len(all_detections_voting) > 0:
                        st.metric("í•„í„°ë§ ë¹„ìœ¨", f"{((len(all_detections_voting)-len(unique_detections_voting))/len(all_detections_voting)*100):.1f}%")
                with col4:
                    if unique_detections_voting:
                        avg_votes = safe_mean([d['voting_info']['total_votes'] for d in unique_detections_voting])
                        st.metric("í‰ê·  íˆ¬í‘œ ìˆ˜", f"{avg_votes:.1f}")

                st.write(f"Votingì„ í†µê³¼í•œ {len(unique_detections_voting)}ê°œì˜ ì‹¬ë³¼ì´ ê²€ì¶œë˜ì—ˆìŠµë‹ˆë‹¤:")

                # ì¼ê´„ ì²˜ë¦¬ ë²„íŠ¼
                col1, col2, col3 = st.columns(3)
                with col1:
                    if st.button("ğŸ”˜ ëª¨ë‘ ìŠ¹ì¸", key="approve_all_voting"):
                        for i, detection in enumerate(unique_detections_voting):
                            st.session_state.verification_status[f"voting_{i}"] = "approved"
                        st.success("ëª¨ë“  ê²€ì¶œì´ ìŠ¹ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.rerun()
                with col2:
                    if st.button("âŒ ëª¨ë‘ ê±°ë¶€", key="reject_all_voting"):
                        for i, detection in enumerate(unique_detections_voting):
                            st.session_state.verification_status[f"voting_{i}"] = "rejected"
                        st.warning("ëª¨ë“  ê²€ì¶œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.rerun()
                with col3:
                    if st.button("ğŸ”„ ìƒíƒœ ì´ˆê¸°í™”", key="reset_status_voting"):
                        # Voting ê²°ê³¼ ìƒíƒœë§Œ ì´ˆê¸°í™”
                        keys_to_remove = [k for k in st.session_state.verification_status.keys() if k.startswith("voting_")]
                        for k in keys_to_remove:
                            del st.session_state.verification_status[k]
                        st.info("ìƒíƒœê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.rerun()

                # Voting ê²°ê³¼ë¥¼ í¬í•¨í•œ ê²€ì¶œ ë¦¬ìŠ¤íŠ¸ í‘œì‹œ
                self.render_detection_list_with_voting(unique_detections_voting, "voting")

        # OCR í‚¤ì›Œë“œ ë¶„ì„ íƒ­
        with tabs[2]:
            self.render_enhanced_ocr_analysis()

        # ê° ëª¨ë¸ë³„ ê²°ê³¼ íƒ­ (ê³ ì • íƒ­ 3ê°œ ì´í›„ë¶€í„° ì‹œì‘)
        for tab_idx, (model_id, detections) in enumerate(st.session_state.detection_results.items()):
            actual_tab_idx = tab_idx + 3  # ê³ ì • íƒ­ 3ê°œ ë‹¤ìŒë¶€í„°
            with tabs[actual_tab_idx]:
                # manual ëª¨ë¸ì€ model_registryì— ì—†ìœ¼ë¯€ë¡œ ë³„ë„ ì²˜ë¦¬
                if model_id == 'manual':
                    model_info = {
                        'name': 'ìˆ˜ì‘ì—… ë¼ë²¨ë§',
                        'emoji': 'âœï¸',
                        'type': 'MANUAL',
                        'description': 'ì‚¬ìš©ìê°€ ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€í•œ ê²€ì¶œ'
                    }
                else:
                    model_info = self.model_registry.registry["models"][model_id]

                if not detections:
                    st.info(f"{model_info['name']} ëª¨ë¸ì—ì„œ ê²€ì¶œëœ ì‹¬ë³¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # ëª¨ë¸ë³„ í†µê³„
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ê²€ì¶œ ìˆ˜", len(detections))
                    with col2:
                        avg_conf = np.mean([d['confidence'] for d in detections])
                        st.metric("í‰ê·  ì‹ ë¢°ë„", f"{avg_conf:.3f}")
                    with col3:
                        unique_classes = len(set(d['class_name'] for d in detections))
                        st.metric("ê²€ì¶œ í´ë˜ìŠ¤ ìˆ˜", unique_classes)

                    # ëª¨ë¸ë³„ ì¼ê´„ ì²˜ë¦¬ ë²„íŠ¼
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        if st.button("ğŸ”˜ ëª¨ë‘ ìŠ¹ì¸", key=f"approve_all_{model_id}"):
                            for i, detection in enumerate(detections):
                                st.session_state.verification_status[f"{model_id}_{i}"] = "approved"
                            st.success(f"{model_info['name']}ì˜ ëª¨ë“  ê²€ì¶œì´ ìŠ¹ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            st.rerun()
                    with col2:
                        if st.button("âŒ ëª¨ë‘ ê±°ë¶€", key=f"reject_all_{model_id}"):
                            for i, detection in enumerate(detections):
                                st.session_state.verification_status[f"{model_id}_{i}"] = "rejected"
                            st.warning(f"{model_info['name']}ì˜ ëª¨ë“  ê²€ì¶œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            st.rerun()
                    with col3:
                        if st.button("ğŸ”„ ìƒíƒœ ì´ˆê¸°í™”", key=f"reset_status_{model_id}"):
                            # í•´ë‹¹ ëª¨ë¸ ìƒíƒœë§Œ ì´ˆê¸°í™”
                            keys_to_remove = [k for k in st.session_state.verification_status.keys() if k.startswith(f"{model_id}_")]
                            for k in keys_to_remove:
                                del st.session_state.verification_status[k]
                            st.info("ìƒíƒœê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            st.rerun()

                    # ê²€ì¶œ ê²°ê³¼ í‘œì‹œ
                    # ëª¨ë¸ IDë¥¼ ì¶”ê°€í•œ ê²€ì¶œ ê²°ê³¼
                    detections_with_model = []
                    for detection in detections:
                        det = detection.copy()
                        det['model_id'] = model_id
                        detections_with_model.append(det)
                    self.render_detection_list(detections_with_model, model_id)

    def render_enhanced_ocr_analysis(self):
        """í†µí•©ëœ Enhanced OCR ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
        st.subheader("ğŸ” Enhanced OCR ë¶„ì„")

        # Enhanced OCR ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì•ˆë‚´ ë©”ì‹œì§€
        if 'enhanced_ocr_results' not in st.session_state or not st.session_state.enhanced_ocr_results:
            st.info("ğŸ‘€ Enhanced OCR ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.markdown("""
            **Enhanced OCR ë¶„ì„ì„ ë³´ë ¤ë©´:**
            1. ğŸ¯ **ê²€ì¶œ ì„¤ì •** ì—ì„œ `ğŸ” Enhanced OCR í…ìŠ¤íŠ¸ ì¸ì‹ í–¥ìƒ` ì²´í¬ë°•ìŠ¤ë¥¼ í™œì„±í™”
            2. AI ê²€ì¶œì„ ì‹¤í–‰í•˜ì—¬ Enhanced OCR ì´ì¤‘ ì„ê³„ê°’ ê²€ì¶œ + Ground Truth ë§¤ì¹­ ìˆ˜í–‰
            3. ì´ íƒ­ì—ì„œ ë¶„ì„ ê²°ê³¼ í™•ì¸

            **Enhanced OCR íŠ¹ì§•:**
            - ì´ì¤‘ ì„ê³„ê°’ ê²€ì¶œ (0.25 ì¼ë°˜ / 0.1 í›„ë³´)
            - PaddleOCR APIë¥¼ í†µí•œ ì •í™•í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            - Ground Truth ë°ì´í„°ë² ì´ìŠ¤ì™€ ë§¤ì¹­í•˜ì—¬ ì‹ ë¢°ë„ í–¥ìƒ
            - 15ê°œ CAD ì‹¬ë³¼ì— ëŒ€í•œ ê²€ì¦ëœ ì •ë‹µì§€ í™œìš©
            """)
            return

        # Enhanced OCR ê²°ê³¼ í†µê³„
        st.markdown("### ğŸ“Š Enhanced OCR í†µê³„")
        col1, col2, col3, col4 = st.columns(4)

        enhanced_results = st.session_state.enhanced_ocr_results
        primary_detections = enhanced_results.get('primary_detections', [])
        ocr_candidates = enhanced_results.get('ocr_candidates', [])
        verified_detections = enhanced_results.get('verified_detections', [])

        total_primary = len(primary_detections)
        total_candidates = len(ocr_candidates)
        total_verified = len(verified_detections)

        with col1:
            st.metric("ì¼ë°˜ ê²€ì¶œ", total_primary)
        with col2:
            st.metric("OCR í›„ë³´", total_candidates)
        with col3:
            st.metric("OCR ê²€ì¦ ì„±ê³µ", total_verified)
        with col4:
            verification_rate = (total_verified / total_candidates * 100) if total_candidates > 0 else 0
            st.metric("ê²€ì¦ ì„±ê³µë¥ ", f"{verification_rate:.1f}%")

        # í•„í„°ë§ ì˜µì…˜
        st.markdown("### ğŸ”§ í•„í„°ë§ ì˜µì…˜")
        filter_col1, filter_col2 = st.columns(2)

        with filter_col1:
            show_primary = st.checkbox("ğŸ¯ ì¼ë°˜ ê²€ì¶œ í‘œì‹œ", value=True)
        with filter_col2:
            show_verified = st.checkbox("âœ… OCR ê²€ì¦ ê²€ì¶œ í‘œì‹œ", value=True)

        # ê²°ê³¼ í•„í„°ë§
        filtered_results = []
        if show_primary:
            for det in primary_detections:
                det['detection_type'] = 'primary'
                filtered_results.append(det)
        if show_verified:
            for det in verified_detections:
                det['detection_type'] = 'ocr_verified'
                filtered_results.append(det)

        # Enhanced OCR ìƒì„¸ ê²°ê³¼ ì„¹ì…˜ì€ ì œê±°ë¨ - ë©”ì¸ ê²€ì¶œ ê²°ê³¼ í…Œì´ë¸”ì— í†µí•©ë¨

        # Enhanced OCR Ground Truth ê·œì¹™ í‘œì‹œ
        st.markdown("### ğŸ“– Enhanced OCR Ground Truth ë§¤ì¹­ ê·œì¹™")
        with st.expander("Ground Truth ë§¤ì¹­ ê·œì¹™ ë³´ê¸°"):
            st.markdown("""
            **Enhanced OCR ì´ì¤‘ ì„ê³„ê°’ ê²€ì¶œ:**
            - **ì¼ë°˜ ê²€ì¶œ**: ì‹ ë¢°ë„ 0.25 ì´ìƒ (1ì°¨ ê²€ì¶œ)
            - **í›„ë³´ ê²€ì¶œ**: ì‹ ë¢°ë„ 0.1 ì´ìƒ (OCR ê²€ì¦ìš©)

            **PaddleOCR í…ìŠ¤íŠ¸ ì¶”ì¶œ:**
            - API ì—”ë“œí¬ì¸íŠ¸: http://localhost:8001/ocr
            - ìµœì†Œ ì‹ ë¢°ë„: 0.3 (ë‚®ì€ ì„ê³„ê°’ìœ¼ë¡œ ë” ë§ì€ í…ìŠ¤íŠ¸ í¬ì°©)

            **Ground Truth ë§¤ì¹­ ê·œì¹™:**
            - **HUB-8PORT**: "8.A", "8-A", "8A" â†’ ì‹ ë¢°ë„ 0.95
            - **CPU1513-1PN**: "1513 1PN CP", "CP 1513 -IPN" â†’ ì‹ ë¢°ë„ 0.95
            - **CPU1214C**: "CPU-1214C", "CPU-I214C" â†’ ì‹ ë¢°ë„ 0.95
            - **TERMINAL_ST4**: "ST4", "ST-4", "32A" â†’ ì‹ ë¢°ë„ 0.85
            - **BREAKER**: "BK63H", "BK-63H", "63H" â†’ ì‹ ë¢°ë„ 0.90
            - **TRANSFORMER**: "MST600VA", "MST-600VA", "600VA" â†’ ì‹ ë¢°ë„ 0.85

            âš¡ **ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜**:
            1. í´ë˜ìŠ¤ëª… ì •ê·œí™” (ì–¸ë”ìŠ¤ì½”ì–´ â†’ ê³µë°±)
            2. í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚° (Levenshtein ê±°ë¦¬)
            3. ë¶€ë¶„ ì¼ì¹˜ í™•ì¸ (0.7 ì„ê³„ê°’)
            4. ì‹ ë¢°ë„ ë¶€ìŠ¤íŠ¸ ì ìš©
            """)

    def render_symbol_reference_panel(self):
        """ì˜¤ë¥¸ìª½ ì‚¬ì´ë“œ íŒ¨ë„ì— ì‹¬ë³¼ ì°¸ì¡° ë¦¬ìŠ¤íŠ¸ í‘œì‹œ"""
        st.markdown("### ğŸ“š ì‹¬ë³¼ ì°¸ì¡°")
        st.caption("ìŠ¹ì¸/ê±°ë¶€ ì‹œ ì°¸ê³ ìš©")

        # class_examples í´ë”ì˜ ëª¨ë“  ì´ë¯¸ì§€ ë¡œë“œ
        import glob
        from PIL import Image
        example_images = glob.glob(os.path.join(self.class_examples_path, "*.jpg"))
        example_images.sort()  # íŒŒì¼ëª… ìˆœìœ¼ë¡œ ì •ë ¬

        if not example_images:
            st.info("ì‹¬ë³¼ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ìŠ¤í¬ë¡¤ ê°€ëŠ¥í•œ ì»¨í…Œì´ë„ˆ ìƒì„±
        with st.container():
            for img_path in example_images:
                filename = os.path.basename(img_path)
                # íŒŒì¼ëª…ì—ì„œ ì •ë³´ ì¶”ì¶œ
                parts = filename.replace('.jpg', '').split('_')
                if len(parts) >= 3:
                    class_idx = parts[0].replace('class_', '')
                    class_nums = parts[1]
                    class_name = '_'.join(parts[2:])

                    # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (1/2 í¬ê¸°ë¡œ ë³€ê²½)
                    img = Image.open(img_path)
                    width, height = img.size
                    new_width = width // 2
                    new_height = height // 2
                    img_resized = img.resize((new_width, new_height), Image.Resampling.LANCZOS)

                    # í´ë˜ìŠ¤ ë²ˆí˜¸ì™€ ì´ë¦„ì„ í¬ê²Œ í‘œì‹œ
                    st.markdown(f"**<span style='font-size: 20px;'>{class_idx}</span>**", unsafe_allow_html=True)
                    st.markdown(f"<span style='font-size: 16px;'>{class_name}</span>", unsafe_allow_html=True)

                    # ì´ë¯¸ì§€ í‘œì‹œ (ê³ ì • í¬ê¸°)
                    st.image(img_resized)
                    st.markdown("---")  # êµ¬ë¶„ì„ 
                else:
                    # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (1/2 í¬ê¸°ë¡œ ë³€ê²½)
                    img = Image.open(img_path)
                    width, height = img.size
                    img_resized = img.resize((width // 2, height // 2), Image.Resampling.LANCZOS)
                    st.image(img_resized, caption=filename)
                    st.markdown("---")

    def get_class_example_image(self, class_name):
        """í´ë˜ìŠ¤ë³„ ì‹¤ì œ ì‹¬ë³¼ ì´ë¯¸ì§€ ì°¾ê¸°

        class_examples í´ë”ì—ì„œ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ì´ë¯¸ì§€ ì°¾ê¸°:
        - íŒ¨í„´: class_XX_YY_CLASS_NAME_*.jpg
        - ì˜ˆ: class_13_24,25_GRAPHIC PANEL_6AV7240-3MC07-0HA0(GP)_p01.jpg
        """
        if not os.path.exists(self.class_examples_path):
            return None

        # í´ë˜ìŠ¤ ì´ë¦„ìœ¼ë¡œ ì§ì ‘ ë§¤ì¹­ ì‹œë„
        import glob

        # íŒŒì¼ëª…ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì²˜ë¦¬
        safe_name = class_name.replace('/', '_').replace('\\', '_').replace(':', '_')

        # ì—¬ëŸ¬ íŒ¨í„´ìœ¼ë¡œ ì‹œë„
        patterns = [
            # ì •í™•í•œ í´ë˜ìŠ¤ ì´ë¦„ ë§¤ì¹­
            f"*_{safe_name}_*.jpg",
            # ë¶€ë¶„ ë§¤ì¹­ (ê³µë°± ì œê±°)
            f"*_{safe_name.replace(' ', '*')}*.jpg",
            # í´ë˜ìŠ¤ ì´ë¦„ì˜ ì¼ë¶€ë§Œ ë§¤ì¹­
            f"*{safe_name.split()[0] if ' ' in safe_name else safe_name}*.jpg"
        ]

        for pattern in patterns:
            matching_files = glob.glob(os.path.join(self.class_examples_path, pattern))
            if matching_files:
                # ì²« ë²ˆì§¸ ë§¤ì¹­ íŒŒì¼ ë°˜í™˜
                return matching_files[0]

        # data.yaml ê¸°ë°˜ ê²€ìƒ‰ (fallback)
        if self.data_yaml:
            class_names = self.data_yaml.get('names', [])
            try:
                class_idx = class_names.index(class_name)
                # ì¸ë±ìŠ¤ ê¸°ë°˜ íŒ¨í„´ìœ¼ë¡œ ê²€ìƒ‰
                pattern = f"class_{class_idx:02d}_*.jpg"
                matching_files = glob.glob(os.path.join(self.class_examples_path, pattern))
                if matching_files:
                    return matching_files[0]
            except (ValueError, IndexError):
                pass

        return None

    def load_ground_truth_labels(self, image_filename):
        """ì •ë‹µ ë¼ë²¨ ë¡œë“œ ë° íŒŒì‹±"""
        # ì´ë¯¸ì§€ íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°
        base_name = os.path.splitext(image_filename)[0]
        label_path = os.path.join(self.test_drawings_path, "labels", f"{base_name}.txt")

        ground_truth = []
        if os.path.exists(label_path):
            with open(label_path, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        parts = line.split()
                        if len(parts) >= 5:
                            class_id = int(parts[0])
                            x_center = float(parts[1])
                            y_center = float(parts[2])
                            width = float(parts[3])
                            height = float(parts[4])

                            # ì´ë¯¸ì§€ í¬ê¸°ë¡œ ì ˆëŒ€ ì¢Œí‘œ ë³€í™˜
                            if st.session_state.current_image:
                                img_h, img_w = st.session_state.current_image['image'].shape[:2]
                                x1 = int((x_center - width/2) * img_w)
                                y1 = int((y_center - height/2) * img_h)
                                x2 = int((x_center + width/2) * img_w)
                                y2 = int((y_center + height/2) * img_h)

                                # data.yamlì˜ í´ë˜ìŠ¤ ì´ë¦„ ì‚¬ìš©
                                if self.data_yaml and 'names' in self.data_yaml:
                                    class_names = self.data_yaml['names']
                                    if class_id < len(class_names):
                                        ground_truth.append({
                                            'class_id': class_id,
                                            'class_name': class_names[class_id],
                                            'bbox': [x1, y1, x2, y2],
                                            'confidence': 1.0,  # ì •ë‹µì€ 100% ì‹ ë¢°ë„
                                            'is_ground_truth': True
                                        })
        return ground_truth

    def render_detection_list(self, detections, prefix):
        """ê²€ì¶œ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ í‘œì‹œ (ì •ë‹µ ë¹„êµ í¬í•¨)"""
        import os  # í•¨ìˆ˜ ë‚´ì—ì„œ ëª…ì‹œì ìœ¼ë¡œ import
        # ê²€ì¶œ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ í‘œì‹œ
        st.subheader("ğŸ” ê²€ì¶œ ê²°ê³¼")
        for i, detection in enumerate(detections):
            status_key = f"{prefix}_{i}"
            current_status = st.session_state.verification_status.get(status_key, "pending")

            # ìƒíƒœì— ë”°ë¥¸ ì»¨í…Œì´ë„ˆ ìŠ¤íƒ€ì¼
            if current_status == "approved":
                container_style = "background-color: #d4edda; border: 1px solid #c3e6cb; padding: 10px; border-radius: 5px; margin-bottom: 10px;"
            elif current_status == "rejected":
                container_style = "background-color: #f8d7da; border: 1px solid #f5c6cb; padding: 10px; border-radius: 5px; margin-bottom: 10px;"
            else:
                container_style = "background-color: #f8f9fa; border: 1px solid #dee2e6; padding: 10px; border-radius: 5px; margin-bottom: 10px;"

            with st.container():
                col1, col2, col3, col4 = st.columns([2, 4, 2, 2])

                with col1:
                    # ê²€ì¶œëœ ì´ë¯¸ì§€ì™€ ì •ë‹µ ì´ë¯¸ì§€ë¥¼ ë‚˜ë€íˆ í‘œì‹œ
                    x1, y1, x2, y2 = detection['bbox']
                    image = st.session_state.current_image['image']
                    h, w = image.shape[:2]
                    x1, y1, x2, y2 = max(0, x1), max(0, y1), min(w, x2), min(h, y2)
                    cropped = image[y1:y2, x1:x2]

                    # ì´ë¯¸ì§€ë¥¼ ê°€ë¡œë¡œ í‘œì‹œí•˜ê¸° ìœ„í•œ êµ¬ì¡°
                    st.write("**ğŸ” ê²€ì¶œ ê²°ê³¼**")

                    # ì„¸ ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì¤€ë¹„
                    images_to_show = []
                    captions = []

                    # 1. Ground Truth ì´ë¯¸ì§€
                    ground_truth = self.load_ground_truth_for_current_image()
                    gt_img = None
                    if ground_truth:
                        # í˜„ì¬ ê²€ì¶œ ìœ„ì¹˜ì™€ ê°€ì¥ ê°€ê¹Œìš´ Ground Truth ì°¾ê¸°
                        best_gt = None
                        best_iou = 0
                        # ê²€ì¶œ bboxë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
                        det_bbox = [int(x) for x in detection['bbox']]

                        for gt in ground_truth:
                            gt_bbox = self.yolo_to_xyxy(
                                gt['x_center'], gt['y_center'],
                                gt['width'], gt['height'],
                                w, h
                            )
                            iou = self.calculate_iou(det_bbox, gt_bbox)
                            if iou > best_iou:
                                best_iou = iou
                                best_gt = gt

                        # IoU ì„ê³„ê°’ì„ 0.1ë¡œ ë‚®ì¶¤ (10% ì´ìƒ ê²¹ì¹˜ë©´ ë§¤ì¹­)
                        if best_gt and best_iou > 0.1:
                            # Ground Truth ë°•ìŠ¤ ì˜ì—­ crop
                            gt_x1, gt_y1, gt_x2, gt_y2 = self.yolo_to_xyxy(
                                best_gt['x_center'], best_gt['y_center'],
                                best_gt['width'], best_gt['height'],
                                w, h
                            )
                            gt_x1, gt_y1, gt_x2, gt_y2 = max(0, gt_x1), max(0, gt_y1), min(w, gt_x2), min(h, gt_y2)
                            gt_cropped = image[gt_y1:gt_y2, gt_x1:gt_x2]
                            if gt_cropped.size > 0:
                                gt_img = gt_cropped
                                images_to_show.append(gt_cropped)
                                captions.append(f"ğŸ·ï¸ GT: {best_gt['class_name']} (IoU:{best_iou:.2f})")

                    if gt_img is None:
                        # GT ì´ë¯¸ì§€ê°€ ì—†ì„ ë•Œ placeholder
                        import numpy as np
                        placeholder = np.ones((100, 100, 3), dtype=np.uint8) * 200
                        images_to_show.append(placeholder)
                        captions.append("ğŸ·ï¸ GT: ì—†ìŒ")

                    # 2. ëª¨ë¸ ê²€ì¶œ ê²°ê³¼
                    if cropped.size > 0:
                        images_to_show.append(cropped)
                        captions.append(f"ğŸ” ê²€ì¶œ: {detection['class_name']}")
                    else:
                        import numpy as np
                        placeholder = np.ones((100, 100, 3), dtype=np.uint8) * 200
                        images_to_show.append(placeholder)
                        captions.append("ğŸ” ê²€ì¶œ: ì˜¤ë¥˜")

                    # 3. ì‹¤ì œ ì‹¬ë³¼ ì´ë¯¸ì§€
                    example_path = self.get_class_example_image(detection['class_name'])
                    if example_path and os.path.exists(example_path):
                        example_img = Image.open(example_path)
                        # numpy arrayë¡œ ë³€í™˜
                        import numpy as np
                        example_np = np.array(example_img)
                        images_to_show.append(example_np)
                        captions.append(f"ğŸ“š ì‹¤ì œ: {detection['class_name']}")
                    else:
                        import numpy as np
                        placeholder = np.ones((100, 100, 3), dtype=np.uint8) * 200
                        images_to_show.append(placeholder)
                        captions.append("ğŸ“š ì‹¤ì œ: ì—†ìŒ")

                    # ì´ë¯¸ì§€ë“¤ì„ ê°€ë¡œë¡œ í‘œì‹œ - HTMLê³¼ base64 ì¸ì½”ë”© ì‚¬ìš©
                    import base64
                    from io import BytesIO
                    import numpy as np

                    # HTML êµ¬ì¡°ë¥¼ ë” ì•ˆì •ì ìœ¼ë¡œ êµ¬ì„±
                    html_parts = ['<div style="display: flex; gap: 15px; align-items: center; margin: 10px 0;">']

                    for img, cap in zip(images_to_show, captions):
                        # numpy arrayë¥¼ PIL Imageë¡œ ë³€í™˜
                        if isinstance(img, np.ndarray):
                            if img.ndim == 2:  # grayscale
                                img_pil = Image.fromarray(img.astype(np.uint8))
                            else:  # color
                                img_pil = Image.fromarray(img.astype(np.uint8))
                        else:
                            img_pil = img

                        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
                        buffered = BytesIO()
                        img_pil.save(buffered, format="PNG")
                        img_base64 = base64.b64encode(buffered.getvalue()).decode()

                        # ê° ì´ë¯¸ì§€ ì•„ì´í…œì„ ë³„ë„ì˜ ë¬¸ìì—´ë¡œ ìƒì„±
                        item_html = (
                            '<div style="text-align: center; flex-shrink: 0;">'
                            f'<img src="data:image/png;base64,{img_base64}" '
                            'style="width: 100px; height: auto; border: 1px solid #ddd; padding: 2px; display: block;">'
                            f'<p style="font-size: 11px; margin-top: 5px; word-wrap: break-word; max-width: 100px;">{cap}</p>'
                            '</div>'
                        )
                        html_parts.append(item_html)

                    html_parts.append('</div>')
                    final_html = ''.join(html_parts)
                    st.markdown(final_html, unsafe_allow_html=True)

                    # OCR ê²°ê³¼ í‘œì‹œ
                    if detection.get('ocr_text'):
                        st.info(f"ğŸ” **OCR ê²°ê³¼**: '{detection['ocr_text']}'")
                        if detection.get('matched_truth'):
                            st.caption(f"GT: {detection['matched_truth']}")
                    elif detection.get('detection_type') == 'ocr_verified':
                        st.info("âœ… OCR ê²€ì¦ë¨")
                    elif st.session_state.get('use_enhanced_ocr', False):
                        st.caption("OCR ì¶”ì¶œ ì‹¤íŒ¨")
                    else:
                        st.caption("OCR ë¯¸ì ìš©")

                with col2:
                    # í˜„ì¬ í´ë˜ìŠ¤ ì´ë¦„ (ìˆ˜ì •ëœ ê²ƒì´ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©)
                    current_class_name = st.session_state.modified_classes.get(
                        status_key, detection['class_name']
                    )

                    # í•­ìƒ í´ë˜ìŠ¤ ì´ë¦„ í‘œì‹œ
                    st.markdown(f"### {current_class_name}")
                    if current_class_name != detection['class_name']:
                        st.caption(f"(ì›ë˜: {detection['class_name']})")

                    # í¸ì§‘ ëª¨ë“œì¸ì§€ í™•ì¸
                    is_editing = st.session_state.edit_mode.get(status_key, False)

                    # í¸ì§‘ ëª¨ë“œì¼ ë•Œ ë“œë¡­ë‹¤ìš´ í‘œì‹œ (í† ê¸€ í˜•íƒœ)
                    if is_editing:
                        # ì‚¬ìš© ê°€ëŠ¥í•œ í´ë˜ìŠ¤ ëª©ë¡ (class_examples ë””ë ‰í† ë¦¬ ê¸°ë°˜)
                        available_classes = load_class_names_from_examples_cached()
                        if current_class_name not in available_classes:
                            available_classes.append(current_class_name)

                        # ì´ë¯¸ load_class_names_from_examples()ì—ì„œ ì •ë ¬ë¨

                        # ë“œë¡­ë‹¤ìš´ì„ ë°”ë¡œ í‘œì‹œ (on_change ì—†ì´)
                        new_class_name = st.selectbox(
                            "ğŸ”„ ìƒˆ í´ë˜ìŠ¤ ì„ íƒ:",
                            available_classes,
                            index=available_classes.index(current_class_name) if current_class_name in available_classes else 0,
                            key=f"select_new_{prefix}_{i}",
                            help="í´ë˜ìŠ¤ë¥¼ ì„ íƒí•œ í›„ 'ğŸ’¾ ìˆ˜ì • ì™„ë£Œ' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”"
                        )

                        # ì„ íƒëœ ê°’ì„ ì„ì‹œë¡œ ì €ì¥
                        st.session_state[f"temp_class_{status_key}"] = new_class_name

                    # ì •ë³´ë¥¼ ì„¸ë¡œë¡œ ë‚˜ì—´
                    st.write(f"ğŸ“Š **ì‹ ë¢°ë„**: {detection['confidence']:.1%}")
                    model_name = detection.get('model', detection.get('model_id', 'unknown'))
                    st.write(f"ğŸ¤– **ëª¨ë¸**: {model_name}")
                    st.write(f"ğŸ“ **ìœ„ì¹˜**: ({x1}, {y1})")
                    st.write(f"ğŸ“ **í¬ê¸°**: {x2-x1}Ã—{y2-y1}px")


                with col3:
                    # í˜„ì¬ ìƒíƒœ í‘œì‹œ
                    if current_status == "approved":
                        st.success("âœ… ìŠ¹ì¸ë¨")
                    elif current_status == "rejected":
                        st.error("âŒ ê±°ë¶€ë¨")
                    else:
                        st.info("â³ ëŒ€ê¸°ì¤‘")

                with col4:
                    # ì•¡ì…˜ ë²„íŠ¼
                    is_editing = st.session_state.edit_mode.get(status_key, False)

                    # ëª¨ë“  ë²„íŠ¼ì„ ì„¸ë¡œë¡œ ë°°ì¹˜
                    if st.button("âœ… ìŠ¹ì¸", key=f"approve_{prefix}_{i}",
                                disabled=(current_status=="approved" or is_editing),
                                use_container_width=True):
                        st.session_state.verification_status[status_key] = "approved"
                        st.rerun()

                    if st.button("âŒ ê±°ë¶€", key=f"reject_{prefix}_{i}",
                                disabled=(current_status=="rejected" or is_editing),
                                use_container_width=True):
                        st.session_state.verification_status[status_key] = "rejected"
                        st.rerun()

                    # í† ê¸€ ë°©ì‹ìœ¼ë¡œ ìˆ˜ì • ë²„íŠ¼ ë™ì‘
                    edit_button_label = "ğŸ’¾ ìˆ˜ì • ì™„ë£Œ" if is_editing else "âœï¸ ìˆ˜ì •"
                    edit_button_type = "primary" if is_editing else "secondary"
                    if st.button(edit_button_label, key=f"edit_{prefix}_{i}",
                                use_container_width=True,
                                type=edit_button_type):
                        if is_editing:
                            # ìˆ˜ì • ì™„ë£Œ - ì„ íƒëœ í´ë˜ìŠ¤ ì €ì¥
                            temp_class = st.session_state.get(f"temp_class_{status_key}")
                            if temp_class:
                                st.session_state.modified_classes[status_key] = temp_class
                            st.session_state.edit_mode[status_key] = False
                        else:
                            # ìˆ˜ì • ì‹œì‘
                            st.session_state.edit_mode[status_key] = True
                        st.rerun()

                    if st.button("â†©ï¸ ì´ˆê¸°í™”", key=f"reset_{prefix}_{i}",
                                use_container_width=True):
                        if status_key in st.session_state.verification_status:
                            del st.session_state.verification_status[status_key]
                        if status_key in st.session_state.modified_classes:
                            del st.session_state.modified_classes[status_key]
                        if status_key in st.session_state.edit_mode:
                            del st.session_state.edit_mode[status_key]
                        st.rerun()
        
        # ìˆ˜ì‘ì—… ë¼ë²¨ë§ ì„¹ì…˜
        st.subheader("ğŸ¨ ìˆ˜ì‘ì—… ë¼ë²¨ë§")
        st.write("ëª¨ë¸ì´ ë†“ì¹œ ë¶€í’ˆì´ ìˆë‹¤ë©´ ë„ë©´ ì´ë¯¸ì§€ ìœ„ì— ì§ì ‘ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë ¤ì„œ ì¶”ê°€í•˜ì„¸ìš”:")

        # ìˆ˜ì‘ì—… ë¼ë²¨ë§ í™œì„±í™” ì˜µì…˜ - prefixë¥¼ ì‚¬ìš©í•˜ì—¬ ê³ ìœ í•œ key ìƒì„±
        enable_manual = st.checkbox("ìˆ˜ì‘ì—… ë¼ë²¨ë§ í™œì„±í™”", value=False, key=f"enable_manual_labeling_{prefix}")

        if enable_manual:
            if not CANVAS_AVAILABLE:
                st.error("âŒ streamlit-drawable-canvasê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                st.code("pip install streamlit-drawable-canvas")
                return

            try:
                # ì´ë¯¸ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
                if not (st.session_state.current_image and 'image' in st.session_state.current_image):
                    st.info("ì´ë¯¸ì§€ë¥¼ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”.")
                    return

                img_array = st.session_state.current_image['image']
                # BGR to RGB ë³€í™˜ (OpenCV ì´ë¯¸ì§€ì¸ ê²½ìš°)
                if len(img_array.shape) == 3 and img_array.shape[2] == 3:
                    img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)

                # ìŠ¹ì¸ëœ ê²€ì¶œ ê²°ê³¼ë¥¼ ë¨¼ì € ì´ë¯¸ì§€ì— ê·¸ë¦¼
                approved_detections = []
                for i, detection in enumerate(detections):
                    status_key = f"{prefix}_{i}"
                    if st.session_state.verification_status.get(status_key) == "approved":
                        approved_detections.append(detection)

                # ìŠ¹ì¸ëœ ë°•ìŠ¤ë“¤ì„ ë°°ê²½ ì´ë¯¸ì§€ì— ê·¸ë¦¼
                background_img = img_array.copy()
                for det in approved_detections:
                    x1, y1, x2, y2 = det['bbox']
                    # ìŠ¹ì¸ëœ ë°•ìŠ¤ëŠ” ì´ˆë¡ìƒ‰ìœ¼ë¡œ í‘œì‹œ
                    cv2.rectangle(background_img, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    # í´ë˜ìŠ¤ ì´ë¦„ í‘œì‹œ
                    label = det['class_name']
                    label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
                    cv2.rectangle(background_img, (x1, y1-20), (x1+label_size[0], y1), (0, 255, 0), -1)
                    cv2.putText(background_img, label, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

                # ê·¸ë¦¬ê¸° ë„êµ¬ ì„¤ì • (ë„¤ëª¨ ë°•ìŠ¤ë§Œ ì‚¬ìš©)
                drawing_mode = "rect"  # ê³ ì •
                stroke_width = 3  # ë” ë‘êº¼ìš´ ì„ 
                stroke_color = "#FF0000"  # ë¹¨ê°„ìƒ‰ ê³ ì •

                # ìˆ˜ì‘ì—… ê²€ì¶œ ì‹œ ì‚¬ìš©í•  í´ë˜ìŠ¤ ì„ íƒ
                available_classes = load_class_names_from_examples_cached()
                selected_class = st.selectbox(
                    "ì¶”ê°€í•  ë¶€í’ˆ ì¢…ë¥˜:",
                    available_classes,
                    key=f"manual_class_{prefix}"
                )

                # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (ìº”ë²„ìŠ¤ìš©)
                canvas_height = 700
                img_height, img_width = background_img.shape[:2]
                aspect_ratio = img_width / img_height
                canvas_width = int(canvas_height * aspect_ratio)

                # ì´ë¯¸ì§€ë¥¼ ìº”ë²„ìŠ¤ í¬ê¸°ì— ë§ê²Œ ë¦¬ì‚¬ì´ì¦ˆ
                img_resized = cv2.resize(background_img, (canvas_width, canvas_height))

                # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
                pil_img = Image.fromarray(img_resized.astype('uint8'))

                st.write("âœï¸ ìˆ˜ì‘ì—… ë¼ë²¨ë§:")
                col1, col2 = st.columns([3, 1])

                with col1:
                    st.info("ğŸ¯ ë„ë©´ ì´ë¯¸ì§€ ìœ„ì— ì§ì ‘ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë ¤ì£¼ì„¸ìš”:")
                    st.caption("â€¢ ğŸŸ¢ ì´ˆë¡ìƒ‰ ë°•ìŠ¤: ì´ë¯¸ ìŠ¹ì¸ëœ ë¶€í’ˆ")
                    st.caption("â€¢ ğŸ”´ ë¹¨ê°„ìƒ‰ ë°•ìŠ¤: ìƒˆë¡œ ì¶”ê°€í•  ë¶€í’ˆ")

                with col2:
                    if st.button("ğŸ—‘ï¸ ëª¨ë“  ë°•ìŠ¤ ì§€ìš°ê¸°", key=f"clear_canvas_{prefix}"):
                        st.session_state[f"manual_labeling_canvas_{prefix}"] = None
                        st.rerun()

                # ìº”ë²„ìŠ¤ ìƒì„± - ë„ë©´ ì´ë¯¸ì§€ë¥¼ ë°°ê²½ìœ¼ë¡œ ì§ì ‘ ì‚¬ìš©
                canvas_result = st_canvas(
                    fill_color="rgba(255, 0, 0, 0.3)",  # ë°˜íˆ¬ëª… ë¹¨ê°„ìƒ‰ ì±„ìš°ê¸°
                    stroke_width=3,
                    stroke_color="#FF0000",  # ë¹¨ê°„ìƒ‰ í…Œë‘ë¦¬
                    background_image=pil_img,  # ë„ë©´ ì´ë¯¸ì§€(ìŠ¹ì¸ëœ ë°•ìŠ¤ í¬í•¨)ë¥¼ ë°°ê²½ìœ¼ë¡œ ì„¤ì •
                    update_streamlit=True,
                    height=canvas_height,
                    width=canvas_width,
                    drawing_mode="rect",
                    key=f"manual_labeling_canvas_{prefix}",
                    display_toolbar=True,
                )

                # ìˆ˜ì‘ì—…ìœ¼ë¡œ ê·¸ë¦° ë°•ìŠ¤ë“¤ ì²˜ë¦¬ (ìƒˆë¡œ ì¶”ê°€ëœ ê²ƒë§Œ)
                if canvas_result and canvas_result.json_data is not None:
                    all_objects = canvas_result.json_data.get("objects", [])
                    if len(all_objects) > 0:
                        # ëª¨ë“  ê°ì²´ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
                        objects_df = pd.json_normalize(all_objects)
                        st.write(f"ğŸ“¦ ê·¸ë ¤ì§„ ë°•ìŠ¤: {len(objects_df)}ê°œ")

                        # ê° ë°•ìŠ¤ì— ëŒ€í•´ ë¶€í’ˆ ì¢…ë¥˜ ì„ íƒ
                        st.write("ğŸ¯ ê° ë°•ìŠ¤ì— ëŒ€í•´ ë¶€í’ˆ ì¢…ë¥˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:")

                        # ì‚¬ìš© ê°€ëŠ¥í•œ í´ë˜ìŠ¤ ëª©ë¡
                        available_classes = load_class_names_from_examples_cached()

                        box_classes = {}
                        for idx in range(len(objects_df)):
                            col1, col2 = st.columns([1, 3])
                            with col1:
                                st.write(f"ë°•ìŠ¤ {idx+1}:")
                            with col2:
                                selected_class = st.selectbox(
                                    f"ë¶€í’ˆ ì„ íƒ",
                                    available_classes,
                                    key=f"box_class_{prefix}_{idx}",
                                    label_visibility="collapsed"
                                )
                                box_classes[idx] = selected_class

                        # ìˆ˜ì‘ì—… ê²€ì¶œì„ ì„¸ì…˜ ìƒíƒœì— ì¶”ê°€
                        if st.button("â• ì„ íƒëœ ë¶€í’ˆë“¤ ì¶”ê°€", key=f"add_manual_detections_{prefix}", type="primary"):
                            manual_detections = []

                            # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
                            original_img = st.session_state.current_image['image']
                            orig_height, orig_width = original_img.shape[:2]

                            # ìŠ¤ì¼€ì¼ë§ íŒ©í„° ê³„ì‚° (ìº”ë²„ìŠ¤ â†’ ì›ë³¸ ì´ë¯¸ì§€)
                            scale_x = orig_width / canvas_width
                            scale_y = orig_height / canvas_height

                            for index, row in objects_df.iterrows():
                                # ìº”ë²„ìŠ¤ ì¢Œí‘œë¥¼ ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜
                                left = int(row['left'] * scale_x)
                                top = int(row['top'] * scale_y)
                                right = int((row['left'] + row['width']) * scale_x)
                                bottom = int((row['top'] + row['height']) * scale_y)

                                # ì´ ë°•ìŠ¤ì— ëŒ€í•´ ì„ íƒëœ í´ë˜ìŠ¤ ê°€ì ¸ì˜¤ê¸°
                                selected_class = box_classes.get(index, available_classes[0])

                                # í´ë˜ìŠ¤ ID ì¶”ì¶œ (í´ë˜ìŠ¤ëª…ì˜ ì²« ë²ˆì§¸ ìˆ«ì ë¶€ë¶„)
                                class_id = 0  # ê¸°ë³¸ê°’
                                try:
                                    # í´ë˜ìŠ¤ëª…ì—ì„œ ì²« ë²ˆì§¸ ìˆ«ì ì¶”ì¶œ
                                    # ì˜ˆ: "10_BUZZER..." -> 10
                                    parts = selected_class.split('_')
                                    if parts and parts[0].replace(',', '').isdigit():
                                        class_id = int(parts[0].split(',')[0])  # ì‰¼í‘œê°€ ìˆëŠ” ê²½ìš° ì²« ë²ˆì§¸ ìˆ«ì
                                except:
                                    class_id = available_classes.index(selected_class) if selected_class in available_classes else 0

                                # YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                                manual_det = {
                                    'class_name': selected_class,
                                    'class_id': class_id,
                                    'confidence': 1.0,  # ìˆ˜ì‘ì—…ì€ 100% ì‹ ë¢°ë„
                                    'bbox': [left, top, right, bottom],
                                    'model_id': 'manual',
                                    'model': 'manual'  # render_detection_listì—ì„œ ì‚¬ìš©í•˜ëŠ” í•„ë“œ
                                }
                                manual_detections.append(manual_det)

                            # ì„¸ì…˜ ìƒíƒœì— ì¶”ê°€
                            if 'manual' not in st.session_state.detection_results:
                                st.session_state.detection_results['manual'] = []
                            st.session_state.detection_results['manual'].extend(manual_detections)

                            st.success(f"âœ… {len(manual_detections)}ê°œì˜ ìˆ˜ì‘ì—… ê²€ì¶œì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            st.rerun()

            except Exception as e:
                st.error(f"ìˆ˜ì‘ì—… ë¼ë²¨ë§ ì˜¤ë¥˜: {str(e)}")
                st.info("streamlit-drawable-canvas íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”: pip install streamlit-drawable-canvas")
                import traceback
                with st.expander("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´"):
                    st.code(traceback.format_exc())
        else:
            st.info("ğŸ–Œï¸ ìˆ˜ì‘ì—… ë¼ë²¨ë§ì„ ì‚¬ìš©í•˜ë ¤ë©´ ìœ„ì˜ ì²´í¬ë°•ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”. ë„ë©´ ì´ë¯¸ì§€ ìœ„ì— ì§ì ‘ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    def render_detection_list_with_voting(self, detections, prefix):
        """ê²€ì¶œ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ í‘œì‹œ (Voting ì •ë³´ í¬í•¨)"""
        # ê²€ì¶œ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ í‘œì‹œ
        st.subheader("ğŸ” ê²€ì¶œ ê²°ê³¼ (Voting ì •ë³´ í¬í•¨)")
        for i, detection in enumerate(detections):
            status_key = f"{prefix}_{i}"
            current_status = st.session_state.verification_status.get(status_key, "pending")

            # ìƒíƒœì— ë”°ë¥¸ ì»¨í…Œì´ë„ˆ ìŠ¤íƒ€ì¼
            if current_status == "approved":
                container_style = "background-color: #d4edda; border: 1px solid #c3e6cb; padding: 10px; border-radius: 5px; margin-bottom: 10px;"
            elif current_status == "rejected":
                container_style = "background-color: #f8d7da; border: 1px solid #f5c6cb; padding: 10px; border-radius: 5px; margin-bottom: 10px;"
            else:
                container_style = "background-color: #f8f9fa; border: 1px solid #dee2e6; padding: 10px; border-radius: 5px; margin-bottom: 10px;"

            with st.container():
                col1, col2, col3, col4 = st.columns([2, 4, 2, 2])

                with col1:
                    # ê²€ì¶œëœ ì´ë¯¸ì§€ì™€ ì •ë‹µ ì´ë¯¸ì§€ë¥¼ ë‚˜ë€íˆ í‘œì‹œ
                    x1, y1, x2, y2 = detection['bbox']
                    image = st.session_state.current_image['image']
                    h, w = image.shape[:2]
                    x1, y1, x2, y2 = max(0, x1), max(0, y1), min(w, x2), min(h, y2)
                    cropped = image[y1:y2, x1:x2]

                    # ì´ë¯¸ì§€ë¥¼ ê°€ë¡œë¡œ í‘œì‹œí•˜ê¸° ìœ„í•œ HTML ìƒì„±
                    st.subheader("ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¹„êµ")
                    ground_truth = self.load_ground_truth_for_current_image()
                    if ground_truth:
                        # í˜„ì¬ ê²€ì¶œ ìœ„ì¹˜ì™€ ê°€ì¥ ê°€ê¹Œìš´ Ground Truth ì°¾ê¸°
                        best_gt = None
                        best_iou = 0
                        # ê²€ì¶œ bboxë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
                        det_bbox = [int(x) for x in detection['bbox']]

                        for gt in ground_truth:
                            gt_bbox = self.yolo_to_xyxy(
                                gt['x_center'], gt['y_center'],
                                gt['width'], gt['height'],
                                w, h
                            )
                            iou = self.calculate_iou(det_bbox, gt_bbox)
                            if iou > best_iou:
                                best_iou = iou
                                best_gt = gt

                        if best_gt and best_iou > 0.1:  # IoU ì„ê³„ê°’ì„ 0.1ë¡œ ë‚®ì¶¤
                            # Ground Truth ë°•ìŠ¤ ì˜ì—­ crop
                            gt_x1, gt_y1, gt_x2, gt_y2 = self.yolo_to_xyxy(
                                best_gt['x_center'], best_gt['y_center'],
                                best_gt['width'], best_gt['height'],
                                w, h
                            )
                            gt_x1, gt_y1, gt_x2, gt_y2 = max(0, gt_x1), max(0, gt_y1), min(w, gt_x2), min(h, gt_y2)
                            gt_cropped = image[gt_y1:gt_y2, gt_x1:gt_x2]
                            if gt_cropped.size > 0:
                                # Ground Truthì— ì´ë¯¸ class_nameì´ ìˆìŒ (load ì‹œ ì¶”ê°€í•¨)
                                gt_class_name = best_gt.get('class_name', f"Class {best_gt['class_id']}")
                                st.image(gt_cropped, caption=f"GT: {gt_class_name} (IoU:{best_iou:.2f})")
                            else:
                                st.info("GT ì˜ì—­ ì˜¤ë¥˜")
                        elif best_gt:
                            # IoUê°€ ë‚®ë”ë¼ë„ ê°€ì¥ ê°€ê¹Œìš´ GT í‘œì‹œ
                            st.info(f"ë‚®ì€ IoU: {best_iou:.2f}")
                        else:
                            st.info("GT ì—†ìŒ")
                    else:
                        st.info("ë¼ë²¨ ì—†ìŒ")

                    # ëª¨ë¸ ê²€ì¶œ ê²°ê³¼
                    # ëª¨ë¸ì´ ê²€ì¶œí•œ ì´ë¯¸ì§€ í‘œì‹œ
                    st.caption("ğŸ” ëª¨ë¸ ê²€ì¶œ", help="AI ëª¨ë¸(YOLOv8)ì´ í˜„ì¬ ê²€ì¶œí•œ ì˜ì—­ì…ë‹ˆë‹¤. ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œì™€ ì‹ ë¢°ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì¶œëœ ì´ë¯¸ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
                    if cropped.size > 0:
                        st.image(cropped, caption=f"ê²€ì¶œ: {detection['class_name']}")
                    else:
                        st.warning("ê²€ì¶œ ì˜ì—­ ì˜¤ë¥˜")

                    # OCR ê²°ê³¼
                    # OCR ê²°ê³¼ ì»¬ëŸ¼ ì¶”ê°€
                    st.caption("ğŸ” OCR ê²°ê³¼", help="Enhanced OCRë¡œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê²°ê³¼ì…ë‹ˆë‹¤.")
                    if detection.get('ocr_text'):
                        st.success(f"âœ… '{detection['ocr_text']}'")
                        if detection.get('matched_truth'):
                            st.info(f"GT: {detection['matched_truth']}")
                    elif detection.get('detection_type') == 'ocr_verified':
                        st.success("âœ… OCR ê²€ì¦ë¨")
                    elif st.session_state.get('use_enhanced_ocr', False):
                        # Enhanced OCRê°€ í™œì„±í™”ë˜ì—ˆì§€ë§Œ ì´ ê²€ì¶œì—ì„œëŠ” OCR í…ìŠ¤íŠ¸ê°€ ì¶”ì¶œë˜ì§€ ì•ŠìŒ
                        st.warning("OCR ì¶”ì¶œ ì‹¤íŒ¨")
                    else:
                        st.info("OCR ë¯¸ì ìš©")

                    # ì‹¤ì œ ì‹¬ë³¼ ì´ë¯¸ì§€
                    # ê²€ì¶œëœ í´ë˜ìŠ¤ì˜ ì‹¤ì œ ì‹¬ë³¼ ì´ë¯¸ì§€ í‘œì‹œ
                    st.caption("ğŸ“š ì‹¤ì œ ì‹¬ë³¼", help="í•´ë‹¹ í´ë˜ìŠ¤ì˜ í‘œì¤€ ì‹¬ë³¼ ì´ë¯¸ì§€ì…ë‹ˆë‹¤. class_examples í´ë”ì˜ ì°¸ì¡° ì´ë¯¸ì§€ë¡œ ì˜¬ë°”ë¥¸ ì‹¬ë³¼ì¸ì§€ ì‹œê°ì ìœ¼ë¡œ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    example_path = self.get_class_example_image(detection['class_name'])
                    if example_path and os.path.exists(example_path):
                        st.image(example_path, caption=detection['class_name'])
                    else:
                        st.info("ì‹¬ë³¼ ì´ë¯¸ì§€ ì—†ìŒ")

                with col2:
                    st.write(f"**{detection['class_name']}**")
                    st.write(f"ğŸ¯ ì‹ ë¢°ë„: {detection['confidence']:.3f}")
                    st.write(f"ğŸ“¦ ìœ„ì¹˜: ({x1}, {y1}) - ({x2}, {y2})")

                    # Voting ì •ë³´ í‘œì‹œ
                    if 'voting_info' in detection:
                        voting_info = detection['voting_info']
                        st.write(f"ğŸ—³ï¸ **Voting ì •ë³´:**")
                        st.write(f"  - íˆ¬í‘œ ìˆ˜: {voting_info['total_votes']}ê°œ ëª¨ë¸")
                        st.write(f"  - í´ë˜ìŠ¤ë³„ íˆ¬í‘œ: {voting_info['class_votes']}")
                        st.write(f"  - ê°€ì¤‘ ì ìˆ˜: {max(voting_info['weighted_scores'].values()):.3f}")
                        st.write(f"  - ì°¸ì—¬ ëª¨ë¸: {', '.join(voting_info['models_agreed'])}")

                    # í´ë˜ìŠ¤ëª… í‘œì‹œ
                    st.write(f"**í´ë˜ìŠ¤**: {detection['class_name']}")

                with col3:
                    # í˜„ì¬ ìƒíƒœ í‘œì‹œ
                    if current_status == "approved":
                        st.success("âœ… ìŠ¹ì¸ë¨")
                    elif current_status == "rejected":
                        st.error("âŒ ê±°ë¶€ë¨")
                    else:
                        st.info("ğŸ•°ï¸ ëŒ€ê¸° ì¤‘")

                with col4:
                    # ê°œë³„ ìƒíƒœ ë³€ê²½ ë²„íŠ¼
                    if current_status != "approved":
                        if st.button("âœ… ìŠ¹ì¸", key=f"approve_{prefix}_{i}"):
                            st.session_state.verification_status[status_key] = "approved"
                            st.rerun()
                    if current_status != "rejected":
                        if st.button("âŒ ê±°ë¶€", key=f"reject_{prefix}_{i}"):
                            st.session_state.verification_status[status_key] = "rejected"
                            st.rerun()
                    if current_status != "pending":
                        if st.button("ğŸ”„ ì´ˆê¸°í™”", key=f"reset_{prefix}_{i}"):
                            del st.session_state.verification_status[status_key]
                            st.rerun()

    def render_bom_generation(self):
        """BOM ìƒì„± ë° ë‚´ë³´ë‚´ê¸°"""
        st.header("ğŸ“Š BOM ìƒì„± ë° ë‚´ë³´ë‚´ê¸°")

        # ìŠ¹ì¸ëœ ê²€ì¶œ ê²°ê³¼ë§Œ í•„í„°ë§
        approved_detections = []

        # ê²€ì¦ ìƒíƒœ í™•ì¸í•˜ì—¬ ìŠ¹ì¸ëœ ê²€ì¶œë§Œ ìˆ˜ì§‘
        if 'verification_status' in st.session_state:
            # í†µí•© ê²°ê³¼ì—ì„œ ìŠ¹ì¸ëœ ê²ƒë“¤
            for key, status in st.session_state.verification_status.items():
                if status == "approved":
                    # key í˜•ì‹: "unified_0", "voting_1", "model_id_2" ë“±
                    parts = key.split('_')
                    if len(parts) >= 2:
                        prefix = parts[0]
                        index = int(parts[-1])

                        # í•´ë‹¹í•˜ëŠ” ê²€ì¶œ ì°¾ê¸°
                        if prefix == "unified":
                            # í†µí•© ê²°ê³¼ì—ì„œ ì°¾ê¸°
                            all_dets = []
                            for model_id, dets in st.session_state.detection_results.items():
                                for det in dets:
                                    det_copy = det.copy()
                                    det_copy['model_id'] = model_id
                                    all_dets.append(det_copy)
                            unique_dets = self.remove_duplicate_detections(all_dets)
                            if index < len(unique_dets):
                                detection = unique_dets[index].copy()
                                # ìˆ˜ì •ëœ í´ë˜ìŠ¤ ì´ë¦„ì´ ìˆìœ¼ë©´ ì ìš©
                                if key in st.session_state.modified_classes:
                                    detection['class_name'] = st.session_state.modified_classes[key]
                                approved_detections.append(detection)
                        elif prefix == "voting":
                            # Voting ê²°ê³¼ì—ì„œ ì°¾ê¸°
                            all_dets = []
                            for model_id, dets in st.session_state.detection_results.items():
                                for det in dets:
                                    det_copy = det.copy()
                                    det_copy['model_id'] = model_id
                                    all_dets.append(det_copy)
                            voting_dets, _ = self.remove_duplicate_detections_with_voting(all_dets)
                            if index < len(voting_dets):
                                detection = voting_dets[index].copy()
                                # ìˆ˜ì •ëœ í´ë˜ìŠ¤ ì´ë¦„ì´ ìˆìœ¼ë©´ ì ìš©
                                if key in st.session_state.modified_classes:
                                    detection['class_name'] = st.session_state.modified_classes[key]
                                approved_detections.append(detection)
                        elif prefix in st.session_state.detection_results:
                            # ê°œë³„ ëª¨ë¸ ê²°ê³¼ì—ì„œ ì°¾ê¸°
                            model_dets = st.session_state.detection_results[prefix]
                            if index < len(model_dets):
                                detection = model_dets[index].copy()
                                # ìˆ˜ì •ëœ í´ë˜ìŠ¤ ì´ë¦„ì´ ìˆìœ¼ë©´ ì ìš©
                                if key in st.session_state.modified_classes:
                                    detection['class_name'] = st.session_state.modified_classes[key]
                                approved_detections.append(detection)

        # ìŠ¹ì¸ëœ ê²€ì¶œì´ ì—†ìœ¼ë©´ ì „ì²´ ê²€ì¶œ ì‚¬ìš© (ê¸°ë³¸ê°’)
        if not approved_detections:
            st.info("ìŠ¹ì¸ëœ ê²€ì¶œì´ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ ê²€ì¶œ ê²°ê³¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            all_detections = []
            for model_id, detections in st.session_state.detection_results.items():
                all_detections.extend(detections)
            approved_detections = all_detections

        if not approved_detections:
            st.info("BOM ìƒì„±ì„ ìœ„í•œ ê²€ì¶œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # BOM í…Œì´ë¸” ìƒì„±
        bom_data = self.create_bom_table(approved_detections)

        st.subheader("ğŸ“‹ ìƒì„±ëœ BOM")

        # ìŠ¹ì¸ëœ ê²€ì¶œ ìˆ˜ í‘œì‹œ
        st.success(f"âœ… ìŠ¹ì¸ëœ ê²€ì¶œ {len(approved_detections)}ê°œë¡œ BOM ìƒì„±")

        st.dataframe(bom_data)

        # í†µê³„ ì •ë³´
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ì´ ë¶€í’ˆ ìˆ˜", len(bom_data))
        with col2:
            total_cost = bom_data['ì´ ê°€ê²©'].sum()
            st.metric("ì´ ì˜ˆìƒ ë¹„ìš©", f"{total_cost:,}ì›")
        with col3:
            unique_types = len(bom_data['ë¶€í’ˆëª…'].unique())
            st.metric("ë¶€í’ˆ ì¢…ë¥˜", unique_types)
        with col4:
            avg_confidence = safe_mean([d['confidence'] for d in approved_detections])
            st.metric("í‰ê·  ì‹ ë¢°ë„", f"{avg_confidence:.3f}")
        
        # ë‚´ë³´ë‚´ê¸° ì˜µì…˜
        st.subheader("ğŸ“¤ ë‚´ë³´ë‚´ê¸°")
        
        col1, col2 = st.columns(2)
        with col1:
            # Excel ë‚´ë³´ë‚´ê¸°
            excel_data = self.create_excel_export(bom_data)
            st.download_button(
                label="ğŸ“Š Excelë¡œ ë‚´ë³´ë‚´ê¸°",
                data=excel_data,
                file_name=f"BOM_{st.session_state.current_image['filename'].split('.')[0]}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        
        with col2:
            # PDF ë‚´ë³´ë‚´ê¸°
            if st.button("ğŸ“„ PDF ë³´ê³ ì„œ ìƒì„±"):
                pdf_data = self.create_pdf_report(bom_data, all_detections)
                st.download_button(
                    label="ğŸ“„ PDF ë‹¤ìš´ë¡œë“œ",
                    data=pdf_data,
                    file_name=f"BOM_Report_{st.session_state.current_image['filename'].split('.')[0]}.pdf",
                    mime="application/pdf"
                )

    def create_bom_table(self, detections):
        """ê²€ì¶œ ê²°ê³¼ë¡œë¶€í„° BOM í…Œì´ë¸” ìƒì„±"""
        # ë™ì¼ ë¶€í’ˆë³„ë¡œ ì§‘ê³„
        component_counts = {}
        for detection in detections:
            class_name = detection['class_name']
            if class_name in component_counts:
                component_counts[class_name]['ìˆ˜ëŸ‰'] += 1
                component_counts[class_name]['ì‹ ë¢°ë„ë“¤'].append(detection['confidence'])
            else:
                component_counts[class_name] = {
                    'ìˆ˜ëŸ‰': 1,
                    'ì‹ ë¢°ë„ë“¤': [detection['confidence']],
                    'ëª¨ë¸': detection['model']
                }
        
        # BOM í…Œì´ë¸” ìƒì„±
        bom_rows = []
        for i, (class_name, info) in enumerate(component_counts.items(), 1):
            # ê°€ê²© ì •ë³´ ì¡°íšŒ
            price_info = self.pricing_data.get(class_name, {})
            unit_price = price_info.get('unit_price', 10000)  # ê¸°ë³¸ê°’
            
            avg_confidence = safe_mean(info['ì‹ ë¢°ë„ë“¤'])
            total_price = unit_price * info['ìˆ˜ëŸ‰']
            
            bom_rows.append({
                'ë²ˆí˜¸': i,
                'ë¶€í’ˆëª…': class_name,
                'ìˆ˜ëŸ‰': info['ìˆ˜ëŸ‰'],
                'ë‹¨ê°€': unit_price,
                'ì´ ê°€ê²©': total_price,
                'í‰ê·  ì‹ ë¢°ë„': round(avg_confidence, 3),
                'ê²€ì¶œ ëª¨ë¸': info['ëª¨ë¸'],
                'ë¹„ê³ ': price_info.get('description', '')
            })
        
        return pd.DataFrame(bom_rows)

    def create_excel_export(self, bom_data):
        """Excel íŒŒì¼ ìƒì„±"""
        import io
        output = io.BytesIO()
        
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            bom_data.to_excel(writer, sheet_name='BOM', index=False)
            
            # ì¶”ê°€ ì •ë³´ ì‹œíŠ¸
            info_data = pd.DataFrame([
                ['ë„ë©´ íŒŒì¼', st.session_state.current_image['filename']],
                ['ìƒì„± ì¼ì‹œ', pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')],
                ['ì‚¬ìš© ëª¨ë¸', ', '.join(st.session_state.selected_models)],
                ['ì´ ë¶€í’ˆ ìˆ˜', len(bom_data)],
                ['ì´ ì˜ˆìƒ ë¹„ìš©', f"{bom_data['ì´ ê°€ê²©'].sum():,}ì›"]
            ], columns=['í•­ëª©', 'ê°’'])
            
            info_data.to_excel(writer, sheet_name='ì •ë³´', index=False)
        
        return output.getvalue()

    def create_pdf_report(self, bom_data, detections):
        """PDF ë³´ê³ ì„œ ìƒì„±"""
        from io import BytesIO
        
        buffer = BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4)
        styles = getSampleStyleSheet()
        story = []
        
        # ì œëª©
        title = Paragraph("AI ê¸°ë°˜ BOM ë¶„ì„ ë³´ê³ ì„œ", styles['Title'])
        story.append(title)
        story.append(Spacer(1, 12))
        
        # ê¸°ë³¸ ì •ë³´
        info_data = [
            ['ë„ë©´ íŒŒì¼', st.session_state.current_image['filename']],
            ['ë¶„ì„ ì¼ì‹œ', pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')],
            ['ì‚¬ìš© ëª¨ë¸', ', '.join(st.session_state.selected_models)],
            ['ì´ ê²€ì¶œ ìˆ˜', str(len(detections))],
            ['ë¶€í’ˆ ì¢…ë¥˜', str(len(bom_data))],
            ['ì´ ì˜ˆìƒ ë¹„ìš©', f"{bom_data['ì´ ê°€ê²©'].sum():,}ì›"]
        ]
        
        info_table = Table(info_data)
        info_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 14),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        
        story.append(info_table)
        story.append(Spacer(1, 12))
        
        # BOM í…Œì´ë¸”
        bom_title = Paragraph("ë¶€í’ˆ ëª©ë¡ (BOM)", styles['Heading2'])
        story.append(bom_title)
        story.append(Spacer(1, 12))
        
        # BOM ë°ì´í„°ë¥¼ í…Œì´ë¸”ë¡œ ë³€í™˜
        bom_table_data = [bom_data.columns.tolist()]
        for _, row in bom_data.iterrows():
            bom_table_data.append(row.tolist())
        
        bom_table = Table(bom_table_data)
        bom_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 10),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        
        story.append(bom_table)
        
        doc.build(story)
        buffer.seek(0)
        return buffer.getvalue()

    def draw_ground_truth_only(self, image, ground_truth):
        """Ground Truthë§Œ í‘œì‹œ (ì´ˆë¡ìƒ‰, ë‘êº¼ìš´ ì„ )"""
        h, w = image.shape[:2]

        for gt in ground_truth:
            # YOLO ì •ê·œí™” ì¢Œí‘œë¥¼ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
            x_center = gt['x_center'] * w
            y_center = gt['y_center'] * h
            width = gt['width'] * w
            height = gt['height'] * h

            x1 = int(x_center - width/2)
            y1 = int(y_center - height/2)
            x2 = int(x_center + width/2)
            y2 = int(y_center + height/2)

            # ì´ˆë¡ìƒ‰ ë‘êº¼ìš´ ë°”ìš´ë”© ë°•ìŠ¤
            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 4)  # ë‘ê»˜ 4

            # í´ë˜ìŠ¤ ID í‘œì‹œ
            label = f"GT_{gt['class_id']}"
            cv2.putText(image, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

        return image

    def draw_detections_only(self, image, detections):
        """ê²€ì¶œ ê²°ê³¼ë§Œ í‘œì‹œ (ë¹¨ê°„ìƒ‰, ë‘êº¼ìš´ ì„ )"""
        for detection in detections:
            x1, y1, x2, y2 = detection['bbox']

            # ë¹¨ê°„ìƒ‰ ë‘êº¼ìš´ ë°”ìš´ë”© ë°•ìŠ¤
            cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 4)  # ë‘ê»˜ 4

            # í´ë˜ìŠ¤ ì´ë¦„ê³¼ ì‹ ë¢°ë„ í‘œì‹œ
            label = f"{detection['class_name']}: {detection['confidence']:.2f}"
            cv2.putText(image, label, (int(x1), int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)

        return image

    def enhance_detection_with_ocr(self, image, detection):
        """OCRì„ í™œìš©í•œ ê²€ì¶œ ê²°ê³¼ í–¥ìƒ (PaddleOCR ì‚¬ìš©)"""
        if not OCR_AVAILABLE:
            return detection

        try:
            # OCR ì´ˆê¸°í™” (ìºì‹œëœ reader ì‚¬ìš©)
            if not hasattr(self, 'ocr_reader'):
                if OCR_TYPE == "PaddleOCR":
                    # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
                    import torch
                    use_gpu = torch.cuda.is_available()
                    self.ocr_reader = PaddleOCR(use_angle_cls=True, lang='en', show_log=False, use_gpu=use_gpu)
                    if use_gpu:
                        print(f"âœ… PaddleOCR GPU ëª¨ë“œ í™œì„±í™”")
                    else:
                        print(f"âš ï¸ PaddleOCR CPU ëª¨ë“œ ì‚¬ìš© (GPU ë¶ˆê°€)")
                else:  # EasyOCR ë°±ì—…
                    import easyocr
                    import torch
                    use_gpu = torch.cuda.is_available()
                    self.ocr_reader = easyocr.Reader(['en'], gpu=use_gpu)

            # ë°”ìš´ë”© ë°•ìŠ¤ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            x1, y1, x2, y2 = [int(coord) for coord in detection['bbox']]

            # íŒ¨ë”© ì¶”ê°€
            padding = 5
            x1 = max(0, x1 - padding)
            y1 = max(0, y1 - padding)
            x2 = min(image.shape[1], x2 + padding)
            y2 = min(image.shape[0], y2 + padding)

            # ì˜ì—­ í¬ë¡­
            cropped = image[y1:y2, x1:x2]
            if cropped.size == 0:
                return detection

            # OCR ìˆ˜í–‰ (PaddleOCR vs EasyOCR)
            if OCR_TYPE == "PaddleOCR":
                results = self.ocr_reader.ocr(cropped, cls=True)
                # PaddleOCR ê²°ê³¼ í˜•ì‹ ë³€í™˜
                ocr_results = []
                if results and results[0]:
                    for line in results[0]:
                        bbox_coords, (text, confidence) = line
                        ocr_results.append((bbox_coords, text, confidence))
                results = ocr_results
            else:  # EasyOCR
                results = self.ocr_reader.readtext(cropped)

            # í‚¤ì›Œë“œ ë§¤í•‘
            class_keywords = {
                'CPU': ['CPU', '1513', '1214', '1215', '6ES7', 'PLC'],
                'RS485': ['RS485', 'RS422', '485', '422', 'CM', '1241'],
                'GRAPHIC': ['GP', 'PANEL', 'HMI', '6AV', 'TOUCH', 'MAIN', 'CONTROL'],
                'TERMINAL': ['ST', 'TERMINAL', 'WAGO', '2.5', '4.0'],
                'AI': ['AI', 'ANALOG', 'INPUT', '1231', '8x13'],
                'AO': ['AO', 'ANALOG', 'OUTPUT', '1232', '4x14'],
                'DI': ['DI', 'DIGITAL', 'INPUT', '1221', '16x24'],
                'DO': ['DO', 'DIGITAL', 'OUTPUT', '1222', '16x'],
                'VALVE': ['VALVE', 'EHS', 'CM3', 'CONTROL'],
                'BREAKER': ['MCB', 'BREAKER', '2P', '3P', '4P', 'BK'],
                'TRANSFORMER': ['TRANSFORMER', 'VA', '600VA', 'MST'],
                'SMPS': ['SMPS', 'PS', '24DC', 'POWER', 'SUPPLY'],
                'SWITCH': ['SWITCH', 'SW', 'SELECT', 'MRS'],
                'RELAY': ['RELAY', 'RLY', 'PLC-RSC', 'UC'],
                'FILTER': ['FILTER', 'NF', 'NOISE', 'WYFS'],
                'EMERGENCY': ['EMERGENCY', 'STOP', 'E-STOP', 'MRE']
            }

            # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì •ì œ
            all_text = ""
            extracted_texts = []
            for (bbox_ocr, text, confidence) in results:
                if confidence > 0.5:
                    clean_text = re.sub(r'[^\w\-]', '', text.upper())
                    all_text += clean_text + " "
                    extracted_texts.append({"text": text, "confidence": confidence, "clean_text": clean_text})

            # í‚¤ì›Œë“œ ë§¤ì¹­
            enhanced_detection = detection.copy()
            boost_applied = False
            matched_keywords = []

            current_class = detection['class_name'].upper()
            for class_type, keywords in class_keywords.items():
                if class_type in current_class:
                    for keyword in keywords:
                        if keyword.upper() in all_text:
                            matched_keywords.append(keyword)
                            # ì‹ ë¢°ë„ ë¶€ìŠ¤íŠ¸ ì ìš©
                            original_conf = detection['confidence']
                            boost_factor = 1.15  # 15% ë¶€ìŠ¤íŠ¸
                            enhanced_detection['confidence'] = min(0.99, original_conf * boost_factor)
                            enhanced_detection['ocr_boost'] = True
                            enhanced_detection['matched_keyword'] = keyword
                            boost_applied = True
                            break
                if boost_applied:
                    break

            # OCR ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            ocr_result = {
                'detection_id': f"{detection['class_name']}_{detection['bbox'][0]}_{detection['bbox'][1]}",
                'extracted_texts': extracted_texts,
                'matched_keywords': matched_keywords,
                'all_text': all_text.strip(),
                'boost_applied': boost_applied,
                'original_confidence': detection['confidence'],
                'enhanced_confidence': enhanced_detection['confidence'] if boost_applied else detection['confidence'],
                'class_name': detection['class_name']
            }

            # ì„¸ì…˜ ìƒíƒœì— OCR ê²°ê³¼ ì €ì¥
            if 'ocr_analysis_results' not in st.session_state:
                st.session_state.ocr_analysis_results = []
            st.session_state.ocr_analysis_results.append(ocr_result)

            if boost_applied and 'ocr_boost' in enhanced_detection:
                # UIì— OCR ì •ë³´ í‘œì‹œ
                st.success(f"ğŸ” OCR í–¥ìƒ: {detection['class_name']} "
                          f"{detection['confidence']:.3f} â†’ {enhanced_detection['confidence']:.3f} "
                          f"(í‚¤ì›Œë“œ: {enhanced_detection['matched_keyword']})")

            return enhanced_detection

        except Exception as e:
            # OCR ì˜¤ë¥˜ ì‹œ ì›ë³¸ ë°˜í™˜
            return detection

    def apply_enhanced_ocr(self, detections):
        """Enhanced OCR v4.0 Rotation ì ìš© (ì§„í–‰ë¥  í‘œì‹œ í¬í•¨)"""
        # ìºì‹œëœ Enhanced OCR Detector ì‚¬ìš©
        enhanced_ocr_detector = get_enhanced_ocr_detector()
        if not enhanced_ocr_detector or not st.session_state.current_image:
            return detections

        try:
            # í˜„ì¬ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
            if isinstance(st.session_state.current_image, dict):
                image = st.session_state.current_image.get('image')
            else:
                image = st.session_state.current_image

            if image is None:
                st.warning(f"âš ï¸ Enhanced OCR {OCR_VERSION}: ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return detections

            # ì›ë³¸ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸° (ìˆëŠ” ê²½ìš°)
            original_image = None
            if hasattr(st.session_state, 'original_image'):
                original_image = st.session_state.original_image
            elif hasattr(st.session_state, 'uploaded_image'):
                original_image = st.session_state.uploaded_image

            # ì§„í–‰ë¥  í‘œì‹œ UI êµ¬ì„±
            total_objects = len(detections)
            st.info(f"ğŸ”„ Enhanced OCR {OCR_VERSION} (PaddleOCR API) ì²˜ë¦¬ ì¤‘... (ì´ {total_objects}ê°œ ê°ì²´)")

            # ì§„í–‰ë¥  ë°”ì™€ ìƒíƒœ í…ìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ
            progress_bar = st.progress(0)
            status_container = st.empty()

            # ì§„í–‰ë¥  ì½œë°± í•¨ìˆ˜ ì •ì˜
            def progress_callback(current, total, current_obj_name=""):
                progress = current / total if total > 0 else 0
                progress_bar.progress(progress)
                status_container.text(f"ì§„í–‰: {current}/{total} ({progress*100:.1f}%) - {current_obj_name}")

            # Enhanced OCR ì ìš© (v4.0 Rotation ìš°ì„ , í´ë°± ì§€ì›)
            if OCR_VERSION == "v4.0 Rotation" and hasattr(enhanced_ocr_detector, 'apply_enhanced_ocr_v4'):
                enhanced_detections = enhanced_ocr_detector.apply_enhanced_ocr_v4(
                    detections, image, original_image, progress_callback=progress_callback
                )
            elif OCR_VERSION == "v3.0 Ultimate" and hasattr(enhanced_ocr_detector, 'apply_enhanced_ocr_v3'):
                enhanced_detections = enhanced_ocr_detector.apply_enhanced_ocr_v3(
                    detections, image, original_image, progress_callback=progress_callback
                )
            else:
                # v2.0 fallback
                enhanced_detections = enhanced_ocr_detector.apply_enhanced_ocr_v2(detections, image)

            # ì™„ë£Œ ìƒíƒœ í‘œì‹œ
            progress_bar.progress(1.0)
            status_container.success(f"âœ… Enhanced OCR ì²˜ë¦¬ ì™„ë£Œ! ({total_objects}ê°œ ê°ì²´)")

            # í†µê³„ ì •ë³´ ì €ì¥ (ê¸°ì¡´ ì„¸ì…˜ ìƒíƒœì™€ í˜¸í™˜)
            ocr_extracted_count = len([d for d in enhanced_detections if d.get('ocr_text')])
            ocr_verified_count = len([d for d in enhanced_detections if d.get('matched_truth')])

            st.session_state.enhanced_ocr_results = {
                'total_detections': len(enhanced_detections),
                'ocr_extracted': ocr_extracted_count,
                'ocr_verified': ocr_verified_count,
                'success_rate': (ocr_verified_count / len(enhanced_detections) * 100) if enhanced_detections else 0
            }

            return enhanced_detections

        except Exception as e:
            st.error(f"âŒ Enhanced OCR {OCR_VERSION} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return detections

    def _calculate_iou_enhanced(self, box1, box2):
        """Enhanced OCRìš© IoU ê³„ì‚°"""
        x1_min, y1_min, x1_max, y1_max = box1
        x2_min, y2_min, x2_max, y2_max = box2

        # êµì§‘í•© ì˜ì—­
        inter_xmin = max(x1_min, x2_min)
        inter_ymin = max(y1_min, y2_min)
        inter_xmax = min(x1_max, x2_max)
        inter_ymax = min(y1_max, y2_max)

        if inter_xmax < inter_xmin or inter_ymax < inter_ymin:
            return 0.0

        inter_area = (inter_xmax - inter_xmin) * (inter_ymax - inter_ymin)

        # í•©ì§‘í•© ì˜ì—­
        box1_area = (x1_max - x1_min) * (y1_max - y1_min)
        box2_area = (x2_max - x2_min) * (y2_max - y2_min)
        union_area = box1_area + box2_area - inter_area

        return inter_area / union_area if union_area > 0 else 0.0

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    system = SmartBOMSystemV2()
    
    # ì‚¬ì´ë“œë°” ë Œë”ë§
    system.render_sidebar()
    
    # ë©”ì¸ ì›Œí¬í”Œë¡œìš° ë Œë”ë§
    system.render_main_workflow()
    
    # í‘¸í„°
    st.markdown("---")
    st.markdown("**AI ì‹¬ë³¼ ì¸ì‹ ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ BOM ë¶„ì„ ë° ê²¬ì  ìë™í™” ì†”ë£¨ì…˜ v2.0** | Powered by YOLOv11 & Detectron2")

if __name__ == "__main__":
    main()