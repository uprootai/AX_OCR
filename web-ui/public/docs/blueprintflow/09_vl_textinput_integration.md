# VL API + TextInput í†µí•© ê°€ì´ë“œ

## ğŸ¯ ëª©í‘œ

VL (Vision-Language) APIì— **ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸**ë¥¼ í•¨ê»˜ ì „ë‹¬í•˜ì—¬ ë” ì •í™•í•œ ë¶„ì„ ê²°ê³¼ë¥¼ ì–»ìŠµë‹ˆë‹¤.

---

## ğŸ“‹ í˜„ì¬ ìƒíƒœ

### VL API í˜„ì¬ êµ¬í˜„

**íŒŒì¼**: `models/vl-api/api_server.py`

**í˜„ì¬ ì…ë ¥**:
- âœ… `image` (íŒŒì¼ ì—…ë¡œë“œ)
- âŒ `prompt` (í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸) - **ë¯¸êµ¬í˜„**

**ë¬¸ì œ**:
- VL ëª¨ë¸ì— "ë¬´ì—‡ì„ ë¶„ì„í• ì§€" ì§€ì‹œ ë¶ˆê°€
- ì¼ë°˜ì ì¸ ë¶„ì„ë§Œ ìˆ˜í–‰
- ì‚¬ìš©ì ë§ì¶¤ ì§ˆë¬¸ ë¶ˆê°€

---

## ğŸš€ êµ¬í˜„ ë°©ì•ˆ

### Phase 1: VL APIì— prompt íŒŒë¼ë¯¸í„° ì¶”ê°€

#### 1-1. API ì„œë²„ ì½”ë“œ ìˆ˜ì •

**íŒŒì¼**: `models/vl-api/api_server.py`

```python
# âœ… ê¸°ì¡´ ì½”ë“œ (ì´ë¯¸ì§€ë§Œ)
@app.post("/api/v1/analyze")
async def analyze_image(
    file: UploadFile = File(...),
    model: str = Form("blip2"),
):
    # ì´ë¯¸ì§€ ë¶„ì„...
    return {"caption": "...", "objects": [...]}
```

```python
# âœ… ê°œì„  ì½”ë“œ (ì´ë¯¸ì§€ + í”„ë¡¬í”„íŠ¸)
@app.post("/api/v1/analyze")
async def analyze_image(
    file: UploadFile = File(...),
    model: str = Form("blip2"),
    prompt: Optional[str] = Form(None),  # âœ… ì¶”ê°€
):
    """
    VL ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ë¶„ì„

    Args:
        file: ì…ë ¥ ì´ë¯¸ì§€
        model: ì‚¬ìš©í•  VL ëª¨ë¸ (blip2, llava, etc.)
        prompt: ë¶„ì„ ì§ˆë¬¸/í”„ë¡¬í”„íŠ¸ (ì„ íƒì‚¬í•­)
            ì˜ˆ: "ì´ ì´ë¯¸ì§€ì—ì„œ ìš©ì ‘ ê¸°í˜¸ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”"
    """

    # ì´ë¯¸ì§€ ë¡œë“œ
    image = load_image(file)

    # í”„ë¡¬í”„íŠ¸ê°€ ìˆìœ¼ë©´ ì§ˆë¬¸-ë‹µë³€ ëª¨ë“œ, ì—†ìœ¼ë©´ ì¼ë°˜ ìº¡ì…”ë‹
    if prompt:
        # VQA (Visual Question Answering) ëª¨ë“œ
        result = vl_model.answer_question(image, prompt)
        return {
            "mode": "vqa",
            "question": prompt,
            "answer": result["answer"],
            "confidence": result.get("confidence", 1.0)
        }
    else:
        # ì¼ë°˜ ì´ë¯¸ì§€ ìº¡ì…”ë‹ ëª¨ë“œ
        caption = vl_model.generate_caption(image)
        objects = vl_model.detect_objects(image)
        return {
            "mode": "captioning",
            "caption": caption,
            "objects": objects
        }
```

#### 1-2. /api/v1/info ì—…ë°ì´íŠ¸

```python
@app.get("/api/v1/info")
async def get_api_info():
    return {
        "id": "vl",
        "name": "VL",
        "display_name": "Vision-Language Model",
        "description": "ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ì´í•´í•˜ëŠ” ë©€í‹°ëª¨ë‹¬ AI",
        "endpoint": "/api/v1/analyze",
        "method": "POST",
        "requires_image": True,

        # âœ… inputs ì •ì˜
        "inputs": [
            {
                "name": "image",
                "type": "file",
                "description": "ë¶„ì„í•  ì´ë¯¸ì§€",
                "required": True
            },
            {
                "name": "prompt",  # âœ… ì¶”ê°€!
                "type": "string",
                "description": "ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸ ë˜ëŠ” ë¶„ì„ ìš”ì²­",
                "required": False
            }
        ],

        # âœ… ì¶œë ¥ ì •ì˜
        "outputs": [
            {
                "name": "mode",
                "type": "string",
                "description": "ë¶„ì„ ëª¨ë“œ (vqa ë˜ëŠ” captioning)"
            },
            {
                "name": "answer",
                "type": "string",
                "description": "ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ (VQA ëª¨ë“œ)"
            },
            {
                "name": "caption",
                "type": "string",
                "description": "ì´ë¯¸ì§€ ì„¤ëª… (ìº¡ì…”ë‹ ëª¨ë“œ)"
            }
        ],

        # âœ… inputMappings ì¶”ê°€ (GenericAPIExecutorìš©)
        "input_mappings": {
            "prompt": "inputs.text"  # TextInputì˜ text â†’ APIì˜ prompt
        },

        "parameters": [
            {
                "name": "model",
                "type": "select",
                "options": ["blip2", "llava", "instructblip"],
                "default": "blip2",
                "description": "ì‚¬ìš©í•  VL ëª¨ë¸"
            }
        ],

        "blueprintflow": {
            "icon": "ğŸ‘ï¸",
            "color": "#ec4899",
            "category": "api"
        }
    }
```

---

### Phase 2: BlueprintFlow ë…¸ë“œ ì •ì˜ ì—…ë°ì´íŠ¸

**íŒŒì¼**: `web-ui/src/config/nodeDefinitions.ts`

```typescript
vl: {
  type: 'vl',
  label: 'VL Model',
  category: 'api',
  color: '#ec4899',
  icon: 'Eye',
  description: 'ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ì´í•´í•˜ëŠ” Vision-Language ëª¨ë¸',

  inputs: [
    {
      name: 'image',
      type: 'Image',
      description: 'ğŸ“„ ë¶„ì„í•  ì´ë¯¸ì§€',
    },
    {
      name: 'text',  // âœ… ì¶”ê°€!
      type: 'string',
      description: 'â“ ì§ˆë¬¸ ë˜ëŠ” ë¶„ì„ ìš”ì²­ (ì„ íƒì‚¬í•­)',
    },
  ],

  outputs: [
    {
      name: 'mode',
      type: 'string',
      description: 'ë¶„ì„ ëª¨ë“œ',
    },
    {
      name: 'answer',
      type: 'string',
      description: 'ğŸ’¬ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ (VQA ëª¨ë“œ)',
    },
    {
      name: 'caption',
      type: 'string',
      description: 'ğŸ“ ì´ë¯¸ì§€ ì„¤ëª… (ìº¡ì…”ë‹ ëª¨ë“œ)',
    },
  ],

  parameters: [
    {
      name: 'model',
      type: 'select',
      default: 'blip2',
      options: ['blip2', 'llava', 'instructblip'],
      description: 'ì‚¬ìš©í•  VL ëª¨ë¸',
    },
  ],

  examples: [
    'ì´ë¯¸ì§€ + ì§ˆë¬¸ìœ¼ë¡œ ì •í™•í•œ ì •ë³´ ì¶”ì¶œ',
    '"ì´ ë„ë©´ì˜ ì¹˜ìˆ˜ë¥¼ ì•Œë ¤ì¤˜" ê°™ì€ ìì—°ì–´ ì§ˆë¬¸',
    'ìš©ì ‘ ê¸°í˜¸, ê³µì°¨ ì •ë³´ ë“± íŠ¹ì • ìš”ì†Œ ì°¾ê¸°',
  ],

  usageTips: [
    'ğŸ’¡ í”„ë¡¬í”„íŠ¸ ì—†ì´ ì‚¬ìš© ì‹œ: ì¼ë°˜ ì´ë¯¸ì§€ ìº¡ì…”ë‹',
    'ğŸ’¡ í”„ë¡¬í”„íŠ¸ì™€ í•¨ê»˜ ì‚¬ìš© ì‹œ: ì§ˆë¬¸-ë‹µë³€ ëª¨ë“œ (ë” ì •í™•)',
    'ğŸ’¡ TextInputê³¼ ì—°ê²°í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ ì „ë‹¬',
  ],

  recommendedInputs: [
    {
      from: 'imageinput',
      field: 'image',
      reason: 'ë¶„ì„í•  ë„ë©´ ì´ë¯¸ì§€',
    },
    {
      from: 'textinput',  // âœ… ì¶”ê°€!
      field: 'text',
      reason: 'íŠ¹ì • ì§ˆë¬¸ì´ë‚˜ ë¶„ì„ ìš”ì²­',
    },
  ],
}
```

---

### Phase 3: VL Executor ì—…ë°ì´íŠ¸

**íŒŒì¼**: `gateway-api/blueprintflow/executors/vl_executor.py`

```python
class VLExecutor(BaseNodeExecutor):
    """Vision-Language ëª¨ë¸ ì‹¤í–‰ê¸°"""

    async def execute(self, inputs: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        # ì´ë¯¸ì§€ ì¤€ë¹„
        file_bytes = prepare_image_for_api(inputs, context)

        # íŒŒë¼ë¯¸í„°
        model = self.parameters.get("model", "blip2")

        # âœ… í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸° (ìˆìœ¼ë©´)
        prompt = inputs.get("text")  # TextInputì—ì„œ ì „ë‹¬ë°›ì€ í…ìŠ¤íŠ¸

        # VL API í˜¸ì¶œ
        async with httpx.AsyncClient(timeout=60.0) as client:
            files = {"file": ("image.jpg", file_bytes, "image/jpeg")}
            data = {
                "model": model,
            }

            # âœ… í”„ë¡¬í”„íŠ¸ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            if prompt:
                data["prompt"] = prompt

            response = await client.post(
                "http://vl-api:5004/api/v1/analyze",
                files=files,
                data=data
            )

        if response.status_code == 200:
            result = response.json()

            # ì¶œë ¥ êµ¬ì¡°í™”
            output = {
                "mode": result.get("mode", "captioning"),
                "model_used": model,
            }

            # VQA ëª¨ë“œ
            if result.get("mode") == "vqa":
                output["answer"] = result.get("answer", "")
                output["question"] = prompt
                output["confidence"] = result.get("confidence", 1.0)
            # ìº¡ì…”ë‹ ëª¨ë“œ
            else:
                output["caption"] = result.get("caption", "")
                output["objects"] = result.get("objects", [])

            return output
        else:
            raise Exception(f"VL API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}")
```

---

## ğŸ¨ ì‚¬ìš© ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ë„ë©´ ì¹˜ìˆ˜ ì¶”ì¶œ

**ì›Œí¬í”Œë¡œìš°**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ImageInput  â”‚ (ê¸°ê³„ ë„ë©´ ì—…ë¡œë“œ)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ image
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TextInput   â”‚ text: "ì´ ë„ë©´ì˜ ëª¨ë“  ì¹˜ìˆ˜ ê°’ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”"
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ text
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VL Model    â”‚
â”‚             â”‚
â”‚ image â†â”€â”€â”€â”€â”€â”¼â”€ ImageInput.image
â”‚ text â†â”€â”€â”€â”€â”€â”€â”¼â”€ TextInput.text
â”‚ model: blip2â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“ answer: "ê²€ì¶œëœ ì¹˜ìˆ˜: Ã˜50, L100, ..."
```

**ê²°ê³¼**:
```json
{
  "mode": "vqa",
  "question": "ì´ ë„ë©´ì˜ ëª¨ë“  ì¹˜ìˆ˜ ê°’ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”",
  "answer": "ê²€ì¶œëœ ì¹˜ìˆ˜: ì§ê²½ Ã˜50mm, ê¸¸ì´ L100mm, ê³µì°¨ Â±0.05mm",
  "confidence": 0.92
}
```

---

### ì˜ˆì‹œ 2: ìš©ì ‘ ê¸°í˜¸ ì°¾ê¸°

**ì›Œí¬í”Œë¡œìš°**:
```
[ImageInput] â”€â”€â”¬â”€â”€â†’ [VL Model]
               â”‚     text: "ìš©ì ‘ ê¸°í˜¸ë¥¼ ëª¨ë‘ ì°¾ì•„ì¤˜"
[TextInput] â”€â”€â”€â”˜
```

**ê²°ê³¼**:
```json
{
  "mode": "vqa",
  "question": "ìš©ì ‘ ê¸°í˜¸ë¥¼ ëª¨ë‘ ì°¾ì•„ì¤˜",
  "answer": "í•„ë › ìš©ì ‘ ê¸°í˜¸ 3ê°œ, ë§ëŒ€ê¸° ìš©ì ‘ ê¸°í˜¸ 1ê°œ ë°œê²¬",
  "confidence": 0.88
}
```

---

### ì˜ˆì‹œ 3: í”„ë¡¬í”„íŠ¸ ì—†ì´ ì‚¬ìš©

**ì›Œí¬í”Œë¡œìš°**:
```
[ImageInput] â”€â”€â†’ [VL Model]
                 (í”„ë¡¬í”„íŠ¸ ì—°ê²° ì•ˆ í•¨)
```

**ê²°ê³¼**:
```json
{
  "mode": "captioning",
  "caption": "ê¸°ê³„ ë¶€í’ˆ ì„¤ê³„ ë„ë©´, ì›í†µí˜• ìƒ¤í”„íŠ¸, ì¹˜ìˆ˜ í‘œê¸° í¬í•¨",
  "objects": ["shaft", "dimension", "centerline"]
}
```

---

## ğŸ“Š ë¹„êµ: í”„ë¡¬í”„íŠ¸ ìœ ë¬´

| ëª¨ë“œ | í”„ë¡¬í”„íŠ¸ | ê²°ê³¼ |
|------|---------|------|
| **ìº¡ì…”ë‹** | âŒ ì—†ìŒ | "ê¸°ê³„ ë¶€í’ˆ ë„ë©´ì…ë‹ˆë‹¤" (ì¼ë°˜ì ) |
| **VQA** | âœ… "ì¹˜ìˆ˜ë¥¼ ì•Œë ¤ì¤˜" | "Ã˜50mm, L100mm" (êµ¬ì²´ì ) |

**ê²°ë¡ **: í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ë©´ **í›¨ì”¬ ì •í™•í•œ ì •ë³´**ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ”§ êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸

### VL API ì„œë²„ (Backend)
- [ ] `/api/v1/analyze`ì— `prompt` íŒŒë¼ë¯¸í„° ì¶”ê°€
- [ ] VQA ëª¨ë“œ êµ¬í˜„ (ì§ˆë¬¸-ë‹µë³€)
- [ ] ìº¡ì…”ë‹ ëª¨ë“œ ìœ ì§€ (í•˜ìœ„ í˜¸í™˜ì„±)
- [ ] `/api/v1/info`ì— inputs, input_mappings ì¶”ê°€

### Gateway API (Executor)
- [ ] `vl_executor.py`ì—ì„œ `inputs.get("text")` ì²˜ë¦¬
- [ ] promptë¥¼ VL APIë¡œ ì „ë‹¬
- [ ] ì¶œë ¥ íŒŒì‹± (mode, answer, caption)

### Web UI (Frontend)
- [ ] `nodeDefinitions.ts` VL ë…¸ë“œì— `text` input ì¶”ê°€
- [ ] `recommendedInputs`ì— TextInput ì¶”ê°€
- [ ] ì‚¬ìš© ê°€ì´ë“œ ì—…ë°ì´íŠ¸

### í…ŒìŠ¤íŠ¸
- [ ] TextInput + VL ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸
- [ ] í”„ë¡¬í”„íŠ¸ ìœ ë¬´ ê²°ê³¼ ë¹„êµ
- [ ] ë‹¤ì–‘í•œ ì§ˆë¬¸ ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦

---

## ğŸ¯ ê¸°ëŒ€ íš¨ê³¼

### Before (í”„ë¡¬í”„íŠ¸ ì—†ìŒ)
```
ImageInput â†’ VL Model â†’ "ê¸°ê³„ ë¶€í’ˆ ë„ë©´"
                         (ëª¨í˜¸í•œ ì¼ë°˜ ì„¤ëª…)
```

### After (í”„ë¡¬í”„íŠ¸ ìˆìŒ)
```
ImageInput â”€â”¬â”€â†’ VL Model â†’ "Ã˜50mm, L100mm, Â±0.05mm"
            â”‚              (ì •í™•í•œ ì¹˜ìˆ˜ ì •ë³´)
TextInput â”€â”€â”˜
"ì¹˜ìˆ˜ ì¶”ì¶œ"
```

**ê°œì„ ì **:
- âœ… ì •í™•ë„ í–¥ìƒ (30% â†’ 90%)
- âœ… ì‚¬ìš©ì ì˜ë„ ë°˜ì˜
- âœ… ë§ì¶¤í˜• ë¶„ì„ ê°€ëŠ¥

---

## ğŸ“ í–¥í›„ í™•ì¥

### 1. Multi-turn ëŒ€í™”
```
ì‚¬ìš©ì: "ì´ ë„ë©´ì˜ ì¹˜ìˆ˜ëŠ”?"
VL: "Ã˜50mmì…ë‹ˆë‹¤"
ì‚¬ìš©ì: "ê³µì°¨ëŠ”?"
VL: "Â±0.05mmì…ë‹ˆë‹¤"
```

### 2. Chain of Thought
```
TextInput: "ë‹¨ê³„ë³„ë¡œ ë¶„ì„: 1) ìš©ì ‘ ê¸°í˜¸ ì°¾ê¸° 2) ì¹˜ìˆ˜ ì¶”ì¶œ 3) ê³µì°¨ ê²€ì¦"
VL: "1ë‹¨ê³„ - ìš©ì ‘ ê¸°í˜¸ 3ê°œ ë°œê²¬..."
```

### 3. ë‹¤êµ­ì–´ ì§€ì›
```
TextInput: "Extract all dimensions in English"
VL: "Detected dimensions: Ã˜50mm, L100mm..."
```

---

**Last Updated**: 2025-11-22
**Status**: ğŸ“‹ êµ¬í˜„ ê°€ì´ë“œ (ì‹¤ì œ êµ¬í˜„ í•„ìš”)
**Priority**: High (VL API í™œìš©ë„ ëŒ€í­ í–¥ìƒ)
