# 트러블슈팅 가이드

**작성일**: 2025-11-03
**대상**: 개발자 및 시스템 관리자
**버전**: v1.0

---

## 📋 목차

1. [일반적인 문제](#1-일반적인-문제)
2. [학습 관련 문제](#2-학습-관련-문제)
3. [API 서버 문제](#3-api-서버-문제)
4. [Docker 관련 문제](#4-docker-관련-문제)
5. [성능 문제](#5-성능-문제)
6. [데이터 관련 문제](#6-데이터-관련-문제)
7. [GPU 관련 문제](#7-gpu-관련-문제)

---

## 1. 일반적인 문제

### 1.1. Python 버전 불일치

**증상**:
"ERROR: Python 3.12 is not supported" 오류 메시지가 표시됩니다.

**원인**: Ultralytics 라이브러리는 Python 3.8-3.11만 지원합니다.

**해결**:
pyenv를 사용하여 Python 3.10.12 버전을 설치하고 로컬 환경으로 설정합니다. 또는 conda를 사용하여 Python 3.10 환경을 새로 생성할 수도 있습니다.

---

### 1.2. 의존성 충돌

**증상**:
"ERROR: Cannot install ultralytics and opencv-python" 메시지가 표시됩니다.

**해결**:
기존 가상환경을 완전히 삭제하고 Python 3.10으로 새로운 가상환경을 생성합니다. 그 다음 pip를 최신 버전으로 업그레이드하고, PyTorch와 torchvision을 CUDA 11.8 인덱스에서 설치한 후, 마지막으로 Ultralytics를 설치합니다. 이 순서를 지키는 것이 중요합니다.

---

### 1.3. 권한 문제

**증상**:
"Permission denied: '/home/uproot/ax/poc/datasets'" 오류가 발생합니다.

**해결**:
먼저 datasets 디렉토리의 현재 권한 상태를 확인합니다. 그 다음 디렉토리에 읽기/쓰기/실행 권한(755)을 부여하고, 소유권을 현재 사용자로 변경합니다.

---

## 2. 학습 관련 문제

### 2.1. CUDA Out of Memory

**증상**:
"RuntimeError: CUDA out of memory. Tried to allocate 1.5 GB" 오류가 발생합니다.

**원인**: GPU VRAM 부족

**해결 1: 배치 크기 줄이기**
학습 스크립트 실행 시 배치 크기를 16에서 8로 줄이거나, 이미지 크기를 1280으로 감소시킵니다. 이렇게 하면 메모리 사용량이 크게 줄어듭니다.

**해결 2: 작은 모델 사용**
모델 크기를 nano(n) 버전으로 변경합니다. 모델 크기는 n < s < m < l 순서로 커지며, 작은 모델일수록 메모리를 적게 사용합니다.

**해결 3: CPU 학습**
GPU가 부족한 경우 device를 cpu로 설정하여 학습할 수 있습니다. 속도는 느리지만 메모리 제약이 없습니다.

---

### 2.2. 학습이 너무 느림

**증상**: 1 epoch에 30분 이상 소요됩니다.

**확인**:
Python에서 torch.cuda.is_available()과 torch.cuda.get_device_name()을 실행하여 GPU가 인식되는지 확인합니다. 첫 번째 명령어는 True를 반환해야 하고, 두 번째 명령어는 GPU 이름을 표시해야 합니다.

**해결 1: GPU 사용 확인**
nvidia-smi 명령어로 GPU가 실제로 사용되고 있는지 확인합니다. GPU 사용을 강제하려면 스크립트 실행 시 --device 0 옵션을 추가합니다.

**해결 2: 데이터 로딩 최적화**
학습 스크립트에 --workers 8 옵션을 추가하여 데이터 로딩을 병렬화합니다. workers 수는 CPU 코어 수에 맞게 조정합니다.

---

### 2.3. 학습 중 중단

**증상**: 학습 중 갑자기 프로세스가 멈춥니다.

**원인 1: Timeout**

**해결**:
체크포인트 파일에서 학습을 재개할 수 있습니다. 스크립트 실행 시 --resume 옵션과 함께 last.pt 체크포인트 파일 경로를 지정합니다.

**원인 2: 디스크 공간 부족**

**해결**:
`df -h` 명령어로 디스크 여유 공간을 확인합니다. 공간이 부족하면 불필요한 파일을 삭제합니다. 예를 들어 이전 추론 결과 디렉토리를 제거할 수 있습니다.

---

### 2.4. Loss가 감소하지 않음

**증상**: Loss 값이 계속 일정하거나 오히려 증가합니다.

**원인**: 학습률이 너무 크거나 작습니다.

**해결**:
학습률을 조정합니다. 기본값 0.001보다 작은 0.0001로 설정하여 더 안정적인 학습을 시도합니다.

**원인 2: 데이터 문제**

**확인**:
데이터셋 검증을 실행하여 데이터에 문제가 없는지 확인합니다. YOLO 모델의 val 메서드를 사용하여 데이터셋 구조와 라벨이 올바른지 검사할 수 있습니다.

---

### 2.5. mAP가 낮음

**증상**: mAP50 값이 0.3 미만입니다.

**해결 1: 더 많은 데이터**
합성 데이터 생성 스크립트를 사용하여 10,000장의 학습 데이터를 추가로 생성합니다.

**해결 2: 더 긴 학습**
epoch 수를 200으로 증가시켜 모델이 충분히 학습할 수 있도록 합니다.

**해결 3: 더 큰 모델**
모델 크기를 medium(m)으로 변경하여 더 많은 파라미터로 복잡한 패턴을 학습하도록 합니다.

---

## 3. API 서버 문제

### 3.1. 포트 이미 사용 중

**증상**:
"ERROR: Port 5005 is already in use" 오류가 표시됩니다.

**확인**:
`lsof` 또는 `netstat` 명령어로 5005번 포트를 사용하는 프로세스의 PID를 확인합니다.

**해결 1: 프로세스 종료**
확인한 PID에 해당하는 프로세스를 강제 종료합니다.

**해결 2: 다른 포트 사용**
환경 변수 YOLO_API_PORT를 5006으로 설정하고 API 서버를 시작합니다.

---

### 3.2. 모델 파일 없음

**증상**:
"FileNotFoundError: Model file not found: /app/models/best.pt" 오류가 발생합니다.

**해결**:
yolo-api/models 디렉토리를 생성하고 학습된 모델 파일(best.pt)을 해당 디렉토리로 복사합니다. 또는 심볼릭 링크를 생성하여 원본 파일을 참조하도록 설정할 수 있습니다.

---

### 3.3. API 응답 없음

**증상**: 요청 후 응답이 없고 타임아웃이 발생합니다.

**확인**:
API 서버의 로그 파일을 실시간으로 확인하여 오류 메시지를 찾습니다. Docker 환경인 경우 컨테이너 로그를 확인합니다.

**해결**:
curl 요청 시 --max-time 옵션을 300(5분)으로 설정하여 타임아웃을 연장합니다. 대용량 이미지 처리에는 더 많은 시간이 필요할 수 있습니다.

---

### 3.4. 파일 업로드 실패

**증상**:
JSON 응답에 "FILE_TOO_LARGE" 오류가 반환됩니다.

**해결 1: 이미지 크기 줄이기**
ImageMagick의 convert 명령어나 Python PIL 라이브러리를 사용하여 이미지를 1920x1080 크기로 리사이즈합니다. thumbnail 메서드를 사용하면 종횡비를 유지하면서 크기를 줄일 수 있습니다.

**해결 2: 서버 설정 변경**
API 서버의 Python 코드에서 max_upload_size를 50MB(50 * 1024 * 1024 바이트)로 증가시킵니다.

---

## 4. Docker 관련 문제

### 4.1. Docker 이미지 빌드 실패

**증상**:
"ERROR: failed to solve: process \"/bin/sh -c pip install ...\" did not complete" 오류가 발생합니다.

**해결**:
Docker 빌드 캐시를 사용하지 않고 처음부터 다시 빌드합니다. --no-cache 옵션을 사용하거나, DOCKER_BUILDKIT=1 환경 변수를 설정하여 새로운 빌드킷을 활성화할 수 있습니다.

---

### 4.2. 컨테이너가 즉시 종료됨

**증상**:
`docker ps` 실행 시 컨테이너가 목록에 표시되지 않습니다.

**확인**:
해당 컨테이너의 로그를 확인하여 종료 원인을 파악합니다. `docker ps -a` 명령어로 종료된 컨테이너를 포함한 모든 컨테이너를 확인할 수 있습니다.

**해결**:
인터랙티브 모드(-it 옵션)와 bash 셸로 컨테이너를 실행하여 직접 문제를 진단합니다. 문제를 해결한 후 컨테이너를 재시작합니다.

---

### 4.3. Docker Compose 실행 실패

**증상**:
"ERROR: Network ax_poc_network not found" 오류가 표시됩니다.

**해결**:
필요한 Docker 네트워크를 수동으로 생성합니다. 또는 docker-compose를 완전히 중지했다가 다시 시작하면 필요한 네트워크가 자동으로 생성됩니다.

---

### 4.4. 볼륨 마운트 문제

**증상**: 컨테이너 내에서 모델 파일에 접근할 수 없습니다.

**해결**:
절대 경로를 사용하여 볼륨을 마운트합니다. $(pwd) 명령어로 현재 디렉토리의 절대 경로를 얻고, :ro 옵션으로 읽기 전용 마운트를 설정합니다. 디렉토리 권한도 확인합니다. SELinux가 활성화된 시스템에서는 :ro,z 옵션을 사용하여 SELinux 컨텍스트를 자동으로 설정합니다.

---

## 5. 성능 문제

### 5.1. 추론이 너무 느림

**증상**: 1장당 10초 이상 소요됩니다.

**확인**:
Python에서 torch.cuda.is_available()로 GPU 사용 가능 여부를 확인하고, torch.__version__으로 PyTorch 버전을 확인합니다.

**해결 1: GPU 사용**
추론 스크립트 실행 시 --device 0 옵션을 추가하여 GPU 0번을 강제로 사용하도록 설정합니다.

**해결 2: 이미지 크기 줄이기**
--imgsz 640 옵션으로 입력 이미지 크기를 1280에서 640으로 줄입니다. 처리 속도가 크게 향상되지만 정확도는 다소 감소할 수 있습니다.

**해결 3: Half precision (FP16)**
--half 옵션을 사용하여 16비트 부동소수점 연산을 활성화합니다. GPU에서만 지원되며, 메모리 사용량과 처리 시간을 약 50% 감소시킵니다.

---

### 5.2. 메모리 부족

**증상**:
"MemoryError: Unable to allocate array" 오류가 발생합니다.

**해결 1: 배치 처리 줄이기**
코드를 수정하여 이미지를 한 장씩 처리하도록 변경합니다. 각 이미지 처리 후 results 객체를 삭제하고 torch.cuda.empty_cache()를 호출하여 GPU 메모리를 해제합니다.

**해결 2: Swap 메모리 증가**
Linux 시스템에서 8GB 크기의 스왑 파일을 생성하고 활성화합니다. fallocate로 파일을 할당하고, chmod로 권한을 설정한 후, mkswap과 swapon으로 스왑을 초기화하고 활성화합니다.

---

## 6. 데이터 관련 문제

### 6.1. 합성 데이터 생성 실패

**증상**:
"OSError: cannot open resource" 오류가 발생합니다.

**원인**: 폰트 파일이 없습니다.

**해결**:
시스템에 DejaVu와 Liberation 폰트를 설치합니다. 또는 GitHub에서 폰트를 다운로드하여 압축을 해제하고, TTF 파일들을 홈 디렉토리의 .fonts 폴더로 복사한 후, 폰트 캐시를 갱신합니다.

---

### 6.2. 라벨 형식 오류

**증상**:
"ValueError: Invalid YOLO label format" 오류가 발생합니다.

**확인**:
라벨 파일의 첫 몇 줄을 확인하여 형식이 올바른지 검사합니다.

**예상 형식**:
각 줄은 "클래스번호 중심x 중심y 너비 높이" 형식이어야 합니다. 모든 값은 0과 1 사이의 정규화된 좌표입니다. 예: "0 0.5234 0.6123 0.0345 0.0234"

**해결**:
라벨 형식이 잘못된 경우 합성 데이터 생성 스크립트를 다시 실행하여 올바른 형식의 라벨을 재생성합니다.

---

### 6.3. 데이터셋 병합 실패

**증상**:
"FileNotFoundError: data.yaml not found" 오류가 발생합니다.

**해결**:
각 데이터셋 디렉토리에 data.yaml 파일이 존재하는지 확인합니다. 파일이 없으면 데이터셋 준비 스크립트를 실행하여 생성합니다.

---

## 7. GPU 관련 문제

### 7.1. CUDA 버전 불일치

**증상**:
"RuntimeError: CUDA version mismatch" 오류가 발생합니다.

**확인**:
nvcc --version으로 CUDA 컴파일러 버전을 확인하고, nvidia-smi로 드라이버가 지원하는 CUDA 버전을 확인합니다. Python에서는 torch.version.cuda로 PyTorch가 사용하는 CUDA 버전을 확인할 수 있습니다.

**해결**:
PyTorch와 torchvision을 제거한 후, 시스템의 CUDA 버전(예: 11.8)에 맞는 버전을 PyTorch 공식 저장소에서 재설치합니다.

---

### 7.2. GPU 인식 안 됨

**증상**:
Python에서 torch.cuda.is_available()이 False를 반환합니다.

**확인**:
nvidia-smi로 NVIDIA 드라이버가 정상적으로 작동하는지 확인합니다. CUDA 라이브러리 파일(libcudart.so)이 존재하는지 확인합니다.

**해결 1: 드라이버 재설치**
기존 NVIDIA 드라이버를 완전히 제거하고 최신 버전(예: 535)을 설치합니다. 설치 후 시스템을 재부팅합니다.

**해결 2: LD_LIBRARY_PATH 설정**
환경 변수를 설정하여 CUDA 라이브러리와 바이너리 경로를 시스템에 알립니다. LD_LIBRARY_PATH에 CUDA lib64 디렉토리를, PATH에 CUDA bin 디렉토리를 추가합니다.

---

### 7.3. 다중 GPU 문제

**증상**: GPU 0번만 사용되고 다른 GPU는 사용되지 않습니다.

**해결 1: 특정 GPU 선택**
CUDA_VISIBLE_DEVICES 환경 변수로 사용할 GPU를 지정합니다. GPU 1번만 사용하려면 CUDA_VISIBLE_DEVICES=1로 설정하고, 여러 GPU를 사용하려면 --device 0,1 옵션을 추가합니다.

**해결 2: DDP (DistributedDataParallel)**
PyTorch의 분산 학습을 사용하여 여러 GPU에서 병렬로 학습합니다. torch.distributed.run 모듈을 사용하고 --nproc_per_node=2로 사용할 GPU 개수를 지정합니다.

---

## 🔍 디버깅 팁

### 1. 로그 레벨 설정

상세한 디버깅 정보를 얻기 위해 YOLO_VERBOSE 환경 변수를 1로 설정합니다. Python에서는 logging 모듈의 레벨을 DEBUG로 설정하여 모든 디버그 메시지를 출력할 수 있습니다.

### 2. 프로파일링

PyTorch Profiler를 사용하여 CPU와 CUDA 활동을 추적합니다. 모델 추론을 프로파일러 컨텍스트 내에서 실행하고, 결과를 CUDA 시간 기준으로 정렬하여 어떤 연산이 가장 많은 시간을 소비하는지 확인할 수 있습니다.

### 3. 메모리 추적

torch.cuda.memory_allocated()로 현재 할당된 GPU 메모리를, torch.cuda.memory_reserved()로 예약된 총 메모리를 확인합니다. GB 단위로 표시하려면 1024**3으로 나눕니다. torch.cuda.memory_summary()는 전체 메모리 사용 현황을 상세히 보여줍니다.

---

## 📞 추가 지원

문제가 해결되지 않는 경우:

1. **로그 수집**: 전체 에러 로그 첨부
2. **환경 정보**: Python/CUDA/GPU 정보 제공
3. **재현 방법**: 문제 재현 단계 상세히 기술
4. **문서 참조**: 관련 문서 및 가이드 확인

---

**작성자**: AX 실증사업팀
**최종 업데이트**: 2025-11-03
