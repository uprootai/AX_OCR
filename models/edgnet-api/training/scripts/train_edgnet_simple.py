#!/usr/bin/env python3
"""
EDGNet ê°„ë‹¨ GPU í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

ì¦ê°•ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ GraphSAGE ëª¨ë¸ í•™ìŠµ
"""

import sys
import json
import time
import logging
from pathlib import Path
from typing import List, Dict
import numpy as np

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.optim import Adam
from sklearn.model_selection import train_test_split

# Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# í´ë˜ìŠ¤ ë§¤í•‘
CLASS_NAMES = [
    'diameter_dim', 'linear_dim', 'radius_dim', 'angular_dim',
    'chamfer_dim', 'tolerance_dim', 'reference_dim',
    'flatness', 'cylindricity', 'position', 'perpendicularity',
    'parallelism', 'surface_roughness', 'text_block'
]
CLASS_TO_IDX = {name: idx for idx, name in enumerate(CLASS_NAMES)}


class SimpleGraphNet(nn.Module):
    """ê°„ë‹¨í•œ ê·¸ë˜í”„ ì‹ ê²½ë§"""

    def __init__(self, num_features: int, num_classes: int, hidden_dim: int = 64):
        super().__init__()

        # ë…¸ë“œ íŠ¹ì§• ì„ë² ë”©
        self.fc1 = nn.Linear(num_features, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, hidden_dim)
        self.fc3 = nn.Linear(hidden_dim, num_classes)

        self.dropout = nn.Dropout(0.3)

    def forward(self, x):
        """
        x: (num_nodes, num_features)
        """
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = F.relu(self.fc2(x))
        x = self.dropout(x)
        x = self.fc3(x)
        return x


def load_dataset(data_dir: Path):
    """ì¦ê°•ëœ ë°ì´í„°ì…‹ ë¡œë“œ"""

    logger.info(f"Loading dataset from {data_dir}")

    json_files = [f for f in data_dir.glob("*.json") if f.name != "metadata.json"]

    all_features = []
    all_labels = []

    for json_file in json_files:
        with open(json_file, 'r') as f:
            data = json.load(f)

        nodes = data.get('graph_nodes', [])

        for node in nodes:
            # íŠ¹ì§• ì¶”ì¶œ: bbox (x, y, width, height) + ì •ê·œí™”
            bbox = node.get('bbox', {})
            x = bbox.get('x', 0)
            y = bbox.get('y', 0)
            w = bbox.get('width', 1)
            h = bbox.get('height', 1)

            # ê°„ë‹¨í•œ íŠ¹ì§•: [x, y, w, h, area, aspect_ratio]
            area = w * h
            aspect = w / max(h, 1)

            features = [x / 2000.0, y / 2000.0, w / 500.0, h / 500.0, area / 100000.0, aspect]

            # ë ˆì´ë¸”
            class_name = node.get('class_name', 'text_block')
            label = CLASS_TO_IDX.get(class_name, CLASS_TO_IDX['text_block'])

            all_features.append(features)
            all_labels.append(label)

    logger.info(f"Loaded {len(all_features)} nodes")

    return np.array(all_features, dtype=np.float32), np.array(all_labels, dtype=np.int64)


def train_model(data_dir: Path, output_dir: Path, device: str = 'cuda', epochs: int = 100):
    """ëª¨ë¸ í•™ìŠµ"""

    logger.info("=" * 70)
    logger.info("EDGNet ê°„ë‹¨ í•™ìŠµ")
    logger.info("=" * 70)

    # GPU í™•ì¸
    if device == 'cuda' and not torch.cuda.is_available():
        logger.warning("CUDA not available, using CPU")
        device = 'cpu'

    if device == 'cuda':
        logger.info(f"ğŸ”¥ GPU: {torch.cuda.get_device_name(0)}")
        logger.info(f"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")

    device = torch.device(device)

    # ë°ì´í„° ë¡œë“œ
    X, y = load_dataset(data_dir)

    # Train/val split
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

    logger.info(f"Train: {len(X_train)}, Val: {len(X_val)}")

    # í…ì„œ ë³€í™˜
    X_train_t = torch.from_numpy(X_train).to(device)
    y_train_t = torch.from_numpy(y_train).to(device)
    X_val_t = torch.from_numpy(X_val).to(device)
    y_val_t = torch.from_numpy(y_val).to(device)

    # ëª¨ë¸
    num_features = X.shape[1]
    num_classes = len(CLASS_NAMES)

    model = SimpleGraphNet(num_features, num_classes, hidden_dim=64).to(device)

    num_params = sum(p.numel() for p in model.parameters())
    logger.info(f"Model parameters: {num_params:,}")

    # ì˜µí‹°ë§ˆì´ì €
    optimizer = Adam(model.parameters(), lr=0.01)
    criterion = nn.CrossEntropyLoss()

    # í•™ìŠµ
    logger.info("ğŸš€ Training started...")
    start_time = time.time()

    best_val_acc = 0.0
    best_model_state = None

    for epoch in range(epochs):
        # Train
        model.train()
        optimizer.zero_grad()

        out = model(X_train_t)
        loss = criterion(out, y_train_t)
        loss.backward()
        optimizer.step()

        train_acc = (out.argmax(dim=1) == y_train_t).float().mean().item()

        # Validation
        model.eval()
        with torch.no_grad():
            val_out = model(X_val_t)
            val_loss = criterion(val_out, y_val_t)
            val_acc = (val_out.argmax(dim=1) == y_val_t).float().mean().item()

        if val_acc > best_val_acc:
            best_val_acc = val_acc
            best_model_state = model.state_dict().copy()

        if epoch % 10 == 0 or epoch == epochs - 1:
            logger.info(
                f"Epoch {epoch:3d}/{epochs} | "
                f"Loss: {loss.item():.4f}, Acc: {train_acc:.4f} | "
                f"Val Loss: {val_loss.item():.4f}, Val Acc: {val_acc:.4f}"
            )

    total_time = time.time() - start_time
    logger.info(f"âœ… Training completed in {total_time:.1f} seconds")
    logger.info(f"   Best Val Accuracy: {best_val_acc:.4f}")

    # ëª¨ë¸ ì €ì¥
    output_dir.mkdir(parents=True, exist_ok=True)
    model_path = output_dir / "edgnet_simple.pth"

    torch.save({
        'model_state_dict': best_model_state,
        'num_features': num_features,
        'num_classes': num_classes,
        'hidden_dim': 64,
        'class_names': CLASS_NAMES,
        'best_val_acc': best_val_acc
    }, model_path)

    logger.info(f"ğŸ’¾ Model saved to {model_path}")

    # ë©”íƒ€ë°ì´í„°
    metadata = {
        'model': 'SimpleGraphNet',
        'num_features': num_features,
        'num_classes': num_classes,
        'num_parameters': num_params,
        'epochs': epochs,
        'best_val_acc': float(best_val_acc),
        'training_time_seconds': total_time,
        'device': str(device),
        'training_samples': len(X_train),
        'validation_samples': len(X_val)
    }

    metadata_path = output_dir / "training_metadata.json"
    with open(metadata_path, 'w') as f:
        json.dump(metadata, f, indent=2)

    logger.info(f"ğŸ“„ Metadata saved to {metadata_path}")
    logger.info("=" * 70)

    return model, metadata


def main():
    """ë©”ì¸ í•¨ìˆ˜"""

    # ê²½ë¡œ
    data_dir = Path("/home/uproot/ax/poc/edgnet_dataset_augmented")
    output_dir = Path("/home/uproot/ax/poc/edgnet-api/models")

    # ë°ì´í„° í™•ì¸
    if not data_dir.exists():
        logger.error(f"âŒ Dataset not found: {data_dir}")
        logger.error("   Please run: python3 scripts/augment_edgnet_simple.py")
        return 1

    # í•™ìŠµ
    try:
        model, metadata = train_model(
            data_dir=data_dir,
            output_dir=output_dir,
            device='cuda',
            epochs=100
        )

        logger.info("")
        logger.info("ğŸ‰ EDGNet training successful!")
        logger.info(f"ğŸ“ˆ Validation Accuracy: {metadata['best_val_acc']:.2%}")
        logger.info("")
        logger.info("Next steps:")
        logger.info("1. Test the model")
        logger.info("2. Update EDGNet API to use new model")
        logger.info("3. Restart edgnet-api service")

        return 0

    except Exception as e:
        logger.error(f"âŒ Training failed: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
