#!/usr/bin/env python3
"""
eDOCr ê²°ê³¼ë¥¼ YOLO ë°ì´í„°ì…‹ìœ¼ë¡œ ë³€í™˜
"""
import os
import json
import shutil
from pathlib import Path
from PIL import Image
import random

def create_dataset_structure(output_dir):
    """ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ ìƒì„±"""
    dirs = [
        'images/train', 'images/val', 'images/test',
        'labels/train', 'labels/val', 'labels/test'
    ]
    for d in dirs:
        Path(output_dir / d).mkdir(parents=True, exist_ok=True)

def classify_dimension(text):
    """ì¹˜ìˆ˜ í…ìŠ¤íŠ¸ë¥¼ í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜"""
    text = text.strip()

    # Diameter
    if text.startswith('Ï†') or text.startswith('Ã˜'):
        return 0, 'diameter_dim'

    # Radius
    if text.startswith('R'):
        return 2, 'radius_dim'

    # Angular
    if 'Â°' in text:
        return 3, 'angular_dim'

    # Chamfer
    if 'x' in text and 'Â°' in text:
        return 4, 'chamfer_dim'
    if text.startswith('C'):
        return 4, 'chamfer_dim'

    # Tolerance
    if 'Â±' in text or ('+' in text and '-' in text):
        return 5, 'tolerance_dim'

    # Reference (in parentheses)
    if text.startswith('(') and text.endswith(')'):
        return 6, 'reference_dim'

    # Default: linear dimension
    return 1, 'linear_dim'

def classify_gdt_symbol(symbol_type):
    """GD&T ê¸°í˜¸ ë¶„ë¥˜"""
    gdt_map = {
        'flatness': 7,
        'cylindricity': 8,
        'position': 9,
        'perpendicularity': 10,
        'parallelism': 11
    }
    return gdt_map.get(symbol_type.lower(), 7)

def edocr_to_yolo_format(bbox, image_width, image_height):
    """eDOCr bboxë¥¼ YOLO í¬ë§·ìœ¼ë¡œ ë³€í™˜"""
    x = bbox.get('x', 0)
    y = bbox.get('y', 0)
    w = bbox.get('width', 50)
    h = bbox.get('height', 30)

    # ì¤‘ì‹¬ì  ê³„ì‚°
    x_center = (x + w / 2) / image_width
    y_center = (y + h / 2) / image_height

    # í¬ê¸° ì •ê·œí™”
    norm_width = w / image_width
    norm_height = h / image_height

    # 0-1 ë²”ìœ„ë¡œ í´ë¦¬í•‘
    x_center = max(0, min(1, x_center))
    y_center = max(0, min(1, y_center))
    norm_width = max(0, min(1, norm_width))
    norm_height = max(0, min(1, norm_height))

    return x_center, y_center, norm_width, norm_height

def convert_annotation(annotation, image_path, output_label_path):
    """
    ë‹¨ì¼ ì–´ë…¸í…Œì´ì…˜ì„ YOLO í¬ë§·ìœ¼ë¡œ ë³€í™˜
    """
    # ì´ë¯¸ì§€ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
    with Image.open(image_path) as img:
        img_width, img_height = img.size

    yolo_lines = []

    # Dimensions ë³€í™˜
    if 'dimensions' in annotation and annotation['dimensions']:
        for dim in annotation['dimensions']:
            if 'bbox' not in dim or 'value' not in dim:
                continue

            bbox = dim['bbox']
            value = dim['value']

            # í´ë˜ìŠ¤ ë¶„ë¥˜
            class_id, class_name = classify_dimension(value)

            # YOLO í¬ë§· ë³€í™˜
            x_center, y_center, width, height = edocr_to_yolo_format(
                bbox, img_width, img_height
            )

            yolo_lines.append(
                f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}"
            )

    # GD&T ê¸°í˜¸ ë³€í™˜
    if 'gdt' in annotation and annotation['gdt']:
        for gdt in annotation['gdt']:
            if 'bbox' not in gdt or 'type' not in gdt:
                continue

            bbox = gdt['bbox']
            symbol_type = gdt['type']

            # í´ë˜ìŠ¤ ë¶„ë¥˜
            class_id = classify_gdt_symbol(symbol_type)

            # YOLO í¬ë§· ë³€í™˜
            x_center, y_center, width, height = edocr_to_yolo_format(
                bbox, img_width, img_height
            )

            yolo_lines.append(
                f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}"
            )

    # ë¼ë²¨ íŒŒì¼ ì €ì¥
    with open(output_label_path, 'w') as f:
        f.write('\n'.join(yolo_lines))

    return len(yolo_lines)

def split_dataset(image_files, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):
    """ë°ì´í„°ì…‹ì„ train/val/testë¡œ ë¶„í• """
    random.shuffle(image_files)

    total = len(image_files)
    train_end = int(total * train_ratio)
    val_end = train_end + int(total * val_ratio)

    return {
        'train': image_files[:train_end],
        'val': image_files[train_end:val_end],
        'test': image_files[val_end:]
    }

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ì„¤ì •
    source_images_dir = Path('/home/uproot/ax/poc/edocr2-api/uploads')
    source_annotations_dir = Path('/home/uproot/ax/poc/edocr2-api/results')
    output_dir = Path('/home/uproot/ax/poc/datasets/engineering_drawings')

    print("ğŸ“ Creating dataset structure...")
    create_dataset_structure(output_dir)

    # ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜ì§‘
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']
    image_files = []

    for ext in image_extensions:
        image_files.extend(source_images_dir.glob(f'*{ext}'))

    print(f"ğŸ“Š Found {len(image_files)} images")

    if len(image_files) == 0:
        print("âŒ No images found. Please add images to:", source_images_dir)
        print("   Run eDOCr2 API to generate annotations first.")
        return

    # Train/Val/Test ë¶„í• 
    splits = split_dataset(image_files)

    print(f"âœ‚ï¸  Split: Train={len(splits['train'])}, Val={len(splits['val'])}, Test={len(splits['test'])}")

    # ê° ë¶„í• ë³„ë¡œ ì²˜ë¦¬
    total_annotations = 0

    for split_name, split_files in splits.items():
        print(f"\nğŸ”„ Processing {split_name} split...")

        for img_path in split_files:
            # ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ ì°¾ê¸°
            annotation_path = source_annotations_dir / f"{img_path.stem}_result.json"

            if not annotation_path.exists():
                print(f"âš ï¸  No annotation for {img_path.name}, skipping")
                continue

            # ì´ë¯¸ì§€ ë³µì‚¬
            dst_image = output_dir / 'images' / split_name / img_path.name
            shutil.copy(img_path, dst_image)

            # ì–´ë…¸í…Œì´ì…˜ ë¡œë“œ
            with open(annotation_path, 'r') as f:
                annotation = json.load(f)

            # YOLO ë¼ë²¨ ìƒì„±
            dst_label = output_dir / 'labels' / split_name / f"{img_path.stem}.txt"
            count = convert_annotation(annotation, img_path, dst_label)

            total_annotations += count

            if count > 0:
                print(f"âœ… {img_path.name}: {count} objects")
            else:
                print(f"âš ï¸  {img_path.name}: No objects detected")

    print(f"\nğŸ‰ Dataset creation complete!")
    print(f"   Total images: {len(image_files)}")
    print(f"   Total annotations: {total_annotations}")
    print(f"   Output directory: {output_dir}")

    # data.yaml ìƒì„±
    yaml_path = output_dir / 'data.yaml'
    with open(yaml_path, 'w') as f:
        f.write(f"""# Engineering Drawings Dataset
path: {output_dir}
train: images/train
val: images/val
test: images/test

# Classes
names:
  0: diameter_dim
  1: linear_dim
  2: radius_dim
  3: angular_dim
  4: chamfer_dim
  5: tolerance_dim
  6: reference_dim
  7: flatness
  8: cylindricity
  9: position
  10: perpendicularity
  11: parallelism
  12: surface_roughness
  13: text_block

nc: 14
""")

    print(f"ğŸ“ Created data.yaml at: {yaml_path}")

if __name__ == '__main__':
    main()
