#!/usr/bin/env python3
"""
ì—¬ëŸ¬ ë°ì´í„°ì…‹ì„ ë³‘í•©í•˜ì—¬ í•˜ë‚˜ì˜ í†µí•© ë°ì´í„°ì…‹ ìƒì„±
"""
import argparse
import shutil
from pathlib import Path
import yaml
from tqdm import tqdm

def merge_datasets(dataset_paths, output_dir, weights=None):
    """
    ì—¬ëŸ¬ ë°ì´í„°ì…‹ì„ ë³‘í•©

    Args:
        dataset_paths: ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ ë¦¬ìŠ¤íŠ¸
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        weights: ê° ë°ì´í„°ì…‹ì˜ ìƒ˜í”Œë§ ë¹„ìœ¨ (Noneì´ë©´ ê· ë“±)
    """
    output_path = Path(output_dir)

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    for split in ['train', 'val', 'test']:
        (output_path / 'images' / split).mkdir(parents=True, exist_ok=True)
        (output_path / 'labels' / split).mkdir(parents=True, exist_ok=True)

    # ë°ì´í„°ì…‹ë³„ í†µê³„
    dataset_stats = {}

    # í´ë˜ìŠ¤ ì´ë¦„ ìˆ˜ì§‘ (ì²« ë²ˆì§¸ ë°ì´í„°ì…‹ ê¸°ì¤€)
    class_names = None
    nc = 0

    print("=" * 70)
    print("ğŸ”„ Merging datasets...")
    print("=" * 70)

    for dataset_path in dataset_paths:
        dataset_path = Path(dataset_path)
        dataset_name = dataset_path.name

        print(f"\nğŸ“‚ Processing: {dataset_name}")

        # data.yaml ë¡œë“œ
        yaml_path = dataset_path / 'data.yaml'
        if not yaml_path.exists():
            print(f"âš ï¸  No data.yaml found, skipping {dataset_name}")
            continue

        with open(yaml_path, 'r') as f:
            data_config = yaml.safe_load(f)

        # í´ë˜ìŠ¤ ì´ë¦„ ì €ì¥ (ì²« ë²ˆì§¸ë§Œ)
        if class_names is None:
            class_names = data_config.get('names', {})
            nc = data_config.get('nc', 14)

        stats = {'train': 0, 'val': 0, 'test': 0}

        # ê° splitë³„ë¡œ ì²˜ë¦¬
        for split in ['train', 'val', 'test']:
            src_images = dataset_path / 'images' / split
            src_labels = dataset_path / 'labels' / split

            if not src_images.exists():
                continue

            # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡
            image_files = list(src_images.glob('*.jpg')) + \
                         list(src_images.glob('*.jpeg')) + \
                         list(src_images.glob('*.png'))

            print(f"  {split}: {len(image_files)} images")

            for img_file in tqdm(image_files, desc=f"  {split}", leave=False):
                # ìƒˆ íŒŒì¼ëª… (ì¤‘ë³µ ë°©ì§€)
                new_name = f"{dataset_name}_{img_file.stem}{img_file.suffix}"

                # ì´ë¯¸ì§€ ë³µì‚¬
                dst_img = output_path / 'images' / split / new_name
                shutil.copy(img_file, dst_img)

                # ë¼ë²¨ ë³µì‚¬
                label_file = src_labels / f"{img_file.stem}.txt"
                if label_file.exists():
                    dst_label = output_path / 'labels' / split / f"{Path(new_name).stem}.txt"
                    shutil.copy(label_file, dst_label)
                    stats[split] += 1

        dataset_stats[dataset_name] = stats

    # data.yaml ìƒì„±
    yaml_path = output_path / 'data.yaml'
    with open(yaml_path, 'w') as f:
        f.write(f"""# Merged Dataset
path: {output_path.absolute()}
train: images/train
val: images/val
test: images/test

# Classes
names:
""")
        for cls_id, cls_name in class_names.items():
            f.write(f"  {cls_id}: {cls_name}\n")

        f.write(f"\nnc: {nc}\n")

    # í†µê³„ ì¶œë ¥
    print("\n" + "=" * 70)
    print("âœ… Merge complete!")
    print("=" * 70)

    total_train = sum(stats['train'] for stats in dataset_stats.values())
    total_val = sum(stats['val'] for stats in dataset_stats.values())
    total_test = sum(stats['test'] for stats in dataset_stats.values())

    print(f"\nğŸ“Š Dataset Statistics:")
    for dataset_name, stats in dataset_stats.items():
        print(f"\n{dataset_name}:")
        print(f"  Train: {stats['train']}")
        print(f"  Val: {stats['val']}")
        print(f"  Test: {stats['test']}")
        print(f"  Total: {sum(stats.values())}")

    print(f"\nğŸ“ˆ Combined Total:")
    print(f"  Train: {total_train}")
    print(f"  Val: {total_val}")
    print(f"  Test: {total_test}")
    print(f"  Total: {total_train + total_val + total_test}")

    print(f"\nğŸ“ Output: {output_path}")
    print(f"ğŸ“ Config: {yaml_path}")

def main():
    parser = argparse.ArgumentParser(
        description='Merge multiple YOLO datasets'
    )

    parser.add_argument('--datasets', nargs='+', required=True,
                        help='List of dataset directories to merge')
    parser.add_argument('--output', type=str, default='datasets/merged',
                        help='Output directory')
    parser.add_argument('--weights', nargs='+', type=float,
                        help='Sampling weights for each dataset')

    args = parser.parse_args()

    merge_datasets(
        dataset_paths=args.datasets,
        output_dir=args.output,
        weights=args.weights
    )

if __name__ == '__main__':
    main()
