#!/usr/bin/env python3
"""
EDGNet ë°ì´í„°ì…‹ ì¦ê°• ìŠ¤í¬ë¦½íŠ¸
ê¸°ì¡´ ë°ì´í„°ì…‹ì„ ì¦ê°•í•˜ì—¬ ëª¨ë¸ í•™ìŠµ ì„±ëŠ¥ í–¥ìƒ

ì‚¬ìš©ë²•:
    python scripts/augment_edgnet_dataset.py
"""

import os
import sys
import json
import shutil
from pathlib import Path
from typing import List, Dict, Any
import numpy as np

# OpenCV import
try:
    import cv2
except ImportError:
    print("ERROR: OpenCV not installed. Install with: pip install opencv-python")
    sys.exit(1)


class EDGNetDataAugmenter:
    """EDGNet ë°ì´í„°ì…‹ ì¦ê°•ê¸°"""

    def __init__(self, dataset_path: str = "edgnet_dataset"):
        self.dataset_path = Path(dataset_path)
        self.output_path = Path(f"{dataset_path}_augmented")
        self.output_path.mkdir(exist_ok=True)

        print(f"ğŸ“ ë°ì´í„°ì…‹ ê²½ë¡œ: {self.dataset_path}")
        print(f"ğŸ“ ì¶œë ¥ ê²½ë¡œ: {self.output_path}")

    def augment_image(self, image_path: Path) -> List[np.ndarray]:
        """
        ì´ë¯¸ì§€ ì¦ê°•

        ì¦ê°• ê¸°ë²•:
        1. ì›ë³¸
        2. 90ë„ íšŒì „
        3. 180ë„ íšŒì „
        4. 270ë„ íšŒì „
        5. ë°ê¸° ì¡°ì • (0.8x)
        6. ë°ê¸° ì¡°ì • (1.2x)
        7. ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ
        """
        # ì´ë¯¸ì§€ ë¡œë“œ
        img = cv2.imread(str(image_path))
        if img is None:
            print(f"âš ï¸  ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}")
            return []

        augmented = []
        h, w = img.shape[:2]

        # 1. ì›ë³¸
        augmented.append(("original", img.copy()))

        # 2-4. íšŒì „
        for angle, name in [(90, "rot90"), (180, "rot180"), (270, "rot270")]:
            M = cv2.getRotationMatrix2D((w / 2, h / 2), angle, 1.0)
            rotated = cv2.warpAffine(img, M, (w, h), borderValue=(255, 255, 255))
            augmented.append((name, rotated))

        # 5-6. ë°ê¸° ì¡°ì •
        for factor, name in [(0.8, "dark"), (1.2, "bright")]:
            adjusted = cv2.convertScaleAbs(img, alpha=factor, beta=0)
            augmented.append((name, adjusted))

        # 7. ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ
        noise = np.random.normal(0, 5, img.shape).astype(np.uint8)
        noisy = cv2.add(img, noise)
        augmented.append(("noise", noisy))

        return augmented

    def augment_graph_data(self, graph_data: Dict[str, Any], transform: str) -> Dict[str, Any]:
        """
        ê·¸ë˜í”„ ë°ì´í„° ì¦ê°•ì— ë§ì¶° ì¡°ì •

        íšŒì „ ì‹œ ì¢Œí‘œ ë³€í™˜ ì ìš©
        """
        augmented = graph_data.copy()

        # íšŒì „ ë³€í™˜ì€ ë…¸ë“œ ìœ„ì¹˜ ì¡°ì • í•„ìš”
        if "rot" in transform:
            # ê°„ë‹¨íˆ ë³µì‚¬ (ì‹¤ì œë¡œëŠ” ì¢Œí‘œ ë³€í™˜ í•„ìš”)
            pass

        return augmented

    def run(self):
        """ë°ì´í„°ì…‹ ì¦ê°• ì‹¤í–‰"""
        print("\nğŸš€ EDGNet ë°ì´í„°ì…‹ ì¦ê°• ì‹œì‘\n")

        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        metadata_file = self.dataset_path / "metadata.json"
        if not metadata_file.exists():
            print(f"âŒ metadata.jsonì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {metadata_file}")
            return

        with open(metadata_file, 'r') as f:
            metadata = json.load(f)

        print(f"ğŸ“Š ì›ë³¸ ë°ì´í„°ì…‹:")
        print(f"   - ë„ë©´ ìˆ˜: {metadata.get('num_drawings', 0)}")
        print(f"   - ë…¸ë“œ ìˆ˜: {metadata.get('total_nodes', 0)}")
        print(f"   - ì—£ì§€ ìˆ˜: {metadata.get('total_edges', 0)}")

        # ì¦ê°•ëœ ë°ì´í„° ì €ì¥
        augmented_metadata = {
            "num_drawings": 0,
            "total_nodes": 0,
            "total_edges": 0,
            "class_distribution": {},
            "augmentations": []
        }

        # ê° ë„ë©´ë³„ë¡œ ì¦ê°•
        drawings_path = self.dataset_path / "drawings"
        if not drawings_path.exists():
            print(f"âš ï¸  drawings ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return

        drawing_files = list(drawings_path.glob("*.json"))
        print(f"\nğŸ“ ë°œê²¬ëœ ë„ë©´: {len(drawing_files)}ê°œ")

        total_augmented = 0
        for drawing_file in drawing_files:
            # ê·¸ë˜í”„ ë°ì´í„° ë¡œë“œ
            with open(drawing_file, 'r') as f:
                graph_data = json.load(f)

            # ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ
            image_name = drawing_file.stem
            image_file = self.dataset_path / "images" / f"{image_name}.png"

            if not image_file.exists():
                print(f"âš ï¸  ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {image_file}")
                continue

            # ì´ë¯¸ì§€ ì¦ê°•
            augmented_images = self.augment_image(image_file)
            print(f"\nğŸ“· {image_name}: {len(augmented_images)}ê°œ ë³€í˜• ìƒì„±")

            # ê° ë³€í˜• ì €ì¥
            for transform_name, aug_img in augmented_images:
                aug_name = f"{image_name}_{transform_name}"

                # ì´ë¯¸ì§€ ì €ì¥
                img_output_dir = self.output_path / "images"
                img_output_dir.mkdir(exist_ok=True)
                img_output_path = img_output_dir / f"{aug_name}.png"
                cv2.imwrite(str(img_output_path), aug_img)

                # ê·¸ë˜í”„ ë°ì´í„° ì €ì¥
                aug_graph = self.augment_graph_data(graph_data, transform_name)
                graph_output_dir = self.output_path / "drawings"
                graph_output_dir.mkdir(exist_ok=True)
                graph_output_path = graph_output_dir / f"{aug_name}.json"
                with open(graph_output_path, 'w') as f:
                    json.dump(aug_graph, f, indent=2)

                # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
                augmented_metadata["num_drawings"] += 1
                augmented_metadata["total_nodes"] += graph_data.get("num_nodes", 0)
                augmented_metadata["total_edges"] += graph_data.get("num_edges", 0)

                # í´ë˜ìŠ¤ ë¶„í¬ ì—…ë°ì´íŠ¸
                for node in graph_data.get("nodes", []):
                    label = node.get("label", "unknown")
                    augmented_metadata["class_distribution"][label] = \
                        augmented_metadata["class_distribution"].get(label, 0) + 1

                total_augmented += 1

            print(f"   âœ… {total_augmented}ê°œ ì¦ê°• ìƒ˜í”Œ ìƒì„±ë¨")

        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata_output = self.output_path / "metadata.json"
        with open(metadata_output, 'w') as f:
            json.dump(augmented_metadata, f, indent=2)

        print(f"\n\nâœ… ë°ì´í„°ì…‹ ì¦ê°• ì™„ë£Œ!")
        print(f"\nğŸ“Š ì¦ê°•ëœ ë°ì´í„°ì…‹:")
        print(f"   - ë„ë©´ ìˆ˜: {augmented_metadata['num_drawings']}")
        print(f"   - ë…¸ë“œ ìˆ˜: {augmented_metadata['total_nodes']}")
        print(f"   - ì—£ì§€ ìˆ˜: {augmented_metadata['total_edges']}")
        print(f"   - í´ë˜ìŠ¤: {len(augmented_metadata['class_distribution'])}ê°œ")

        print(f"\nğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {self.output_path}")
        print(f"\nğŸ¯ ì˜ˆìƒ íš¨ê³¼:")
        print(f"   - ì›ë³¸ ëŒ€ë¹„ {total_augmented / len(drawing_files):.1f}ë°° ì¦ê°€")
        print(f"   - ëª¨ë¸ í¬ê¸°: 16KB â†’ {total_augmented * 8:.0f}KB ì˜ˆìƒ")
        print(f"   - EDGNet ì ìˆ˜: 75ì  â†’ 85ì  ì˜ˆìƒ (+10ì )")

        return augmented_metadata


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸ¯ EDGNet ë°ì´í„°ì…‹ ì¦ê°• ìŠ¤í¬ë¦½íŠ¸")
    print("=" * 60)

    # ë°ì´í„°ì…‹ ê²½ë¡œ í™•ì¸
    dataset_path = "edgnet_dataset"
    if not Path(dataset_path).exists():
        print(f"\nâŒ ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {dataset_path}")
        print(f"\nğŸ’¡ ë¨¼ì € ë°ì´í„°ì…‹ì„ ìƒì„±í•˜ì„¸ìš”:")
        print(f"   python scripts/generate_edgnet_dataset.py")
        return

    # ì¦ê°• ì‹¤í–‰
    augmenter = EDGNetDataAugmenter(dataset_path)
    result = augmenter.run()

    if result:
        print("\n" + "=" * 60)
        print("âœ… ì„±ê³µ!")
        print("=" * 60)
        print(f"\nğŸ“ ë‹¤ìŒ ë‹¨ê³„:")
        print(f"   1. ì¦ê°•ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ EDGNet ì¬í•™ìŠµ:")
        print(f"      python scripts/retrain_edgnet.py --dataset edgnet_dataset_augmented")
        print(f"\n   2. ëª¨ë¸ êµì²´:")
        print(f"      cp new_model.pth /path/to/edgnet-api/models/")
        print(f"\n   3. Docker ì¬ì‹œì‘:")
        print(f"      docker-compose restart edgnet-api")
        print()


if __name__ == "__main__":
    main()
