# Docker GPU ìë™ ê°ì§€ ìŠ¤í¬ë¦½íŠ¸

ì»¨í…Œì´ë„ˆ ì‹œì‘ ì‹œ GPU ê°€ìš©ì„±ì„ ìë™ìœ¼ë¡œ ì²´í¬í•˜ê³  í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.

## ì‚¬ìš©ë²•

### 1. Dockerfileì— ìŠ¤í¬ë¦½íŠ¸ ë³µì‚¬

```dockerfile
# ìŠ¤í¬ë¦½íŠ¸ ë³µì‚¬ (ë¹Œë“œ ì»¨í…ìŠ¤íŠ¸ì— docker-gpu-entrypoint.sh í•„ìš”)
COPY docker-gpu-entrypoint.sh /usr/local/bin/docker-gpu-entrypoint.sh
RUN chmod +x /usr/local/bin/docker-gpu-entrypoint.sh

# í™˜ê²½ë³€ìˆ˜ ê¸°ë³¸ê°’ ì„¤ì •
ENV USE_GPU=auto

# ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ ì„¤ì • (í´ë°± í¬í•¨)
ENTRYPOINT ["/bin/bash", "-c", "if [ -x /usr/local/bin/docker-gpu-entrypoint.sh ]; then exec /usr/local/bin/docker-gpu-entrypoint.sh \"$@\"; else exec \"$@\"; fi", "--"]
CMD ["python", "api_server.py"]
```

### 2. ì„œë¹„ìŠ¤ ë””ë ‰í† ë¦¬ì— ìŠ¤í¬ë¦½íŠ¸ ë³µì‚¬

```bash
cp scripts/docker-gpu-entrypoint.sh models/my-api/docker-gpu-entrypoint.sh
```

### 3. docker-compose.yml í™˜ê²½ë³€ìˆ˜ ì„¤ì •

```yaml
services:
  my-api:
    environment:
      - USE_GPU=auto  # auto|true|false
```

## í™˜ê²½ë³€ìˆ˜

### ì…ë ¥

| ë³€ìˆ˜ | ê°’ | ì„¤ëª… |
|------|-----|------|
| `USE_GPU` | `auto` | (ê¸°ë³¸ê°’) GPU ê°ì§€ ì‹œ ì‚¬ìš©, ì—†ìœ¼ë©´ CPU |
| `USE_GPU` | `true` | GPU ê°•ì œ ì‚¬ìš© (ì—†ìœ¼ë©´ ê²½ê³  í›„ CPU) |
| `USE_GPU` | `false` | CPU ê°•ì œ ì‚¬ìš© (GPU ë¬´ì‹œ) |

### ì¶œë ¥ (ìŠ¤í¬ë¦½íŠ¸ê°€ ì„¤ì •)

| ë³€ìˆ˜ | ê°’ | ì„¤ëª… |
|------|-----|------|
| `GPU_AVAILABLE` | `true`/`false` | GPU ê°ì§€ ì—¬ë¶€ |
| `GPU_COUNT` | ìˆ«ì | ì‚¬ìš© ê°€ëŠ¥í•œ GPU ìˆ˜ |
| `GPU_NAME` | ë¬¸ìì—´ | GPU ëª¨ë¸ëª… |
| `CUDA_VISIBLE_DEVICES` | (ë¹ˆ ë¬¸ìì—´) | `USE_GPU=false`ì¸ ê²½ìš° ì„¤ì • |

## ì ìš©ëœ ì„œë¹„ìŠ¤

| ì„œë¹„ìŠ¤ | ìƒíƒœ |
|--------|------|
| `yolo-api` | âœ… ì ìš©ë¨ |
| `edocr2-v2-api` | â³ ë¯¸ì ìš© |
| `paddleocr-api` | â³ ë¯¸ì ìš© (ê¸°ì¡´ USE_GPU ì‚¬ìš©) |
| `trocr-api` | â³ ë¯¸ì ìš© |
| `esrgan-api` | â³ ë¯¸ì ìš© |

## ì‹œì‘ ë¡œê·¸ ì˜ˆì‹œ

```
ğŸš€ GPU Mode: Auto-detected (1x NVIDIA GeForce RTX 3090)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”§ GPU Detection Summary
   GPU_AVAILABLE: true
   GPU_COUNT: 1
   GPU_NAME: NVIDIA GeForce RTX 3090
   USE_GPU: auto
   CUDA_VISIBLE_DEVICES: all
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

## GPU ê°ì§€ ë°©ë²• (ìš°ì„ ìˆœìœ„)

1. `nvidia-smi` ëª…ë ¹ì–´ ì‹¤í–‰
2. `/dev/nvidia*` ë””ë°”ì´ìŠ¤ íŒŒì¼ ì²´í¬
3. PyTorch `torch.cuda.is_available()` í˜¸ì¶œ
