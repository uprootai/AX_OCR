#!/usr/bin/env python3
"""
Skin Model XGBoost ì—…ê·¸ë ˆì´ë“œ ìŠ¤í¬ë¦½íŠ¸

ê¸°ì¡´ RandomForest ëª¨ë¸ì„ XGBoostë¡œ ì—…ê·¸ë ˆì´ë“œí•˜ì—¬ ì •í™•ë„ í–¥ìƒ
- ê¸°ì¡´ í•™ìŠµ ë°ì´í„° ì‚¬ìš©
- GPU ê°€ì† í•™ìŠµ
- ëª¨ë¸ ë¹„êµ ë° ì„±ëŠ¥ í‰ê°€
"""

import sys
import json
import time
import logging
from pathlib import Path
from typing import List, Dict, Tuple
import numpy as np
import pandas as pd

# Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# XGBoost import
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False
    logger.error("âŒ XGBoost not installed. Install with: pip install xgboost")

# joblib for model loading/saving
import joblib
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error


# í•©ì„± ë°ì´í„° ìƒì„± (ê¸°ì¡´ê³¼ ë™ì¼)
def generate_synthetic_data(n_samples: int = 5000) -> pd.DataFrame:
    """í•©ì„± í•™ìŠµ ë°ì´í„° ìƒì„±"""
    np.random.seed(42)

    data = []

    for _ in range(n_samples):
        # íŠ¹ì§• ìƒì„±
        diameter = np.random.uniform(10, 200)  # mm
        length = np.random.uniform(20, 500)
        thickness = np.random.uniform(1, 50)
        material_hardness = np.random.choice([50, 100, 200, 275])  # Al, Brass, Steel, Ti
        material_youngs = np.random.choice([70, 100, 200, 110])
        process_encoded = np.random.choice([0, 1, 2, 3])  # machining, casting, forging, sheet_metal

        # íŠ¹ì§• ë²¡í„°
        features = {
            'diameter': diameter,
            'length': length,
            'thickness': thickness,
            'material_hardness': material_hardness,
            'material_youngs_modulus': material_youngs,
            'process_encoded': process_encoded
        }

        # ëª©í‘œ ë³€ìˆ˜ ìƒì„± (ë¬¼ë¦¬ ê¸°ë°˜ íœ´ë¦¬ìŠ¤í‹±)
        # Flatness
        thickness_factor = 0.001 * (thickness ** 0.5)
        process_factor = 1.0 + 0.1 * process_encoded
        flatness = thickness_factor * process_factor * np.random.uniform(0.8, 1.2)

        # Cylindricity
        diameter_factor = 0.002 * (diameter ** 0.5)
        material_factor = 200.0 / material_hardness
        cylindricity = diameter_factor * material_factor * np.random.uniform(0.8, 1.2)

        # Position
        length_factor = 0.005 * (length ** 0.3)
        position = length_factor * process_factor * np.random.uniform(0.8, 1.2)

        features['flatness'] = max(0.001, flatness)
        features['cylindricity'] = max(0.001, cylindricity)
        features['position'] = max(0.001, position)

        data.append(features)

    return pd.DataFrame(data)


def load_existing_data(models_dir: Path) -> Tuple[pd.DataFrame, bool]:
    """ê¸°ì¡´ ëª¨ë¸ì—ì„œ í•™ìŠµ ë°ì´í„° ì¶”ì¶œ ì‹œë„"""
    try:
        # ë©”íƒ€ë°ì´í„° í™•ì¸
        metadata_path = models_dir / "model_metadata.json"
        if metadata_path.exists():
            with open(metadata_path, 'r') as f:
                metadata = json.load(f)

            training_samples = metadata.get('training_samples', 0)
            logger.info(f"ê¸°ì¡´ ë©”íƒ€ë°ì´í„°: {training_samples} ìƒ˜í”Œ")

        # ê¸°ì¡´ ëª¨ë¸ì´ ìˆìœ¼ë©´ ë°ì´í„°ë¥¼ ì¬ìƒì„±í•  í•„ìš” ì—†ìŒ
        # í•©ì„± ë°ì´í„° ìƒì„± (ê¸°ì¡´ê³¼ ë™ì¼í•œ ë¶„í¬)
        logger.info("í•©ì„± ë°ì´í„° ìƒì„± (ê¸°ì¡´ ë¶„í¬ ìœ ì§€)")
        df = generate_synthetic_data(n_samples=5000)
        return df, True

    except Exception as e:
        logger.warning(f"ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, False


def train_xgboost_models(
    X: np.ndarray,
    y_flatness: np.ndarray,
    y_cylindricity: np.ndarray,
    y_position: np.ndarray,
    use_gpu: bool = True
) -> Tuple[xgb.XGBRegressor, xgb.XGBRegressor, xgb.XGBRegressor, Dict]:
    """XGBoost ëª¨ë¸ í•™ìŠµ"""

    # Device ì„¤ì •
    # XGBoost GPU ì§€ì› í™•ì¸
    device = "cpu"
    tree_method = "hist"

    if use_gpu:
        # XGBoost GPU ì§€ì›ì€ CUDA ë¹Œë“œê°€ í•„ìš”
        # ì¼ë°˜ pip install xgboostëŠ” CPUë§Œ ì§€ì›
        logger.info("âš¡ XGBoost í•™ìŠµ ëª¨ë“œ (tree_method=hist)")
        logger.info("   Note: GPU acceleration requires CUDA-enabled XGBoost build")
    else:
        logger.info("ğŸ’» XGBoost CPU í•™ìŠµ ëª¨ë“œ")

    # XGBoost í•˜ì´í¼íŒŒë¼ë¯¸í„°
    params = {
        'n_estimators': 200,
        'max_depth': 6,
        'learning_rate': 0.1,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'tree_method': tree_method,
        'random_state': 42,
        'n_jobs': -1
    }

    logger.info(f"XGBoost íŒŒë¼ë¯¸í„°: {params}")

    # Train/val split
    X_train, X_val, y_flat_train, y_flat_val = train_test_split(
        X, y_flatness, test_size=0.2, random_state=42
    )
    _, _, y_cyl_train, y_cyl_val = train_test_split(
        X, y_cylindricity, test_size=0.2, random_state=42
    )
    _, _, y_pos_train, y_pos_val = train_test_split(
        X, y_position, test_size=0.2, random_state=42
    )

    logger.info(f"í•™ìŠµ ë°ì´í„°: {len(X_train)}, ê²€ì¦ ë°ì´í„°: {len(X_val)}")

    results = {}
    start_time = time.time()

    # 1. Flatness ëª¨ë¸
    logger.info("ğŸ“¦ Flatness ëª¨ë¸ í•™ìŠµ...")
    flatness_model = xgb.XGBRegressor(**params)
    flatness_model.fit(X_train, y_flat_train, eval_set=[(X_val, y_flat_val)], verbose=False)

    y_flat_pred = flatness_model.predict(X_val)
    flat_r2 = r2_score(y_flat_val, y_flat_pred)
    flat_mae = mean_absolute_error(y_flat_val, y_flat_pred)
    flat_rmse = np.sqrt(mean_squared_error(y_flat_val, y_flat_pred))

    results['flatness'] = {'r2': flat_r2, 'mae': flat_mae, 'rmse': flat_rmse}
    logger.info(f"  Flatness - RÂ²={flat_r2:.4f}, MAE={flat_mae:.6f}, RMSE={flat_rmse:.6f}")

    # 2. Cylindricity ëª¨ë¸
    logger.info("ğŸ“¦ Cylindricity ëª¨ë¸ í•™ìŠµ...")
    cylindricity_model = xgb.XGBRegressor(**params)
    cylindricity_model.fit(X_train, y_cyl_train, eval_set=[(X_val, y_cyl_val)], verbose=False)

    y_cyl_pred = cylindricity_model.predict(X_val)
    cyl_r2 = r2_score(y_cyl_val, y_cyl_pred)
    cyl_mae = mean_absolute_error(y_cyl_val, y_cyl_pred)
    cyl_rmse = np.sqrt(mean_squared_error(y_cyl_val, y_cyl_pred))

    results['cylindricity'] = {'r2': cyl_r2, 'mae': cyl_mae, 'rmse': cyl_rmse}
    logger.info(f"  Cylindricity - RÂ²={cyl_r2:.4f}, MAE={cyl_mae:.6f}, RMSE={cyl_rmse:.6f}")

    # 3. Position ëª¨ë¸
    logger.info("ğŸ“¦ Position ëª¨ë¸ í•™ìŠµ...")
    position_model = xgb.XGBRegressor(**params)
    position_model.fit(X_train, y_pos_train, eval_set=[(X_val, y_pos_val)], verbose=False)

    y_pos_pred = position_model.predict(X_val)
    pos_r2 = r2_score(y_pos_val, y_pos_pred)
    pos_mae = mean_absolute_error(y_pos_val, y_pos_pred)
    pos_rmse = np.sqrt(mean_squared_error(y_pos_val, y_pos_pred))

    results['position'] = {'r2': pos_r2, 'mae': pos_mae, 'rmse': pos_rmse}
    logger.info(f"  Position - RÂ²={pos_r2:.4f}, MAE={pos_mae:.6f}, RMSE={pos_rmse:.6f}")

    training_time = time.time() - start_time
    results['training_time'] = training_time
    results['device'] = device
    results['tree_method'] = tree_method

    logger.info(f"âœ… í•™ìŠµ ì™„ë£Œ: {training_time:.2f}ì´ˆ")

    return flatness_model, cylindricity_model, position_model, results


def compare_models(models_dir: Path, results: Dict):
    """ê¸°ì¡´ RandomForest vs ìƒˆë¡œìš´ XGBoost ë¹„êµ"""
    logger.info("\n" + "="*60)
    logger.info("ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
    logger.info("="*60)

    # ê¸°ì¡´ ëª¨ë¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ
    metadata_path = models_dir / "model_metadata.json"
    if metadata_path.exists():
        with open(metadata_path, 'r') as f:
            old_metadata = json.load(f)

        logger.info("\n[ê¸°ì¡´ RandomForest ëª¨ë¸]")
        logger.info(f"  Model: {old_metadata.get('model_type', 'RandomForest')}")
        logger.info(f"  Training samples: {old_metadata.get('training_samples', 'N/A')}")

        flat_r2 = old_metadata.get('flatness_r2')
        cyl_r2 = old_metadata.get('cylindricity_r2')
        pos_r2 = old_metadata.get('position_r2')

        if flat_r2 and isinstance(flat_r2, (int, float)):
            logger.info(f"  Flatness RÂ²: {flat_r2:.4f}")
        else:
            logger.info(f"  Flatness RÂ²: N/A")

        if cyl_r2 and isinstance(cyl_r2, (int, float)):
            logger.info(f"  Cylindricity RÂ²: {cyl_r2:.4f}")
        else:
            logger.info(f"  Cylindricity RÂ²: N/A")

        if pos_r2 and isinstance(pos_r2, (int, float)):
            logger.info(f"  Position RÂ²: {pos_r2:.4f}")
        else:
            logger.info(f"  Position RÂ²: N/A")
    else:
        logger.info("\n[ê¸°ì¡´ ëª¨ë¸ ë©”íƒ€ë°ì´í„° ì—†ìŒ]")

    logger.info("\n[ìƒˆë¡œìš´ XGBoost ëª¨ë¸]")
    logger.info(f"  Device: {results.get('device', 'N/A')}")
    logger.info(f"  Tree method: {results.get('tree_method', 'N/A')}")
    logger.info(f"  Training time: {results.get('training_time', 0):.2f}ì´ˆ")
    logger.info(f"  Flatness RÂ²: {results['flatness']['r2']:.4f}")
    logger.info(f"  Cylindricity RÂ²: {results['cylindricity']['r2']:.4f}")
    logger.info(f"  Position RÂ²: {results['position']['r2']:.4f}")

    logger.info("\n" + "="*60)


def save_models(
    flatness_model: xgb.XGBRegressor,
    cylindricity_model: xgb.XGBRegressor,
    position_model: xgb.XGBRegressor,
    process_encoder,
    results: Dict,
    output_dir: Path
):
    """ëª¨ë¸ ì €ì¥"""
    output_dir.mkdir(parents=True, exist_ok=True)

    # ëª¨ë¸ ì €ì¥
    joblib.dump(flatness_model, output_dir / "flatness_predictor_xgboost.pkl")
    joblib.dump(cylindricity_model, output_dir / "cylindricity_predictor_xgboost.pkl")
    joblib.dump(position_model, output_dir / "position_predictor_xgboost.pkl")
    joblib.dump(process_encoder, output_dir / "process_encoder.pkl")

    logger.info(f"ğŸ’¾ ëª¨ë¸ ì €ì¥: {output_dir}")

    # ë©”íƒ€ë°ì´í„°
    metadata = {
        'model_type': 'XGBoost',
        'xgboost_version': xgb.__version__,
        'device': results.get('device', 'cpu'),
        'tree_method': results.get('tree_method', 'hist'),
        'training_time': results.get('training_time', 0),
        'training_samples': 5000,
        'flatness_r2': results['flatness']['r2'],
        'flatness_mae': results['flatness']['mae'],
        'flatness_rmse': results['flatness']['rmse'],
        'cylindricity_r2': results['cylindricity']['r2'],
        'cylindricity_mae': results['cylindricity']['mae'],
        'cylindricity_rmse': results['cylindricity']['rmse'],
        'position_r2': results['position']['r2'],
        'position_mae': results['position']['mae'],
        'position_rmse': results['position']['rmse'],
    }

    with open(output_dir / "model_metadata_xgboost.json", 'w') as f:
        json.dump(metadata, f, indent=2)

    logger.info(f"ğŸ“„ ë©”íƒ€ë°ì´í„° ì €ì¥: {output_dir}/model_metadata_xgboost.json")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logger.info("="*60)
    logger.info("Skin Model XGBoost ì—…ê·¸ë ˆì´ë“œ")
    logger.info("="*60)

    if not XGBOOST_AVAILABLE:
        logger.error("âŒ XGBoost not available. Install with: pip install xgboost")
        return 1

    # ê²½ë¡œ ì„¤ì •
    models_dir = Path("/home/uproot/ax/poc/skinmodel-api/models")
    output_dir = models_dir  # ë™ì¼ ë””ë ‰í† ë¦¬ì— ì €ì¥

    # ë°ì´í„° ìƒì„±
    logger.info("\nğŸ“Š í•™ìŠµ ë°ì´í„° ìƒì„±...")
    df = generate_synthetic_data(n_samples=5000)

    logger.info(f"  ìƒ˜í”Œ ìˆ˜: {len(df)}")
    logger.info(f"  íŠ¹ì§• ìˆ˜: {df.shape[1] - 3}")  # 3ê°œ ëª©í‘œ ë³€ìˆ˜ ì œì™¸

    # íŠ¹ì§• ë° ëª©í‘œ ë³€ìˆ˜ ë¶„ë¦¬
    feature_cols = ['diameter', 'length', 'thickness', 'material_hardness',
                    'material_youngs_modulus', 'process_encoded']
    X = df[feature_cols].values
    y_flatness = df['flatness'].values
    y_cylindricity = df['cylindricity'].values
    y_position = df['position'].values

    # Process encoder (ê¸°ì¡´ê³¼ ë™ì¼)
    process_mapping = {
        'machining': 0,
        'casting': 1,
        'forging': 2,
        'sheet_metal': 3
    }

    # XGBoost ëª¨ë¸ í•™ìŠµ
    logger.info("\nğŸš€ XGBoost ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    flatness_model, cylindricity_model, position_model, results = train_xgboost_models(
        X, y_flatness, y_cylindricity, y_position, use_gpu=True
    )

    # ëª¨ë¸ ë¹„êµ
    compare_models(models_dir, results)

    # ëª¨ë¸ ì €ì¥
    save_models(
        flatness_model,
        cylindricity_model,
        position_model,
        process_mapping,
        results,
        output_dir
    )

    logger.info("\n" + "="*60)
    logger.info("âœ… XGBoost ì—…ê·¸ë ˆì´ë“œ ì™„ë£Œ!")
    logger.info("="*60)
    logger.info(f"í‰ê·  RÂ² ì ìˆ˜: {np.mean([results['flatness']['r2'], results['cylindricity']['r2'], results['position']['r2']]):.4f}")
    logger.info("")
    logger.info("ë‹¤ìŒ ë‹¨ê³„:")
    logger.info("1. ml_predictor.pyì—ì„œ XGBoost ëª¨ë¸ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •")
    logger.info("2. docker-compose restart skinmodel-api")
    logger.info("3. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")

    return 0


if __name__ == "__main__":
    sys.exit(main())
