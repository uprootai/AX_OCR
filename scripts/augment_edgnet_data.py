#!/usr/bin/env python3
"""
EDGNet ë°ì´í„° ì¦ê°• ìŠ¤í¬ë¦½íŠ¸
5ê°œ ì´ë¯¸ì§€ â†’ 50+ ì¦ê°• ì´ë¯¸ì§€ ìƒì„±
"""

import os
import cv2
import numpy as np
from pathlib import Path
import json
from tqdm import tqdm

# ì¦ê°• íŒŒë¼ë¯¸í„°
AUGMENTATIONS = {
    'rotation': [-15, -10, -5, 5, 10, 15],  # íšŒì „ ê°ë„
    'brightness': [0.7, 0.85, 1.15, 1.3],   # ë°ê¸° ì¡°ì •
    'contrast': [0.7, 0.85, 1.15, 1.3],     # ëŒ€ë¹„ ì¡°ì •
    'blur': [0, 1, 3],                       # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬
    'noise': [0, 5, 10],                     # ë…¸ì´ì¦ˆ ì¶”ê°€
}

def rotate_image(image, angle):
    """ì´ë¯¸ì§€ íšŒì „"""
    height, width = image.shape[:2]
    center = (width // 2, height // 2)
    matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
    rotated = cv2.warpAffine(image, matrix, (width, height),
                             borderMode=cv2.BORDER_CONSTANT,
                             borderValue=(255, 255, 255))
    return rotated

def adjust_brightness(image, factor):
    """ë°ê¸° ì¡°ì •"""
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    hsv = hsv.astype(np.float32)
    hsv[:, :, 2] = hsv[:, :, 2] * factor
    hsv[:, :, 2] = np.clip(hsv[:, :, 2], 0, 255)
    hsv = hsv.astype(np.uint8)
    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)

def adjust_contrast(image, factor):
    """ëŒ€ë¹„ ì¡°ì •"""
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB).astype(np.float32)
    lab[:, :, 0] = lab[:, :, 0] * factor
    lab[:, :, 0] = np.clip(lab[:, :, 0], 0, 255)
    lab = lab.astype(np.uint8)
    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)

def add_gaussian_blur(image, kernel_size):
    """ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì¶”ê°€"""
    if kernel_size == 0:
        return image
    kernel = (kernel_size * 2 + 1, kernel_size * 2 + 1)
    return cv2.GaussianBlur(image, kernel, 0)

def add_noise(image, noise_level):
    """ë…¸ì´ì¦ˆ ì¶”ê°€"""
    if noise_level == 0:
        return image
    noise = np.random.normal(0, noise_level, image.shape).astype(np.uint8)
    noisy = cv2.add(image, noise)
    return noisy

def horizontal_flip(image):
    """ì¢Œìš° ë°˜ì „"""
    return cv2.flip(image, 1)

def vertical_flip(image):
    """ìƒí•˜ ë°˜ì „"""
    return cv2.flip(image, 0)

def augment_image(image, aug_params):
    """ë‹¨ì¼ ì¦ê°• ì ìš©"""
    augmented = image.copy()

    # íšŒì „
    if 'rotation' in aug_params:
        augmented = rotate_image(augmented, aug_params['rotation'])

    # ë°ê¸°
    if 'brightness' in aug_params:
        augmented = adjust_brightness(augmented, aug_params['brightness'])

    # ëŒ€ë¹„
    if 'contrast' in aug_params:
        augmented = adjust_contrast(augmented, aug_params['contrast'])

    # ë¸”ëŸ¬
    if 'blur' in aug_params:
        augmented = add_gaussian_blur(augmented, aug_params['blur'])

    # ë…¸ì´ì¦ˆ
    if 'noise' in aug_params:
        augmented = add_noise(augmented, aug_params['noise'])

    # í”Œë¦½
    if aug_params.get('h_flip', False):
        augmented = horizontal_flip(augmented)

    if aug_params.get('v_flip', False):
        augmented = vertical_flip(augmented)

    return augmented

def generate_augmentation_params():
    """ì¦ê°• íŒŒë¼ë¯¸í„° ì¡°í•© ìƒì„±"""
    params_list = []

    # 1. íšŒì „ë§Œ
    for angle in AUGMENTATIONS['rotation']:
        params_list.append({'rotation': angle})

    # 2. ë°ê¸°ë§Œ
    for brightness in AUGMENTATIONS['brightness']:
        params_list.append({'brightness': brightness})

    # 3. ëŒ€ë¹„ë§Œ
    for contrast in AUGMENTATIONS['contrast']:
        params_list.append({'contrast': contrast})

    # 4. íšŒì „ + ë°ê¸°
    for angle in AUGMENTATIONS['rotation'][:3]:  # 3ê°œë§Œ
        for brightness in AUGMENTATIONS['brightness'][:2]:  # 2ê°œë§Œ
            params_list.append({
                'rotation': angle,
                'brightness': brightness
            })

    # 5. ì¢Œìš° ë°˜ì „
    params_list.append({'h_flip': True})

    # 6. ì¢Œìš° ë°˜ì „ + ë°ê¸°
    for brightness in AUGMENTATIONS['brightness'][:2]:
        params_list.append({
            'h_flip': True,
            'brightness': brightness
        })

    return params_list

def augment_dataset(source_dir, output_dir, target_count=50):
    """ë°ì´í„°ì…‹ ì¦ê°•"""
    source_path = Path(source_dir)
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']
    image_files = []
    for ext in image_extensions:
        image_files.extend(list(source_path.glob(f'*{ext}')))
        image_files.extend(list(source_path.glob(f'*{ext.upper()}')))

    if not image_files:
        print(f"âŒ No images found in {source_dir}")
        return

    print(f"ğŸ“Š Found {len(image_files)} original images")
    print(f"ğŸ¯ Target: {target_count} augmented images per original")

    # ì¦ê°• íŒŒë¼ë¯¸í„° ìƒì„±
    aug_params_list = generate_augmentation_params()
    print(f"ğŸ”§ Generated {len(aug_params_list)} augmentation combinations")

    total_generated = 0
    metadata = {'augmentations': [], 'statistics': {}}

    # ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ì¦ê°• ìˆ˜í–‰
    for img_file in tqdm(image_files, desc="Augmenting images"):
        # ì›ë³¸ ì´ë¯¸ì§€ ì½ê¸°
        image = cv2.imread(str(img_file))
        if image is None:
            print(f"âš ï¸  Failed to load {img_file}")
            continue

        # ì›ë³¸ ë³µì‚¬
        output_name = output_path / img_file.name
        cv2.imwrite(str(output_name), image)
        metadata['augmentations'].append({
            'original': img_file.name,
            'augmented': img_file.name,
            'params': 'original'
        })
        total_generated += 1

        # ì¦ê°• ì ìš©
        for idx, aug_params in enumerate(aug_params_list[:target_count-1]):
            augmented = augment_image(image, aug_params)

            # íŒŒì¼ëª… ìƒì„±
            stem = img_file.stem
            ext = img_file.suffix
            aug_name = f"{stem}_aug_{idx:03d}{ext}"
            aug_path = output_path / aug_name

            # ì €ì¥
            cv2.imwrite(str(aug_path), augmented)

            metadata['augmentations'].append({
                'original': img_file.name,
                'augmented': aug_name,
                'params': aug_params
            })
            total_generated += 1

    # ë©”íƒ€ë°ì´í„° ì €ì¥
    metadata['statistics'] = {
        'original_count': len(image_files),
        'augmented_count': total_generated,
        'augmentation_factor': total_generated / len(image_files) if image_files else 0
    }

    metadata_path = output_path / 'augmentation_metadata.json'
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)

    print(f"\nâœ… Augmentation complete!")
    print(f"   Original images: {len(image_files)}")
    print(f"   Augmented images: {total_generated}")
    print(f"   Augmentation factor: {total_generated / len(image_files):.1f}x")
    print(f"   Output directory: {output_dir}")
    print(f"   Metadata saved: {metadata_path}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description='EDGNet ë°ì´í„° ì¦ê°•')
    parser.add_argument('--source', type=str,
                       default='/home/uproot/ax/poc/edgnet_dataset',
                       help='Source dataset directory')
    parser.add_argument('--output', type=str,
                       default='/home/uproot/ax/poc/edgnet_dataset_large',
                       help='Output directory for augmented dataset')
    parser.add_argument('--target', type=int, default=50,
                       help='Target number of images per original (default: 50)')

    args = parser.parse_args()

    print("=" * 60)
    print("ğŸ¨ EDGNet ë°ì´í„° ì¦ê°• ì‹œì‘")
    print("=" * 60)
    print(f"Source: {args.source}")
    print(f"Output: {args.output}")
    print(f"Target: {args.target} images per original")
    print("=" * 60)

    augment_dataset(args.source, args.output, args.target)

    print("\n" + "=" * 60)
    print("ğŸ‰ ë°ì´í„° ì¦ê°• ì™„ë£Œ!")
    print("=" * 60)

if __name__ == '__main__':
    main()
