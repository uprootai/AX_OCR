#!/usr/bin/env python3
"""
í•™ìŠµ ê´€ë¦¬ ëª¨ë“ˆ
ì›¹ UIì—ì„œ ëŒ€ê·œëª¨ í•™ìŠµì„ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ê´€ë¦¬
"""

import os
import json
import time
import subprocess
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional
import threading
import logging

logger = logging.getLogger(__name__)

# í•™ìŠµ ì‘ì—… ìƒíƒœ ì €ì¥
training_jobs: Dict[str, Dict[str, Any]] = {}
training_lock = threading.Lock()


class TrainingJob:
    """í•™ìŠµ ì‘ì—… í´ë˜ìŠ¤"""

    def __init__(self, job_id: str, model_type: str, config: Dict[str, Any]):
        self.job_id = job_id
        self.model_type = model_type
        self.config = config
        self.status = "pending"
        self.progress = 0.0
        self.current_epoch = 0
        self.total_epochs = config.get('epochs', 100)
        self.logs = []
        self.started_at = None
        self.completed_at = None
        self.error = None

    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "job_id": self.job_id,
            "model_type": self.model_type,
            "config": self.config,
            "status": self.status,
            "progress": self.progress,
            "current_epoch": self.current_epoch,
            "total_epochs": self.total_epochs,
            "logs": self.logs[-50:],  # ìµœê·¼ 50ì¤„ë§Œ
            "started_at": self.started_at,
            "completed_at": self.completed_at,
            "error": self.error
        }


def create_training_job(model_type: str, config: Dict[str, Any]) -> str:
    """í•™ìŠµ ì‘ì—… ìƒì„±"""
    job_id = f"{model_type}_{int(time.time())}"

    with training_lock:
        job = TrainingJob(job_id, model_type, config)
        training_jobs[job_id] = job

    # ë°±ê·¸ë¼ìš´ë“œë¡œ í•™ìŠµ ì‹œì‘
    thread = threading.Thread(target=run_training, args=(job_id,))
    thread.daemon = True
    thread.start()

    return job_id


def get_training_job(job_id: str) -> Optional[Dict[str, Any]]:
    """í•™ìŠµ ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
    with training_lock:
        job = training_jobs.get(job_id)
        return job.to_dict() if job else None


def list_training_jobs() -> list:
    """ëª¨ë“  í•™ìŠµ ì‘ì—… ëª©ë¡"""
    with training_lock:
        return [job.to_dict() for job in training_jobs.values()]


def run_training(job_id: str):
    """í•™ìŠµ ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ)"""
    with training_lock:
        job = training_jobs.get(job_id)
        if not job:
            return

    try:
        job.status = "running"
        job.started_at = datetime.now().isoformat()
        logger.info(f"Starting training job {job_id}")

        if job.model_type == "edgnet_large":
            run_edgnet_large_training(job)
        elif job.model_type == "yolo_custom":
            run_yolo_custom_training(job)
        elif job.model_type == "skinmodel":
            run_skinmodel_training(job)
        elif job.model_type == "edgnet":
            run_edgnet_simple_training(job)
        else:
            raise ValueError(f"Unknown model type: {job.model_type}")

        job.status = "completed"
        job.progress = 100.0
        logger.info(f"Training job {job_id} completed")

    except Exception as e:
        logger.error(f"Training job {job_id} failed: {e}")
        job.status = "failed"
        job.error = str(e)
        job.logs.append(f"ERROR: {str(e)}")

    finally:
        job.completed_at = datetime.now().isoformat()


def run_edgnet_large_training(job: TrainingJob):
    """EDGNet ëŒ€ê·œëª¨ í•™ìŠµ ì‹¤í–‰"""
    job.logs.append("ğŸš€ EDGNet ëŒ€ê·œëª¨ í•™ìŠµ ì‹œì‘...")

    # ë°ì´í„°ì…‹ í™•ì¸
    data_path = Path("/home/uproot/ax/poc/edgnet_dataset_large")
    if not data_path.exists():
        raise FileNotFoundError(f"Dataset not found: {data_path}")

    job.logs.append(f"âœ… ë°ì´í„°ì…‹ í™•ì¸: {data_path}")

    # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ
    script_path = Path("/home/uproot/ax/poc/scripts/train_edgnet_large.py")

    # í•™ìŠµ íŒŒë¼ë¯¸í„°
    epochs = job.config.get('epochs', 100)
    batch_size = job.config.get('batch_size', 8)

    job.logs.append(f"ğŸ“Š í•™ìŠµ íŒŒë¼ë¯¸í„°:")
    job.logs.append(f"   - Epochs: {epochs}")
    job.logs.append(f"   - Batch size: {batch_size}")

    # í•™ìŠµ ì‹¤í–‰
    cmd = [
        "python3",
        str(script_path),
        "--data", str(data_path),
        "--epochs", str(epochs),
        "--batch-size", str(batch_size)
    ]

    job.logs.append(f"ğŸ”§ ì‹¤í–‰ ëª…ë ¹: {' '.join(cmd)}")

    process = subprocess.Popen(
        cmd,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
        bufsize=1
    )

    # ì‹¤ì‹œê°„ ë¡œê·¸ ë° ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
    import re
    for line in process.stdout:
        line = line.strip()
        if line:
            job.logs.append(line)

            # Epoch ì§„í–‰ë¥  íŒŒì‹± - ì •ê·œí‘œí˜„ì‹ ì‚¬ìš©
            # "Epoch 10/100:" ë˜ëŠ” "Epoch 10/100" í˜•ì‹ íŒŒì‹±
            epoch_match = re.search(r'Epoch\s+(\d+)/(\d+)', line)
            if epoch_match:
                try:
                    current = int(epoch_match.group(1))
                    total = int(epoch_match.group(2))
                    job.current_epoch = current
                    job.total_epochs = total
                    job.progress = (current / total) * 100
                except:
                    pass

    process.wait()

    if process.returncode != 0:
        raise RuntimeError(f"Training failed with exit code {process.returncode}")

    job.logs.append("âœ… EDGNet ëŒ€ê·œëª¨ í•™ìŠµ ì™„ë£Œ!")


def run_yolo_custom_training(job: TrainingJob):
    """YOLO ì»¤ìŠ¤í…€ í•™ìŠµ ì‹¤í–‰"""
    job.logs.append("ğŸ¯ YOLO ì»¤ìŠ¤í…€ í•™ìŠµ ì‹œì‘...")

    # ë°ì´í„°ì…‹ í™•ì¸
    data_yaml = Path("/home/uproot/ax/poc/datasets/real_drawings_yolo/dataset.yaml")
    if not data_yaml.exists():
        raise FileNotFoundError(f"Dataset config not found: {data_yaml}")

    job.logs.append(f"âœ… ë°ì´í„°ì…‹ ì„¤ì • í™•ì¸: {data_yaml}")

    epochs = job.config.get('epochs', 50)
    batch_size = job.config.get('batch_size', 16)

    cmd = [
        "python3",
        "/home/uproot/ax/poc/yolo-api/train.py",
        "--data", str(data_yaml),
        "--epochs", str(epochs),
        "--batch-size", str(batch_size)
    ]

    job.logs.append(f"ğŸ”§ ì‹¤í–‰ ëª…ë ¹: {' '.join(cmd)}")

    process = subprocess.Popen(
        cmd,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
        bufsize=1
    )

    for line in process.stdout:
        line = line.strip()
        if line:
            job.logs.append(line)

            # Epoch ì§„í–‰ë¥  íŒŒì‹±
            if "Epoch" in line or "epoch" in line:
                try:
                    parts = line.split("/")
                    if len(parts) >= 2:
                        current = int(parts[0].split()[-1])
                        total = int(parts[1].split()[0])
                        job.current_epoch = current
                        job.total_epochs = total
                        job.progress = (current / total) * 100
                except:
                    pass

    process.wait()

    if process.returncode != 0:
        raise RuntimeError(f"Training failed with exit code {process.returncode}")

    job.logs.append("âœ… YOLO ì»¤ìŠ¤í…€ í•™ìŠµ ì™„ë£Œ!")


def run_skinmodel_training(job: TrainingJob):
    """Skin Model í•™ìŠµ ì‹¤í–‰ (ê¸°ì¡´)"""
    job.logs.append("ğŸ”¬ Skin Model í•™ìŠµ ì‹œì‘...")

    script_path = Path("/home/uproot/ax/poc/scripts/upgrade_skinmodel_xgboost.py")

    cmd = ["python3", str(script_path)]

    process = subprocess.Popen(
        cmd,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
        bufsize=1,
        cwd="/home/uproot/ax/poc"
    )

    for line in process.stdout:
        line = line.strip()
        if line:
            job.logs.append(line)
            job.progress = min(job.progress + 5, 95)  # ì ì§„ì  ì§„í–‰

    process.wait()

    if process.returncode != 0:
        raise RuntimeError(f"Training failed with exit code {process.returncode}")

    job.progress = 100
    job.logs.append("âœ… Skin Model í•™ìŠµ ì™„ë£Œ!")


def run_edgnet_simple_training(job: TrainingJob):
    """EDGNet ê°„ë‹¨ í•™ìŠµ ì‹¤í–‰ (ê¸°ì¡´)"""
    job.logs.append("ğŸ“ EDGNet ê°„ë‹¨ í•™ìŠµ ì‹œì‘...")

    script_path = Path("/home/uproot/ax/poc/scripts/train_edgnet_simple.py")

    cmd = ["python3", str(script_path)]

    process = subprocess.Popen(
        cmd,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
        bufsize=1,
        cwd="/home/uproot/ax/poc"
    )

    for line in process.stdout:
        line = line.strip()
        if line:
            job.logs.append(line)
            job.progress = min(job.progress + 5, 95)

    process.wait()

    if process.returncode != 0:
        raise RuntimeError(f"Training failed with exit code {process.returncode}")

    job.progress = 100
    job.logs.append("âœ… EDGNet ê°„ë‹¨ í•™ìŠµ ì™„ë£Œ!")


def cancel_training_job(job_id: str) -> bool:
    """í•™ìŠµ ì‘ì—… ì·¨ì†Œ (TODO: êµ¬í˜„)"""
    with training_lock:
        job = training_jobs.get(job_id)
        if job and job.status == "running":
            job.status = "cancelled"
            job.logs.append("âš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì·¨ì†Œë¨")
            return True
    return False
