# ì¥ê¸° ê°œì„  ê³¼ì œ

> ì‘ì„±ì¼: 2025-11-13
> ê¸°ê°„: 1-3ê°œì›”
> ìš°ì„ ìˆœìœ„: ğŸŸ¢ Priority 3

---

## ğŸ“‹ ê°œìš”

ì‹œìŠ¤í…œì˜ ì¥ê¸°ì ì¸ ì•ˆì •ì„±, í™•ì¥ì„±, ìœ ì§€ë³´ìˆ˜ì„±ì„ ìœ„í•œ ê°œì„  ê³¼ì œë“¤ì„ ì •ë¦¬í•©ë‹ˆë‹¤.
ê° ê³¼ì œëŠ” 1-2ì£¼ ì´ìƒì˜ ì‹œê°„ì´ ì†Œìš”ë˜ë©°, ì‹œìŠ¤í…œì˜ ê·¼ë³¸ì ì¸ ê°œì„ ì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

---

## 1. ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë° ë²„ì „ ê´€ë¦¬ ğŸ¯

### 1.1 ë¬¸ì œ ì •ì˜

**í˜„ì¬ ìƒí™©**:
```
/models/
â”œâ”€â”€ yolo11n.pt              # ë²„ì „ ë¶ˆëª…, ì²´í¬ì„¬ ì—†ìŒ
â”œâ”€â”€ graphsage_dimension_classifier.pth  # ë²„ì „ ë¶ˆëª…
â””â”€â”€ (ê¸°íƒ€ ëª¨ë¸ë“¤...)
```

**ë¬¸ì œì **:
- âŒ ëª¨ë¸ ë²„ì „ ì¶”ì  ë¶ˆê°€ëŠ¥
- âŒ ëª¨ë¸ ë³€ê²½ ì´ë ¥ ì—†ìŒ
- âŒ ì²´í¬ì„¬ ê²€ì¦ ì—†ìŒ
- âŒ ìë™ ë‹¤ìš´ë¡œë“œ/ë°°í¬ ë¶ˆê°€ëŠ¥
- âŒ A/B í…ŒìŠ¤íŠ¸ ì–´ë ¤ì›€

### 1.2 í•´ê²° ë°©ì•ˆ: MLflow Model Registry

#### ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 MLflow Server                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Tracking   â”‚  â”‚     Model Registry       â”‚ â”‚
â”‚  â”‚   Server     â”‚  â”‚  - Versioning            â”‚ â”‚
â”‚  â”‚   (Metrics,  â”‚  â”‚  - Staging/Production    â”‚ â”‚
â”‚  â”‚    Logs)     â”‚  â”‚  - Metadata              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                      â”‚
          â”‚                      â”‚
          â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Training Script â”‚    â”‚   Inference API      â”‚
â”‚  - Log metrics   â”‚    â”‚   - Load model v2    â”‚
â”‚  - Register v2   â”‚    â”‚   - Fallback to v1   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### êµ¬í˜„ ì˜ˆì‹œ

```python
import mlflow
import mlflow.pytorch

# 1. MLflow ì´ˆê¸°í™”
mlflow.set_tracking_uri("http://mlflow-server:5000")
mlflow.set_experiment("yolo-training")

# 2. í•™ìŠµ ì¤‘ ë©”íŠ¸ë¦­ ë¡œê¹…
with mlflow.start_run(run_name="yolo11n-v1.2"):
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ê¸°ë¡
    mlflow.log_params({
        "model": "yolo11n",
        "epochs": 100,
        "batch_size": 16,
        "lr": 0.001,
        "dataset": "engineering_drawings_v1.0"
    })

    # í•™ìŠµ
    for epoch in range(100):
        train_loss = train_one_epoch(model, ...)
        val_loss = validate(model, ...)

        # ë©”íŠ¸ë¦­ ë¡œê¹…
        mlflow.log_metrics({
            "train_loss": train_loss,
            "val_loss": val_loss,
            "mAP50": compute_map(model, ...),
            "mAP50_95": compute_map_range(model, ...)
        }, step=epoch)

    # ëª¨ë¸ ì €ì¥
    mlflow.pytorch.log_model(
        model,
        artifact_path="model",
        registered_model_name="yolo-dimension-detector"
    )

# 3. í”„ë¡œë•ì…˜ìœ¼ë¡œ ìŠ¹ê²©
client = mlflow.tracking.MlflowClient()
client.transition_model_version_stage(
    name="yolo-dimension-detector",
    version=2,
    stage="Production"
)

# 4. ì¶”ë¡  ì‹œ ë¡œë“œ
model_uri = "models:/yolo-dimension-detector/Production"
model = mlflow.pytorch.load_model(model_uri)
```

#### ë°°í¬

```yaml
# docker-compose.ymlì— MLflow ì¶”ê°€
services:
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    container_name: mlflow-server
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_BACKEND_STORE_URI=postgresql://user:pass@postgres:5432/mlflow
      - MLFLOW_ARTIFACT_ROOT=s3://mlflow-artifacts/  # ë˜ëŠ” /mlflow/artifacts
    volumes:
      - mlflow-artifacts:/mlflow/artifacts
    command: >
      mlflow server
      --backend-store-uri postgresql://user:pass@postgres:5432/mlflow
      --default-artifact-root /mlflow/artifacts
      --host 0.0.0.0
      --port 5000

  postgres:
    image: postgres:15
    environment:
      - POSTGRES_USER=mlflow
      - POSTGRES_PASSWORD=mlflow
      - POSTGRES_DB=mlflow
    volumes:
      - postgres-data:/var/lib/postgresql/data

volumes:
  mlflow-artifacts:
  postgres-data:
```

### 1.3 ì¥ì 

- âœ… ëª¨ë¸ ë²„ì „ ìë™ ì¶”ì 
- âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° ê¸°ë¡
- âœ… ë©”íŠ¸ë¦­ ì‹œê°í™”
- âœ… ëª¨ë¸ ë¹„êµ (v1 vs v2)
- âœ… A/B í…ŒìŠ¤íŠ¸ ì§€ì›
- âœ… Staging/Production í™˜ê²½ ë¶„ë¦¬
- âœ… ì²´í¬ì„¬ ìë™ ê²€ì¦

**ì˜ˆìƒ ì†Œìš”**: 3-4ì¼

---

## 2. ë¶„ì‚° ì¶”ë¡  (Load Balancing) âš¡

### 2.1 ë¬¸ì œ ì •ì˜

**í˜„ì¬ ìƒí™©**:
- ê° APIê°€ ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ë¡œ ì‹¤í–‰
- ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ ì œí•œ (1-2ê°œ)
- GPU ë¦¬ì†ŒìŠ¤ ë¯¸í™œìš© (ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤)

**ë¬¸ì œì **:
- âŒ ë™ì‹œ ì²˜ë¦¬ëŸ‰ ë‚®ìŒ (1-2 RPS)
- âŒ GPU í™œìš©ë¥  ë‚®ìŒ (<50%)
- âŒ ì‘ë‹µ ì‹œê°„ ë¶ˆì•ˆì •

### 2.2 í•´ê²° ë°©ì•ˆ: Kubernetes + HPA

#### ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Kubernetes Cluster                   â”‚
â”‚                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚         Ingress (nginx)                     â”‚ â”‚
â”‚  â”‚         gateway.example.com                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                 â”‚                                  â”‚
â”‚                 â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚       Gateway API Service                â”‚    â”‚
â”‚  â”‚       Replicas: 3                        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                 â”‚                                  â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚       â–¼         â–¼         â–¼         â–¼            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ YOLO-1  â”‚ â”‚ YOLO-2  â”‚ â”‚ YOLO-3  â”‚            â”‚
â”‚  â”‚ GPU: 0  â”‚ â”‚ GPU: 1  â”‚ â”‚ GPU: 0  â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Horizontal Pod Autoscaler (HPA)       â”‚    â”‚
â”‚  â”‚  - CPU > 70% â†’ Scale up                â”‚    â”‚
â”‚  â”‚  - CPU < 30% â†’ Scale down              â”‚    â”‚
â”‚  â”‚  - Min: 2, Max: 10                     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### êµ¬í˜„ ì˜ˆì‹œ

```yaml
# kubernetes/yolo-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: yolo-api
spec:
  replicas: 3  # ì´ˆê¸° ë ˆí”Œë¦¬ì¹´ ìˆ˜
  selector:
    matchLabels:
      app: yolo-api
  template:
    metadata:
      labels:
        app: yolo-api
    spec:
      containers:
      - name: yolo-api
        image: yolo-api:latest
        resources:
          requests:
            memory: "4Gi"
            cpu: "2"
            nvidia.com/gpu: "1"  # GPU ìš”ì²­
          limits:
            memory: "8Gi"
            cpu: "4"
            nvidia.com/gpu: "1"
        ports:
        - containerPort: 5005

---
# kubernetes/yolo-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: yolo-api
spec:
  selector:
    app: yolo-api
  ports:
  - protocol: TCP
    port: 5005
    targetPort: 5005
  type: ClusterIP

---
# kubernetes/yolo-hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: yolo-api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: yolo-api
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

### 2.3 ëŒ€ì•ˆ: Ray Serve (ì¶”ì²œ - ê°„ë‹¨)

```python
# ray_serve_yolo.py
import ray
from ray import serve
from ultralytics import YOLO

ray.init()
serve.start()

@serve.deployment(
    num_replicas=3,  # 3ê°œ ë ˆí”Œë¦¬ì¹´
    ray_actor_options={"num_gpus": 0.33}  # GPU ê³µìœ 
)
class YOLODetector:
    def __init__(self):
        self.model = YOLO("yolo11n.pt")

    async def __call__(self, request):
        image = await request.body()
        results = self.model(image)
        return results.json()

YOLODetector.deploy()

# ì‚¬ìš©
import requests
response = requests.post("http://localhost:8000/YOLODetector", data=image_bytes)
```

**ì¥ì **:
- âœ… Kubernetesë³´ë‹¤ ê°„ë‹¨
- âœ… GPU ê³µìœ  ì§€ì›
- âœ… ë™ì  ìŠ¤ì¼€ì¼ë§
- âœ… Python ë„¤ì´í‹°ë¸Œ

**ì˜ˆìƒ ì†Œìš”**: 2-3ì¼ (Ray Serve) / 1ì£¼ì¼ (Kubernetes)

---

## 3. ë¹„ë™ê¸° ì²˜ë¦¬ (Task Queue) ğŸ“¬

### 3.1 ë¬¸ì œ ì •ì˜

**í˜„ì¬ ìƒí™©**:
- ë™ê¸°ì‹ API (ìš”ì²­ â†’ ëŒ€ê¸° â†’ ì‘ë‹µ)
- ê¸´ ì²˜ë¦¬ ì‹œê°„ (5-30ì´ˆ)
- íƒ€ì„ì•„ì›ƒ ìœ„í—˜

### 3.2 í•´ê²° ë°©ì•ˆ: Celery + Redis

#### ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    POST /process    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Client  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚  Gateway API â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                                   â”‚
     â”‚  202 Accepted                     â”‚ enqueue task
     â”‚  {"job_id": "abc-123"}            â”‚
     â”‚ <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”‚
     â”‚                                   â–¼
     â”‚                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                            â”‚    Redis    â”‚
     â”‚                            â”‚ (Task Queue)â”‚
     â”‚                            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
     â”‚                                   â”‚
     â”‚  GET /status/abc-123              â”‚ dequeue
     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>           â”‚
     â”‚                                   â–¼
     â”‚  200 OK                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  {"status": "processing"}  â”‚   Celery    â”‚
     â”‚ <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚   Workers   â”‚
     â”‚                            â”‚  (3 nodes)  â”‚
     â”‚                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                                   â”‚
     â”‚  GET /status/abc-123              â”‚ task complete
     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>           â”‚
     â”‚                                   â–¼
     â”‚  200 OK                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  {"status": "completed",   â”‚   Redis     â”‚
     â”‚   "result": {...}}         â”‚ (Results DB)â”‚
     â”‚ <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### êµ¬í˜„ ì˜ˆì‹œ

```python
# celery_app.py
from celery import Celery

app = Celery(
    'gateway',
    broker='redis://localhost:6379/0',
    backend='redis://localhost:6379/1'
)

@app.task(bind=True)
def process_drawing_async(self, image_path, params):
    """
    ë¹„ë™ê¸° ë„ë©´ ì²˜ë¦¬
    """
    # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
    self.update_state(state='PROGRESS', meta={'stage': 'yolo', 'progress': 0})

    # YOLO ê²€ì¶œ
    yolo_result = call_yolo(image_path, params["yolo"])
    self.update_state(state='PROGRESS', meta={'stage': 'yolo', 'progress': 30})

    # OCR ì¶”ì¶œ
    ocr_result = call_edocr2(image_path, params["ocr"])
    self.update_state(state='PROGRESS', meta={'stage': 'ocr', 'progress': 60})

    # ì„¸ê·¸ë©˜í…Œì´ì…˜
    seg_result = call_edgnet(image_path, params["seg"])
    self.update_state(state='PROGRESS', meta={'stage': 'segmentation', 'progress': 90})

    # ê²°ê³¼ í†µí•©
    final_result = merge_results(yolo_result, ocr_result, seg_result)
    self.update_state(state='SUCCESS', meta={'result': final_result})

    return final_result

# api_server.py
from fastapi import FastAPI, BackgroundTasks
from celery.result import AsyncResult

app = FastAPI()

@app.post("/api/v1/process")
async def process_drawing(file: UploadFile):
    """
    ë„ë©´ ì²˜ë¦¬ (ë¹„ë™ê¸°)
    """
    # íŒŒì¼ ì €ì¥
    image_path = save_uploaded_file(file)

    # Celery íƒœìŠ¤í¬ ì‹œì‘
    task = process_drawing_async.delay(image_path, params)

    return {
        "status": "accepted",
        "job_id": task.id,
        "status_url": f"/api/v1/status/{task.id}"
    }

@app.get("/api/v1/status/{job_id}")
async def get_status(job_id: str):
    """
    ì‘ì—… ìƒíƒœ ì¡°íšŒ
    """
    task_result = AsyncResult(job_id, app=celery_app)

    if task_result.state == 'PENDING':
        return {"status": "pending", "progress": 0}
    elif task_result.state == 'PROGRESS':
        return {
            "status": "processing",
            "stage": task_result.info.get('stage'),
            "progress": task_result.info.get('progress')
        }
    elif task_result.state == 'SUCCESS':
        return {
            "status": "completed",
            "result": task_result.result
        }
    elif task_result.state == 'FAILURE':
        return {
            "status": "failed",
            "error": str(task_result.info)
        }
```

**ì˜ˆìƒ ì†Œìš”**: 3-4ì¼

---

## 4. ëª¨ë‹ˆí„°ë§ ë° ê´€ì°°ì„± (Observability) ğŸ“Š

### 4.1 Prometheus + Grafana

```yaml
# docker-compose.monitoring.yml
services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana-dashboards:/etc/grafana/provisioning/dashboards

  node-exporter:
    image: prom/node-exporter:latest
    ports:
      - "9100:9100"

  nvidia-gpu-exporter:
    image: utkuozdemir/nvidia_gpu_exporter:latest
    runtime: nvidia
    ports:
      - "9835:9835"
```

#### ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ì¶”ê°€

```python
# api_server.py
from prometheus_client import Counter, Histogram, Gauge
import time

# ë©”íŠ¸ë¦­ ì •ì˜
request_count = Counter('yolo_requests_total', 'Total YOLO requests')
request_duration = Histogram('yolo_request_duration_seconds', 'YOLO request duration')
model_confidence = Histogram('yolo_confidence', 'YOLO detection confidence')
active_requests = Gauge('yolo_active_requests', 'Active YOLO requests')

@app.post("/api/v1/detect")
async def detect(file: UploadFile):
    request_count.inc()
    active_requests.inc()

    start_time = time.time()
    try:
        result = model(file)

        # ì‹ ë¢°ë„ ë©”íŠ¸ë¦­ ê¸°ë¡
        for detection in result.detections:
            model_confidence.observe(detection.confidence)

        duration = time.time() - start_time
        request_duration.observe(duration)

        return result
    finally:
        active_requests.dec()
```

**ì˜ˆìƒ ì†Œìš”**: 2-3ì¼

---

## 5. í†µí•© í…ŒìŠ¤íŠ¸ ë° CI/CD ğŸ”„

### 5.1 GitHub Actions Workflow

```yaml
# .github/workflows/test-and-deploy.yml
name: Test and Deploy

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov

      - name: Run unit tests
        run: pytest tests/unit --cov=src --cov-report=xml

      - name: Run integration tests
        run: |
          docker-compose -f docker-compose.test.yml up -d
          pytest tests/integration
          docker-compose -f docker-compose.test.yml down

      - name: Upload coverage
        uses: codecov/codecov-action@v3

  build:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Build Docker images
        run: |
          docker-compose build

      - name: Push to registry
        run: |
          docker tag gateway-api:latest ${{ secrets.REGISTRY }}/gateway-api:${{ github.sha }}
          docker push ${{ secrets.REGISTRY }}/gateway-api:${{ github.sha }}

  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Deploy to production
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.PROD_HOST }}
          username: ${{ secrets.PROD_USER }}
          key: ${{ secrets.PROD_SSH_KEY }}
          script: |
            cd /opt/ax-poc
            docker-compose pull
            docker-compose up -d
```

**ì˜ˆìƒ ì†Œìš”**: 3-4ì¼

---

## 6. ë°ì´í„° íŒŒì´í”„ë¼ì¸ (Data Versioning) ğŸ’¾

### 6.1 DVC (Data Version Control)

```bash
# ë°ì´í„° ë²„ì „ ê´€ë¦¬ ì´ˆê¸°í™”
dvc init

# ë°ì´í„°ì…‹ ì¶”ê°€
dvc add data/training_images.zip
dvc add data/annotations.json

# Gitì— ë©”íƒ€ë°ì´í„°ë§Œ ì»¤ë°‹
git add data/training_images.zip.dvc data/annotations.json.dvc .gitignore
git commit -m "Add dataset v1.0"

# ì›ê²© ì €ì¥ì†Œ ì„¤ì • (S3, GCS, Azure Blob)
dvc remote add -d storage s3://ax-poc-datasets
dvc push

# ë‹¤ë¥¸ ë¨¸ì‹ ì—ì„œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
dvc pull
```

#### ë°ì´í„° íŒŒì´í”„ë¼ì¸

```yaml
# dvc.yaml
stages:
  prepare:
    cmd: python scripts/prepare_data.py
    deps:
      - data/raw/
    outs:
      - data/prepared/

  train:
    cmd: python scripts/train_yolo.py
    deps:
      - data/prepared/
      - scripts/train_yolo.py
    params:
      - train.epochs
      - train.batch_size
    outs:
      - models/yolo11n.pt
    metrics:
      - metrics.json:
          cache: false
```

**ì˜ˆìƒ ì†Œìš”**: 2-3ì¼

---

## 7. ë³´ì•ˆ ê°•í™” ğŸ”’

### 7.1 API ì¸ì¦ (JWT)

```python
from fastapi import Depends, HTTPException, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
import jwt

security = HTTPBearer()

def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """
    JWT í† í° ê²€ì¦
    """
    token = credentials.credentials
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=["HS256"])
        return payload
    except jwt.ExpiredSignatureError:
        raise HTTPException(status_code=401, detail="Token expired")
    except jwt.JWTError:
        raise HTTPException(status_code=401, detail="Invalid token")

@app.post("/api/v1/process")
async def process_drawing(
    file: UploadFile,
    user: dict = Depends(verify_token)  # ì¸ì¦ í•„ìš”
):
    print(f"Processing for user: {user['sub']}")
    ...
```

### 7.2 Rate Limiting

```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

@app.post("/api/v1/process")
@limiter.limit("10/minute")  # ë¶„ë‹¹ 10íšŒ ì œí•œ
async def process_drawing(request: Request, file: UploadFile):
    ...
```

**ì˜ˆìƒ ì†Œìš”**: 2-3ì¼

---

## ğŸ“Š ì „ì²´ ë¡œë“œë§µ

### Phase 1: ì¸í”„ë¼ ê°œì„  (2-3ì£¼)

| ì£¼ì°¨ | ì‘ì—… | ì˜ˆìƒ ì†Œìš” |
|------|------|----------|
| **Week 1** | ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ (MLflow) | 3-4ì¼ |
|            | ë¹„ë™ê¸° ì²˜ë¦¬ (Celery) | 3-4ì¼ |
| **Week 2** | ëª¨ë‹ˆí„°ë§ (Prometheus + Grafana) | 2-3ì¼ |
|            | CI/CD íŒŒì´í”„ë¼ì¸ | 3-4ì¼ |
| **Week 3** | í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„± | 2-3ì¼ |
|            | ë¬¸ì„œ ì—…ë°ì´íŠ¸ | 1-2ì¼ |

### Phase 2: ì„±ëŠ¥ ìµœì í™” (2-3ì£¼)

| ì£¼ì°¨ | ì‘ì—… | ì˜ˆìƒ ì†Œìš” |
|------|------|----------|
| **Week 4** | ë¶„ì‚° ì¶”ë¡  (Ray Serve) | 2-3ì¼ |
|            | ìºì‹± ë ˆì´ì–´ ì¶”ê°€ | 2-3ì¼ |
| **Week 5** | GPU ìµœì í™” (TensorRT) | 3-4ì¼ |
|            | ë°°ì¹˜ ì²˜ë¦¬ êµ¬í˜„ | 2-3ì¼ |
| **Week 6** | ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë° íŠœë‹ | 3-5ì¼ |

### Phase 3: ë³´ì•ˆ ë° ê±°ë²„ë„ŒìŠ¤ (1-2ì£¼)

| ì£¼ì°¨ | ì‘ì—… | ì˜ˆìƒ ì†Œìš” |
|------|------|----------|
| **Week 7** | API ì¸ì¦ (JWT) | 2-3ì¼ |
|            | Rate Limiting | 1-2ì¼ |
|            | ë°ì´í„° ì•”í˜¸í™” | 2-3ì¼ |
| **Week 8** | ê°ì‚¬ ë¡œê·¸ (Audit Log) | 2-3ì¼ |
|            | ë³´ì•ˆ ìŠ¤ìº” ë° ì·¨ì•½ì  ìˆ˜ì • | 2-3ì¼ |

**ì´ ì˜ˆìƒ ì†Œìš”**: 8-11ì£¼ (2-3ê°œì›”)

---

## ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì¸í”„ë¼

- [ ] MLflow ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ êµ¬ì¶•
- [ ] Celery ë¹„ë™ê¸° ì²˜ë¦¬ êµ¬í˜„
- [ ] Prometheus + Grafana ëª¨ë‹ˆí„°ë§
- [ ] GitHub Actions CI/CD
- [ ] DVC ë°ì´í„° ë²„ì „ ê´€ë¦¬

### ì„±ëŠ¥

- [ ] Ray Serve ë˜ëŠ” Kubernetes ë°°í¬
- [ ] Redis ìºì‹± ë ˆì´ì–´
- [ ] GPU ìµœì í™” (TensorRT)
- [ ] ë°°ì¹˜ ì²˜ë¦¬ êµ¬í˜„
- [ ] ë¡œë“œ í…ŒìŠ¤íŠ¸ (Locust)

### ë³´ì•ˆ

- [ ] JWT ì¸ì¦
- [ ] Rate Limiting
- [ ] HTTPS/TLS
- [ ] ë°ì´í„° ì•”í˜¸í™”
- [ ] ê°ì‚¬ ë¡œê·¸

### ë¬¸ì„œ

- [ ] API ì‚¬ìš© ê°€ì´ë“œ
- [ ] ìš´ì˜ ë§¤ë‰´ì–¼ (Runbook)
- [ ] ì¥ì•  ëŒ€ì‘ ê°€ì´ë“œ
- [ ] ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

---

## ğŸ¯ ì„±ê³µ ê¸°ì¤€

### ì¸í”„ë¼

- âœ… ëª¨ë¸ ë°°í¬ ì‹œê°„: 10ë¶„ â†’ **2ë¶„ ì´í•˜**
- âœ… ì‹œìŠ¤í…œ ê°€ë™ë¥  (Uptime): 95% â†’ **99.9%**
- âœ… ì¥ì•  ê°ì§€ ì‹œê°„: ? â†’ **1ë¶„ ì´ë‚´**

### ì„±ëŠ¥

- âœ… ì²˜ë¦¬ëŸ‰ (Throughput): 1-2 RPS â†’ **10+ RPS**
- âœ… ì‘ë‹µ ì‹œê°„ (P95): 30ì´ˆ â†’ **5ì´ˆ ì´í•˜**
- âœ… GPU í™œìš©ë¥ : 50% â†’ **80%+**

### ë³´ì•ˆ

- âœ… ì¸ì¦ ì ìš©: âŒ â†’ **100% ì ìš©**
- âœ… ì·¨ì•½ì : ? â†’ **0ê±´ (Critical/High)**
- âœ… ê°ì‚¬ ë¡œê·¸: âŒ â†’ **100% ê¸°ë¡**

---

**ê´€ë ¨ ë¬¸ì„œ**:
- `01_CURRENT_STATUS_OVERVIEW.md`: í˜„ì¬ ì‹œìŠ¤í…œ í˜„í™©
- `02_EDOCR2_INTEGRATION_PLAN.md`: ìš°ì„ ìˆœìœ„ 1 ê³¼ì œ
- `03_MINOR_FIXES.md`: ë¹ ë¥¸ ê°œì„  ì‚¬í•­
