# ğŸŸ¢ ìš°ì„ ìˆœìœ„ 3-1: GPU í•˜ë“œì›¨ì–´ ì„¤ì •

**ëª©ì **: ì²˜ë¦¬ ì‹œê°„ 45ì´ˆ â†’ 10-15ì´ˆë¡œ ë‹¨ì¶• (3-4ë°° í–¥ìƒ)
**ì†Œìš” ì‹œê°„**: 1-2ì¼
**ë¹„ìš©**: í•˜ë“œì›¨ì–´ ì˜ì¡´ (ê¸°ì¡´ GPU í™œìš© ì‹œ $0)

---

## ğŸ“‹ í˜„ì¬ ìƒíƒœ

### ì²˜ë¦¬ ì‹œê°„
| ì‘ì—… | CPU | GPU (ì˜ˆìƒ) | ê°œì„  |
|------|-----|-----------|------|
| EDGNet ì„¸ê·¸ë©˜í…Œì´ì…˜ | 45ì´ˆ | 12ì´ˆ | 3.8ë°° |
| eDOCr2 OCR | 23ì´ˆ | 8ì´ˆ | 2.9ë°° |
| ì „ì²´ íŒŒì´í”„ë¼ì¸ | 70ì´ˆ | 20ì´ˆ | 3.5ë°° |

---

## âœ… GPU ìš”êµ¬ì‚¬í•­

### ìµœì†Œ ì‚¬ì–‘
- **GPU**: NVIDIA GTX 1060 (6GB) ì´ìƒ
- **CUDA**: 11.0+
- **cuDNN**: 8.0+
- **VRAM**: 6GB+

### ê¶Œì¥ ì‚¬ì–‘
- **GPU**: NVIDIA RTX 3060 (12GB) ì´ìƒ
- **CUDA**: 11.8+
- **cuDNN**: 8.9+
- **VRAM**: 12GB+

---

## ğŸ” GPU í™•ì¸

### 1ë‹¨ê³„: GPU ì¡´ì¬ í™•ì¸

```bash
# NVIDIA GPU í™•ì¸
lspci | grep -i nvidia

# ì˜ˆìƒ ì¶œë ¥:
# 01:00.0 VGA compatible controller: NVIDIA Corporation ...
```

### 2ë‹¨ê³„: NVIDIA ë“œë¼ì´ë²„ í™•ì¸

```bash
nvidia-smi

# ì˜ˆìƒ ì¶œë ¥:
# +-----------------------------------------------------------------------------+
# | NVIDIA-SMI 525.60.11    Driver Version: 525.60.11    CUDA Version: 12.0     |
# |-------------------------------+----------------------+----------------------+
# | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
# | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
```

**GPU ì—†ëŠ” ê²½ìš°**: `TODO/PRIORITY_3_GPU_ALTERNATIVES.md` ì°¸ì¡°

---

## ğŸ”§ ì„¤ì¹˜ ì‘ì—…

### ì˜µì…˜ A: ë“œë¼ì´ë²„ ì´ë¯¸ ì„¤ì¹˜ë¨

**í™•ì¸**:
```bash
nvidia-smi  # ì •ìƒ ì¶œë ¥ë˜ë©´ OK
docker run --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi
```

**ê²°ê³¼**: âœ… Skip to Docker GPU ì„¤ì •

### ì˜µì…˜ B: ë“œë¼ì´ë²„ ì„¤ì¹˜ í•„ìš”

#### Ubuntu/Debian
```bash
# 1. ê¸°ì¡´ ë“œë¼ì´ë²„ ì œê±° (ìˆë‹¤ë©´)
sudo apt-get purge nvidia-*
sudo apt-get autoremove

# 2. ë“œë¼ì´ë²„ ì„¤ì¹˜
sudo apt-get update
sudo apt-get install -y nvidia-driver-525

# 3. ì¬ë¶€íŒ…
sudo reboot

# 4. í™•ì¸
nvidia-smi
```

#### Docker NVIDIA Runtime ì„¤ì¹˜
```bash
# 1. NVIDIA Docker ëŸ°íƒ€ì„ ì„¤ì¹˜
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
  sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update
sudo apt-get install -y nvidia-docker2

# 2. Docker ì¬ì‹œì‘
sudo systemctl restart docker

# 3. í…ŒìŠ¤íŠ¸
docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi
```

---

## ğŸ³ Docker GPU ì„¤ì •

### docker-compose.yml ìˆ˜ì •

```bash
# (Claudeê°€ ìë™ìœ¼ë¡œ ìˆ˜ì •í•¨)
# GPU ì§€ì› ì¶”ê°€ë¨
```

### ê°œë³„ ì„œë¹„ìŠ¤ GPU í• ë‹¹

**EDGNet API** (ê°€ì¥ ëŠë¦¼, ìµœìš°ì„ ):
```yaml
edgnet-api:
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: 1
            capabilities: [gpu]
```

**eDOCr2 API** (ë‘ ë²ˆì§¸ ìš°ì„ ):
```yaml
edocr2-api-v1:
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: 1
            capabilities: [gpu]
```

---

## ğŸ§ª GPU í…ŒìŠ¤íŠ¸

### 1. PyTorch GPU í™•ì¸

```bash
docker exec -it edgnet-api python3 << 'PYEOF'
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"CUDA version: {torch.version.cuda}")
print(f"GPU count: {torch.cuda.device_count()}")
if torch.cuda.is_available():
    print(f"GPU name: {torch.cuda.get_device_name(0)}")
PYEOF

# ì˜ˆìƒ ì¶œë ¥:
# CUDA available: True
# CUDA version: 11.8
# GPU count: 1
# GPU name: NVIDIA GeForce RTX 3060
```

### 2. ëª¨ë¸ GPU ë¡œë”© í™•ì¸

```bash
# EDGNet API ë¡œê·¸ í™•ì¸
docker-compose logs edgnet-api | grep -i "cuda\|gpu"

# ì˜ˆìƒ ì¶œë ¥:
# Model loaded on device: cuda:0
# GPU memory allocated: 2048 MB
```

### 3. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

```bash
# GPU í™œì„±í™” ì „/í›„ ë¹„êµ
python TODO/scripts/benchmark_gpu.py

# ì˜ˆìƒ ê²°ê³¼:
# CPU: 45.2s
# GPU: 11.8s
# Speedup: 3.8x
```

---

## ğŸ“Š ì„±ê³µ ê¸°ì¤€

### ìµœì†Œ ìš”êµ¬ì‚¬í•­
- [ ] nvidia-smi ì •ìƒ ì‘ë™
- [ ] Docker GPU ì ‘ê·¼ ê°€ëŠ¥
- [ ] PyTorch CUDA available: True
- [ ] ì²˜ë¦¬ ì‹œê°„ 30% ì´ìƒ ë‹¨ì¶•

### ì´ìƒì  ëª©í‘œ
- [ ] EDGNet: 45s â†’ 12s
- [ ] eDOCr2: 23s â†’ 8s
- [ ] ì „ì²´: 70s â†’ 20s

---

## ğŸš¨ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### nvidia-smi: command not found
```bash
# ë“œë¼ì´ë²„ ë¯¸ì„¤ì¹˜
sudo apt-get install nvidia-driver-525
sudo reboot
```

### Docker: could not select device driver
```bash
# NVIDIA Docker ëŸ°íƒ€ì„ ë¯¸ì„¤ì¹˜
sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker
```

### CUDA out of memory
```bash
# GPU VRAM ë¶€ì¡±
# í•´ê²°: Batch size ì¤„ì´ê¸°
# edgnet-api/config.py
BATCH_SIZE = 8  # 16 â†’ 8ë¡œ ì¤„ì„
```

---

## âœ… ì™„ë£Œ í™•ì¸

```bash
# 1. GPU ì‚¬ìš© í™•ì¸
nvidia-smi

# 2. Docker GPU í™•ì¸
docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi

# 3. ì„œë¹„ìŠ¤ GPU í™•ì¸
docker exec -it edgnet-api python3 -c "import torch; print(torch.cuda.is_available())"
# ì¶œë ¥: True

# 4. ë²¤ì¹˜ë§ˆí¬
python TODO/scripts/benchmark_gpu.py
# Speedup: 3x ì´ìƒì´ë©´ ì„±ê³µ!
```

---

**ì‘ì„±ì¼**: 2025-11-08
**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 1-2ì¼
**ë‹¤ìŒ ë‹¨ê³„**: `PRIORITY_3_PRODUCTION.md`
